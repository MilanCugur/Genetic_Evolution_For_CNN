{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Neuroevolution_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CuXJhy_ieyQ0",
        "hVp4A8xQU-fb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilanCugur/Neuroevolution-LocalSearch/blob/master/Baseline_Model/Baseline_Neuroevolution_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfJ-fn_XLnLU",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DoSLvx2LdSl",
        "colab_type": "code",
        "outputId": "e36a52c1-bece-4046-ad10-5f54dd9ab9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoTzVEoMfV6",
        "colab_type": "code",
        "outputId": "35177090-b5c4-4ca7-abc0-63a07d1fbbe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Add, Activation, Flatten, Concatenate, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam  \n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import LeakyReLU, concatenate\n",
        "from keras.layers.advanced_activations import ReLU\n",
        "from keras.initializers import glorot_normal\n",
        "import keras.backend as K\n",
        "from keras.models import load_model  # Save model params\n",
        "\n",
        "def extract_dataset(path):\n",
        "  \"\"\"\n",
        "  extract DoubledMNIST dataset\n",
        "  Argument: path to .zip file with the dataset\n",
        "  Return value: x_train, y_train, x_test, y_test lists of numpy arrays \n",
        "  \n",
        "  (DoubledMNIST dataset: train size 120k images 56x56, test size 20k images 56x56)\n",
        "  \"\"\"\n",
        "  # import libraries\n",
        "  import os                     # for basic os operations\n",
        "  from zipfile import ZipFile \n",
        "  from skimage import io\n",
        "  import shutil\n",
        "  \n",
        "  if not path.endswith('.zip'):\n",
        "    raise ValueError(\"Error: path is not '.zip' file\")\n",
        "  \n",
        "  archive = ZipFile(path, 'r')  # extract\n",
        "  archive.extractall('./DoubledMNIST')\n",
        "  archive.close()\n",
        "  del archive\n",
        "  \n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/train'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/train', file))\n",
        "    x_train.append(np.array(img))\n",
        "    y_train.append(int(file.split('_')[1]))\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/test'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/test', file))\n",
        "    x_test.append(np.array(img))\n",
        "    y_test.append(int(file.split('_')[1]))\n",
        "    \n",
        "  shutil.rmtree('./DoubledMNIST')\n",
        "  return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bKQ505PMxBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(doubled=0, ntrain=None, ntest=None):\n",
        "    \"\"\"\n",
        "    doubled==0 -> load MNIST; doubled==1-> load DoubledMNIST\n",
        "    ntrain - number of train samples\n",
        "    ntest - number of test samples\n",
        "    \"\"\"\n",
        "\n",
        "    from keras.utils import to_categorical\n",
        "    import numpy as np\n",
        "\n",
        "    if doubled==0:\n",
        "        # load mnist\n",
        "        from keras.datasets import mnist\n",
        "\n",
        "        (_x_train, _y_train), (_x_test, _y_test) = mnist.load_data()\n",
        "        if ntrain==None:\n",
        "            ntrain = _x_train.shape[0]\n",
        "        if ntest==None:\n",
        "            ntest = _x_test.shape[0]\n",
        "        assert ntrain<=_x_train.shape[0] and ntest<=_x_test.shape[0]\n",
        "    else:\n",
        "        # load doubled mnist\n",
        "        _x_train, _y_train, _x_test, _y_test = extract_dataset('./drive/My Drive/ni_sem/DoubledMNIST.zip')\n",
        "\n",
        "    # Prepare images\n",
        "    box_size = _x_train.shape[1]\n",
        "    y_train = to_categorical(_y_train)[:ntrain]\n",
        "    y_test = to_categorical(_y_test)[:ntest]\n",
        "    x_train = np.array(_x_train).astype('float32')[:ntrain]\n",
        "    x_train /= 255\n",
        "    x_train = np.reshape(x_train,[-1, box_size, box_size, 1])\n",
        "    x_test = np.array(_x_test).astype('float32')[:ntest]\n",
        "    x_test /= 255\n",
        "    x_test = np.reshape(x_test, [-1, box_size, box_size, 1])\n",
        "    return x_train, y_train, x_test, y_test, box_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5K7U7oOg4_4",
        "colab_type": "code",
        "outputId": "f56eef06-d46e-4938-b3e8-53c0f8aee3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=0, ntrain=10000, ntest=1000)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "CPU times: user 383 ms, sys: 120 ms, total: 503 ms\n",
            "Wall time: 6.76 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8PNO4_WwR-E",
        "colab_type": "code",
        "outputId": "0f611286-1a0c-40cd-f06f-1a89eaa179ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28, 1), (10000, 10), (1000, 28, 28, 1), (1000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA_twWHcP-71",
        "colab_type": "code",
        "outputId": "52248825-6e69-407a-fdf4-e3cb23676045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import pyplot as plt  # smal demonstration\n",
        "\n",
        "plt.imshow(x_test[19].reshape((x_test.shape[1], x_test.shape[2])))\n",
        "plt.show()\n",
        "\n",
        "print(y_test[19])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANUElEQVR4nO3dbYxc5XnG8evyZv0SQ1q/4MUYK0Bi\ngkzbOM3WoMRJqWgihy8mXxCugtwKdVMVoiChqoiqCv1UFIVESEWRNsXCQRSCCggnQgHHskCIyLJx\nHb9BYopMsbvYIbZqIMTete9+2EO0wM6z65kzL/b9/0mrOXPuOXtuH+3lZ+acmXkcEQJw7pvR7QYA\ndAZhB5Ig7EAShB1IgrADSXykkzub6VkxW3M7uUsgld/pHZ2ME56s1lLYba+WdK+kPkn/HhF3lx4/\nW3N1la9tZZcACrbG5oa1pp/G2+6TdJ+kr0haLmmt7eXN/j4A7dXKa/aVkl6JiFcj4qSkRyStqact\nAHVrJexLJL0+4f7Bat372B6yvd329lGdaGF3AFrR9rPxETEcEYMRMdivWe3eHYAGWgn7IUlLJ9y/\nuFoHoAe1EvZtkpbZvtT2TEk3StpYT1sA6tb0pbeIGLN9q6SnNX7pbX1E7K2tMwC1auk6e0Q8Jemp\nmnoB0Ea8XRZIgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE\nYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkWprF\nFWinoz+5vFgf++nCYn3Rv71QZztnvZbCbvuApLcknZI0FhGDdTQFoH51jOx/ERFv1vB7ALQRr9mB\nJFoNe0h6xvaLtocme4DtIdvbbW8f1YkWdwegWa0+jV8VEYdsL5K0yfbLEfHcxAdExLCkYUn6mOdH\ni/sD0KSWRvaIOFTdHpH0hKSVdTQFoH5Nh932XNvnv7cs6cuS9tTVGIB6tfI0fkDSE7bf+z3/ERE/\nraUr5DCjr1i+78qHivW/+uU3ivVFZ9zQua3psEfEq5I+XWMvANqIS29AEoQdSIKwA0kQdiAJwg4k\nwUdc0TVj16wo1j87c1uHOsmBkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuA6ew/wZ68s1k99+3ix\n3v+NOY233ferpno6G8zb6263cFZhZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJLjO3gNGVv1Bsb7j\nigeL9as+d0vD2oJ9TbXUEccun9nS9ucfHK2pkxwY2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCa6z\n94CxL/5fS9uff3Cspk4664qbXi7WXx49UazP3LKrWI8z7ujcNuXIbnu97SO290xYN9/2Jtv7q9t5\n7W0TQKum8zT+AUmrP7DuDkmbI2KZpM3VfQA9bMqwR8Rzko5+YPUaSRuq5Q2Srq+5LwA1a/Y1+0BE\njFTLb0gaaPRA20OShiRptj7a5O4AtKrls/ERESqcC4mI4YgYjIjBfs1qdXcAmtRs2A/bXixJ1e2R\n+loC0A7Nhn2jpHXV8jpJT9bTDoB2mfI1u+2HJV0jaaHtg5K+JeluSY/avlnSa5JuaGeTZ7u+BfOL\n9Xs+/Z/F+tX/dWOxPv+ZHWfcUy+Y+5GTxfpolMeiGC1vj/ebMuwRsbZB6dqaewHQRrxdFkiCsANJ\nEHYgCcIOJEHYgST4iGsHvDt4WbH+pTk/K9Zv27GgWJ9/unenZe4bWNSw9neLflLc9uY9NxXrC9W7\n/+5exMgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwnb0D/ndVf0vbX7yl/JXKvex//uaTDWsrZpb/\n/H73wsIpfjvX2c8EIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF19hrM+Gh5Wqt/ueGRYn33ydFi\n/e0lM4v1Yz/6k4a1Sy/4TXHbhbPfKdbv//imYn0qM/RioeritqfmMOlynRjZgSQIO5AEYQeSIOxA\nEoQdSIKwA0kQdiAJR3TuWubHPD+u8rk3+WvfBRcU6z/e+XRb9z+mUw1r9x37VHHbpw8vr7ud93nw\n8h81rC2YMae47bHT7xbr137nH4r1C+99oVg/F22NzToeRyd9A8OUI7vt9baP2N4zYd1dtg/Z3ln9\nXFdnwwDqN52n8Q9IWj3J+u9FxIrq56l62wJQtynDHhHPSTragV4AtFErJ+hutb2repo/r9GDbA/Z\n3m57+6jO3u9SA852zYb9+5I+IWmFpBFJ9zR6YEQMR8RgRAz2a1aTuwPQqqbCHhGHI+JURJyW9ANJ\nK+ttC0Ddmgq77cUT7n5V0p5GjwXQG6b8PLvthyVdI2mh7YOSviXpGtsrJIWkA5K+3sYee1789rfF\n+gPHLyrWPzfn1WL9+oduL9Y/OXywYW3stdeL20qNt63Dtlcazy2/ek75uL11uvwekC98rfRZeWn/\nvcVyOlOGPSLWTrL6/jb0AqCNeLsskARhB5Ig7EAShB1IgrADSfBV0jU4/U7565gf+8KVxfrj/SuK\n9UtGfl6sjxWr7dW37LJi/Y9nPt+w9q+/GSxu++zfX13e9zvlr+CW9k5Rz4WRHUiCsANJEHYgCcIO\nJEHYgSQIO5AEYQeS4Dp7B5x6szxt8tns9TUXFutL+hpPZ73+2T8vbrvs+a3FOhM6nxlGdiAJwg4k\nQdiBJAg7kARhB5Ig7EAShB1IguvsaMnJP2z+avdFz9bYCKbEyA4kQdiBJAg7kARhB5Ig7EAShB1I\ngrADSXCdHV3Td4JPpHfSlCO77aW2t9jeZ3uv7W9W6+fb3mR7f3U7r/3tAmjWdJ7Gj0m6PSKWS7pa\n0i22l0u6Q9LmiFgmaXN1H0CPmjLsETESETuq5bckvSRpiaQ1kjZUD9sg6fp2NQmgdWf0mt32JZI+\nI2mrpIGIGKlKb0gaaLDNkKQhSZqtxt9HBqC9pn023vZ5kh6TdFtEHJ9Yi4hQg+//i4jhiBiMiMF+\nzWqpWQDNm1bYbfdrPOgPRcTj1erDthdX9cWSjrSnRQB1mM7ZeEu6X9JLEfHdCaWNktZVy+skPVl/\newDqMp3X7J+XdJOk3bZ3VuvulHS3pEdt3yzpNUk3tKdFAHWYMuwR8bwkNyhfW287ANqFt8sCSRB2\nIAnCDiRB2IEkCDuQBB9xRUsG/uyNYr3PjceTo1eU//wu+nFTLaEBRnYgCcIOJEHYgSQIO5AEYQeS\nIOxAEoQdSILr7GjJhXOPF+un4nTD2qxjfJV0JzGyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASXGdH\nS36x5fJi/S/fPa9hbdGje4vbnmqqIzTCyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSUx5nd32Ukk/\nlDQgKSQNR8S9tu+S9LeSfl099M6IeKpdjaI3XfLPP296W66jd9Z03lQzJun2iNhh+3xJL9reVNW+\nFxHfaV97AOoynfnZRySNVMtv2X5J0pJ2NwagXmf0mt32JZI+I2lrtepW27tsr7c9r8E2Q7a3294+\nqhMtNQugedMOu+3zJD0m6baIOC7p+5I+IWmFxkf+eybbLiKGI2IwIgb7NauGlgE0Y1pht92v8aA/\nFBGPS1JEHI6IUxFxWtIPJK1sX5sAWjVl2G1b0v2SXoqI705Yv3jCw74qaU/97QGoy3TOxn9e0k2S\ndtveWa27U9Ja2ys0fjnugKSvt6VDALWYztn45yV5khLX1IGzCO+gA5Ig7EAShB1IgrADSRB2IAnC\nDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI6NzO7F9Lem3CqoWS3uxYA2emV3vr1b4k\nemtWnb19PCIumKzQ0bB/aOf29ogY7FoDBb3aW6/2JdFbszrVG0/jgSQIO5BEt8M+3OX9l/Rqb73a\nl0RvzepIb119zQ6gc7o9sgPoEMIOJNGVsNtebfuXtl+xfUc3emjE9gHbu23vtL29y72st33E9p4J\n6+bb3mR7f3U76Rx7XertLtuHqmO30/Z1Xeptqe0ttvfZ3mv7m9X6rh67Ql8dOW4df81uu0/SryR9\nSdJBSdskrY2IfR1tpAHbByQNRkTX34Bh+4uS3pb0w4j4o2rdtyUdjYi7q/8o50XEP/ZIb3dJervb\n03hXsxUtnjjNuKTrJf21unjsCn3doA4ct26M7CslvRIRr0bESUmPSFrThT56XkQ8J+noB1avkbSh\nWt6g8T+WjmvQW0+IiJGI2FEtvyXpvWnGu3rsCn11RDfCvkTS6xPuH1Rvzfcekp6x/aLtoW43M4mB\niBiplt+QNNDNZiYx5TTenfSBacZ75tg1M/15qzhB92GrIuJPJX1F0i3V09WeFOOvwXrp2um0pvHu\nlEmmGf+9bh67Zqc/b1U3wn5I0tIJ9y+u1vWEiDhU3R6R9IR6byrqw+/NoFvdHulyP7/XS9N4TzbN\nuHrg2HVz+vNuhH2bpGW2L7U9U9KNkjZ2oY8PsT23OnEi23MlfVm9NxX1RknrquV1kp7sYi/v0yvT\neDeaZlxdPnZdn/48Ijr+I+k6jZ+R/29J/9SNHhr0dZmkX1Q/e7vdm6SHNf60blTj5zZulrRA0mZJ\n+yX9TNL8HurtQUm7Je3SeLAWd6m3VRp/ir5L0s7q57puH7tCXx05brxdFkiCE3RAEoQdSIKwA0kQ\ndiAJwg4kQdiBJAg7kMT/A8+T6g7j+JKWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uungJ3ZiczL",
        "colab_type": "text"
      },
      "source": [
        "# CNN tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDESDezifHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "\n",
        "# sampleIndividual = [1, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi klasicna CNN\n",
        "# stage1 examples\n",
        "# sampleIndividual = [1, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; trojka eliminisana\n",
        "# sampleIndividual = [0, 1, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; dvojka eliminisana\n",
        "# sampleIndividual = [0, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; jedinica eliminisana\n",
        "# sampleIndividual = [0, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; samo jedna konv.\n",
        "# stage2 examples\n",
        "# sampleIndividual = [1, 0, 1,   0, 0, 0, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->3->4->5\n",
        "# sampleIndividual = [1, 0, 1,   0, 1, 0, 0, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->1->3->5\n",
        "# sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; 0->1->2,3,4->5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbp0WjNmifCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __create_indices(num_nodes):\n",
        "  \"\"\"\n",
        "  num_nodes - number of nodes per each stage\n",
        "\n",
        "  Calculate bits indices (startindex, length) for each stage \n",
        "  \"\"\"\n",
        "  l =  0                              # genome length\n",
        "  bits_indices, i = np.empty((0,2),dtype = np.int32), 0 \n",
        "  for Ks in num_nodes:\n",
        "    length = Ks * (Ks - 1)\n",
        "    bits_indices = np.vstack([bits_indices,[i, i + int(0.5 * length)]])\n",
        "    i += int(0.5 * length)\n",
        "    l += length\n",
        "  l = int(0.5 * l)\n",
        "  return bits_indices, l\n",
        "\n",
        "def CNN_build(stages, num_nodes, n_filters, individual, box_size, n_classes, verbose=0):\n",
        "  \"\"\"\n",
        "  stages - array of stage names\n",
        "  num_nodes - number of conv nodes per each stage\n",
        "  n_filters - number of filters per stage\n",
        "  individual - binary list representing individual architecture\n",
        "  box_size - expect input images like (box_size, box_size)\n",
        "  n_classes - number of output clasees\n",
        "\n",
        "  Build CNN architecture from the given list\n",
        "  \"\"\"\n",
        "\n",
        "  L = len(individual)\n",
        "  bits_indices, _L= __create_indices(num_nodes)\n",
        "  assert(L==_L)  # small check of the input individual connections info\n",
        "\n",
        "  if(verbose):\n",
        "    print('Starting network building..')\n",
        "  image_shape = (box_size, box_size, 1) \n",
        "  x_input = Input(shape=image_shape)  \n",
        "  previous = None # output from previous stage (initially input of CNN)\n",
        "  # Build stage by stage\n",
        "  for i, (s, Ks, n_filter) in enumerate(zip(stages, num_nodes, n_filters)):\n",
        "    if i==0:\n",
        "      previous = x_input\n",
        "    if(verbose):\n",
        "        print('\\nBuild layer', s, ':', Ks, 'nodes,', n_filter, 'filters.')\n",
        "    stage_indices = individual[bits_indices[i][0]:bits_indices[i][1]]                  # connection indices for current stage nodes; ex. [1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "    stage_indexes = np.split(range(int(Ks*(Ks-1)/2)),np.cumsum(range(Ks - 1)))[1:]     # connection indexes for current stage nodes; ex. [array([0]), array([1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]\n",
        "    stage_nodes = []                                                                   # nodes in a stage; ex. [vs1_1, vs1_2, vs1_3] (0, 4 are dummy)\n",
        "    to_him = list(np.zeros(Ks))                                                              # number of nodes to which i-th node points to\n",
        "    from_him = list(np.zeros(Ks))  \n",
        "    if(verbose):                                                          # number of nodes from i-th node to others\n",
        "        print('Stage indices:', stage_indices)\n",
        "        print('Stage indexes:', stage_indexes)\n",
        "\n",
        "    # default stage input node\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_0')\n",
        "    vs0 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_0')(previous)  # TODO\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_0')\n",
        "\n",
        "    # first node and trivial vs0->vs1\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_1')\n",
        "    vs1 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_1')(vs0) \n",
        "    stage_nodes += [vs1]\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_1')\n",
        "\n",
        "    for j in range(2, Ks+1):\n",
        "      name = 'v'+str(s)+'_'+str(j)  # name of the current node\n",
        "      if(verbose):\n",
        "        print('Building '+name)\n",
        "      tonode = stage_indices[stage_indexes[j-2][0]:stage_indexes[j-2][-1]+1]  # slice from stage_indices\n",
        "      input = None  # Input to current node\n",
        "      if sum(tonode)==0:  # empty input, connect to vs0\n",
        "        input = vs0\n",
        "      else:  # have some input\n",
        "        for k, connection in enumerate(tonode):\n",
        "          if connection==1:\n",
        "            from_him[k] += 1\n",
        "            to_him[j-1] += 1\n",
        "            if input is None:\n",
        "              input = stage_nodes[k]\n",
        "            else:\n",
        "              input = Add()([input, stage_nodes[k]])\n",
        "      v = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(j))(input) \n",
        "      stage_nodes += [v]\n",
        "      if(verbose):\n",
        "        print('Builded node '+name)\n",
        "\n",
        "    if(verbose):\n",
        "        print('from_him: ', from_him)\n",
        "        print('to_him: ', to_him)\n",
        "        print('stage_nodes: ', stage_nodes)\n",
        "\n",
        "    if sum(from_him)==sum(to_him)==0:  # only one convolution vs0\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vs0)\n",
        "    else:  # have some of the ordinary nodes\n",
        "        if(verbose):\n",
        "            print('Building '+'v'+str(s)+'_'+str(Ks+1))\n",
        "        input = None  # last node no output definitelly\n",
        "        for k in range(len(stage_nodes)):\n",
        "            if from_him[k]==0 and to_him[k]!=0:  # no connections from that node\n",
        "                if(verbose):\n",
        "                    print('Connect to last node node', k, ' ', stage_nodes[k])\n",
        "                if input is None:\n",
        "                    input = stage_nodes[k]\n",
        "                else:\n",
        "                    input = Add()([input, stage_nodes[k]])\n",
        "        vsKs = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(Ks+1))(input) # defaul stage output node\n",
        "        if(verbose):\n",
        "            print('Builded '+'v'+str(s)+str(Ks+1))\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vsKs)\n",
        "  \n",
        "  # Adding FC part of NN\n",
        "  x = Flatten(name='flatten')(previous)                                                                                       \n",
        "  x = Dense(units=32, activation='relu', name='next_to_last')(x)         \n",
        "  x = Dense(units=n_classes, activation='softmax', name='last')(x)\n",
        "\n",
        "  # Creaate Model\n",
        "  model = Model(inputs=x_input, outputs=x, name='individual')\n",
        "  if(verbose):\n",
        "    print('Created Network builded.')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FND-j48Zie1-",
        "colab_type": "code",
        "outputId": "2feee706-77fb-474a-ac88-deb21b49ecab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3hhN7e_SZwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  Compile forwarded model, and return it compiled\n",
        "  \"\"\"\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=1e-3), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFypCPpShN2",
        "colab_type": "code",
        "outputId": "37b83304-d85a-495c-c288-e1f51b2058ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_TzENOzS2vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  plot forwarded model architecture\n",
        "  \"\"\"\n",
        "  from keras.utils import plot_model\n",
        "\n",
        "  print('Model summary: ')\n",
        "  model.summary()\n",
        "  plot_model(model, to_file='model.png')\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rA6YX8CTMcF",
        "colab_type": "code",
        "outputId": "ba674182-3eca-4557-8111-15184e925c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model summary: \n",
            "Model: \"individual\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vs1_0 (Conv2D)                  (None, 28, 28, 32)   320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "vs1_1 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_2 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_3 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_4 (Conv2D)                  (None, 28, 28, 32)   9248        vs1_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 32)   0           vs1_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_0 (Conv2D)                  (None, 14, 14, 48)   13872       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "vs2_1 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_2 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_3 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 14, 14, 48)   0           vs2_2[0][0]                      \n",
            "                                                                 vs2_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_4 (Conv2D)                  (None, 14, 14, 48)   20784       vs2_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 14, 14, 48)   0           add_1[0][0]                      \n",
            "                                                                 vs2_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_5 (Conv2D)                  (None, 14, 14, 48)   20784       add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 48)     0           vs2_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_0 (Conv2D)                  (None, 7, 7, 64)     27712       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "vs3_1 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_2 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_3 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_4 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_5 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_6 (Conv2D)                  (None, 7, 7, 64)     36928       vs3_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           vs3_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "next_to_last (Dense)            (None, 32)           32800       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "last (Dense)                    (None, 10)           330         next_to_last[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 437,514\n",
            "Trainable params: 437,514\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAH-z7QeUFqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose=1, validation_split=0.0, callbacks=[]):\n",
        "    \"\"\"\n",
        "    model - compiled CNN model\n",
        "    x_train - input images\n",
        "    y_train - input labels (one hot encoded)\n",
        "    x_test - test images\n",
        "    y_test - test labels (one hot encoded)\n",
        "    epochs - number of epochs\n",
        "    batch_size - mini batch size of training\n",
        "    verbose - verbose of training\n",
        "    validation_split - data split used for validation\n",
        "\n",
        "    Train forwrded model. Returns (train history, model obtained test accuracy)\n",
        "    \"\"\"\n",
        "    if (epochs == 0):\n",
        "        # for faster testing\n",
        "        # print('only eval, without training')\n",
        "        return None, model.evaluate(x_test, y_test)\n",
        "    # print('training and eval')\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split=validation_split, callbacks=callbacks)\n",
        "    return history, model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv7hRnZHWK9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history, result = train_model(model, x_train, y_train, x_test, y_test, 1, 1024, 1)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWrFN-yTkW2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYRxJ53XkYwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOiF1-tx74y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toPseudo(model):\n",
        "    \"\"\"\n",
        "    model - input CNN model\n",
        "    return - structure that describe model weights for later from that model loading\n",
        "    \"\"\"\n",
        "    return [(layer.get_config()['name'], layer.get_weights()) for layer in model.layers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlLUG0GedB1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadWeights(toModel, fromPseudoModel, numSameStages, numNodesPerStage):\n",
        "    '''\n",
        "    toModel: keras model for which to load weights\n",
        "    fromPseudoModel: list of (layer name, layer weights) from which to load weights\n",
        "    numSameStages: number of first same stages; can be 0, 1, 2, 3; trivial cases 0 and 3\n",
        "    numNodesPerStage: number of nodes per stage; ex. [3,4,5]\n",
        "\n",
        "    You need to call model.compile. This can be done either before or after the model.load_weights \n",
        "    call but must be after the model architecture is specified and before the model.predict call.\n",
        "    returns the model with loaded weights from file\n",
        "\n",
        "    IMPORTANT: toModel and fromModel MUST HAVE exactly the same architecture on first numSameStages! (same indices eqvivalently)\n",
        "    TODO: add critical pool if want more pooling operations in architecture\n",
        "    '''\n",
        "    assert numSameStages<=len(numNodesPerStage)\n",
        "    allflag = (numSameStages==len(numNodesPerStage))  # to load all weights\n",
        "    for i, (name, weights) in enumerate(fromPseudoModel):\n",
        "        #print(name, weights) \n",
        "\n",
        "        if numSameStages==0:\n",
        "            if not allflag:\n",
        "                break\n",
        "\n",
        "        toModel.layers[i].set_weights(weights)\n",
        "\n",
        "        if 'max_pooling' in name:\n",
        "            numSameStages-=1         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kdgjBhwRq2c",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEWPhebDtHe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import random, seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFU56u2otadr",
        "colab_type": "code",
        "outputId": "56e54ab8-8972-41f3-b34d-c6b82d355712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.random.seed(42) # reproducible\n",
        "class Genetic:\n",
        "    def __init__(self, pc, qc, pm, qm, numGen, numInd, geneLength, bitIndices):\n",
        "        ''' \n",
        "        pc: probability of crossover - whether crossover process begins\n",
        "        qc: probability of stages being exchanged - while in crossover process\n",
        "        pm: probability of mutation - whether mutation process begins\n",
        "        qm: probability of a per bit mutation - while in mutation process\n",
        "        numGen: number of generations\n",
        "        numInd: number of individuals\n",
        "        bitIndices: 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "        '''\n",
        "        self.pc = pc\n",
        "        self.qc = qc\n",
        "        self.pm = pm\n",
        "        self.qm = qm\n",
        "        self.numGen = numGen\n",
        "        self.currNumGen = 0\n",
        "        self.numInd = numInd\n",
        "        self.geneLength = geneLength\n",
        "        self.bitIndices = bitIndices\n",
        "        self.oldGen = None\n",
        "        self.initFirstGeneration()\n",
        "    \n",
        "    def initFirstGeneration(self):\n",
        "        ''' \n",
        "        initializes the first generation\n",
        "        '''\n",
        "        self.currNumGen = 1\n",
        "        self.currGen = np.random.randint(0, 2, (self.numInd, self.geneLength))\n",
        "\n",
        "    def getCurrentGeneration(self):\n",
        "        return self.currGen\n",
        "\n",
        "    def selection(self, fitness):\n",
        "        '''\n",
        "        returns indices of individuals that survived the selection\n",
        "        '''\n",
        "        npfit = np.array(fitness)\n",
        "        proba = npfit - np.min(npfit) # removes the worst one\n",
        "        proba = proba / np.sum(proba)\n",
        "\n",
        "        return np.random.choice(self.numInd, replace=True, size=self.numInd, p=proba)\n",
        "\n",
        "    def mutate(self, newGen, indices):\n",
        "        '''\n",
        "        mutates individuals in newGen on positions where indices are 0 (because those individuals didn't mate)\n",
        "        '''\n",
        "        for i, had in enumerate(indices):\n",
        "            if had == 0 and np.random.random() <= self.pm:\n",
        "                newGen[i] = self.mutateIndividual(self.currGen[i])\n",
        "            else:\n",
        "                newGen[i] = np.copy(self.currGen[i])\n",
        "\n",
        "    def mutateIndividual(self, individual):\n",
        "        '''\n",
        "        returns a new individual by mutating the given one\n",
        "        '''\n",
        "        mut = np.copy(individual)\n",
        "        for i, val in enumerate(mut):\n",
        "            if np.random.random() <= self.qm:\n",
        "                mut[i] = 1 - mut[i]\n",
        "\n",
        "        return mut\n",
        "\n",
        "    def crossover(self, individualA, individualB):\n",
        "        '''\n",
        "        returns two new individuals by performing crossover on two given individuals.\n",
        "        it takes care to only swap the whole segments, and not bits within segments\n",
        "        '''\n",
        "        a = np.copy(individualA)\n",
        "        b = np.copy(individualB)\n",
        "\n",
        "        for segment in self.bitIndices:\n",
        "            if np.random.random() <= self.qc:\n",
        "                start = segment[0]\n",
        "                end = segment[1]\n",
        "                tmpa = np.copy(a[start:end])\n",
        "                a[start:end] = b[start:end]\n",
        "                b[start:end] = tmpa\n",
        "\n",
        "        return a, b\n",
        "\n",
        "    def newGeneration(self, fitness, verbose=False):\n",
        "        '''\n",
        "        creates a new generation of individuals by selection, crossover, and mutation \n",
        "        of previous generation. Selection is based on the rulet method\n",
        "\n",
        "        fitness - np array of fitness metrics for all individuals, based on which to construct rulet\n",
        "        '''\n",
        "        self.currNumGen += 1\n",
        "        if self.currNumGen > self.numGen:\n",
        "            raise Exception(f\"currNumGen > numGen, {self.currNumGen} > {self.numGen}\")\n",
        "        newGenIdx = self.selection(fitness)\n",
        "        if verbose:\n",
        "            print(f'survived selection: {newGenIdx}')\n",
        "        newGen = np.zeros((self.numInd, self.geneLength), dtype='int32') # np matrix of new generation\n",
        "        hadCrossoverIdx = np.zeros(self.numInd) # tracks if an individial had a crossover\n",
        "        assert(len(newGen)%2 == 0)\n",
        "        # for each pair of neighbours, try crossover\n",
        "        for i in range(0, len(newGen), 2):\n",
        "            if np.random.random() <= self.pc:\n",
        "                newGen[i], newGen[i+1] = self.crossover(self.currGen[newGenIdx[i]], self.currGen[newGenIdx[i+1]])\n",
        "                hadCrossoverIdx[i] = 1\n",
        "                hadCrossoverIdx[i+1] = 1\n",
        "\n",
        "        self.mutate(newGen, hadCrossoverIdx)\n",
        "        \n",
        "        self.oldGen = self.currGen\n",
        "        self.currGen = newGen\n",
        "\n",
        "    def findIndividualsWithSameRoots(self, verbose=False):\n",
        "        '''\n",
        "        for each individual in a new generation finds the indices of individuals in the old generation \n",
        "        which had the same firts n segments\n",
        "\n",
        "        returns a list, where i-th element has a touple (listOfParentsWithSameSegment, numberOfSameSegments)\n",
        "        '''\n",
        "        parentsAndNumSegments = []\n",
        "        for indiv in self.currGen:\n",
        "            parents, numSameSegments = self.hasSameRoots(indiv)\n",
        "            parentsAndNumSegments.append((parents, numSameSegments))\n",
        "            if numSameSegments > 0 and verbose:\n",
        "                print('individual:',indiv)\n",
        "                print(f'has the same {numSameSegments} first segments as:')\n",
        "                print(parents)\n",
        "                print(f'e.g: {self.oldGen[parents[0]]}')\n",
        "\n",
        "        return parentsAndNumSegments\n",
        "\n",
        "\n",
        "    def hasSameRoots(self, individual):\n",
        "        '''\n",
        "        returns indices of individuals from last generations which have the biggest same root as the\n",
        "        given individual, and returns the number of segments which are the same (starting from the first)\n",
        "        '''\n",
        "        for i, segment in reversed(list(enumerate(self.bitIndices))):\n",
        "            nColumns = segment[1]\n",
        "            # print('bools',(self.oldGen[:,:nColumns] == individual[:nColumns]))\n",
        "            # print('oldgen:',self.oldGen)\n",
        "            # print('ind:', individual)\n",
        "            # find rows which have the individual (only look at the part of the colums)\n",
        "            matchedRows = (self.oldGen[:,:nColumns] == individual[:nColumns]).all(axis=1)\n",
        "            sameRootIndividuals = np.where(matchedRows)[0]\n",
        "            if sameRootIndividuals.size > 0:\n",
        "                return sameRootIndividuals, i+1\n",
        "\n",
        "        return np.empty(0), 0\n",
        "\n",
        "geneLength = L\n",
        "gen = Genetic(0.2, 0.3, 0.8, 0.1, 10, 10, geneLength, BITS_INDICES)\n",
        "print('mean1', np.mean(gen.getCurrentGeneration()))\n",
        "gen.newGeneration(np.random.random(10))\n",
        "print('mean2', np.mean(gen.getCurrentGeneration()))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean1 0.5105263157894737\n",
            "mean2 0.5157894736842106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5onkJV5pZ4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import types\n",
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "\n",
        "BIT_INDICES, L = __create_indices(NUM_NODES)\n",
        "# params is used as function parameter throught the core algorithm\n",
        "params = types.SimpleNamespace()\n",
        "params.pc = 0.2 # pc: probability of crossover - whether crossover process begins\n",
        "params.pm = 0.8 # pm: probability of mutation - whether mutation process begins\n",
        "params.qc = 0.3 # qc: probability of stages being exchanged - while in crossover process\n",
        "params.qm = 0.1 # qm: probability of a per bit mutation - while in mutation process\n",
        "params.geneLength = L # number of bits needed to encode the gene\n",
        "params.numGenerations = 20 # 10 # number of generations\n",
        "params.numIndividuals = 20 # 10 # number of individuals\n",
        "params.bitIndices = BITS_INDICES # 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "params.boxSize = box_size # width and height of the input\n",
        "params.numClasses = 10 # number of output classes\n",
        "params.stageNames = STAGES # list containing names of stages\n",
        "params.numFilters = FILTERS # list containing number of filters per stage\n",
        "params.numNodes = NUM_NODES # number of nodes within each stage\n",
        "params.xTrain = x_train # training set data\n",
        "params.yTrain = y_train # training set labels\n",
        "params.xTest = x_test # test set data\n",
        "params.yTest = y_test # test set labels\n",
        "params.epochs = 5 # default number of epochs to train in the first generation\n",
        "params.batchSize = 256\n",
        "params.verbose = 1 \n",
        "params.numInheritedStagesToEpochs = { # maps number of inherited stages into \n",
        "                                      # number of needed epochs to train it\n",
        "                                      # all: 0epoch, 1stage: 4epoch, 2stage: 3epoch\n",
        "    0: params.epochs,\n",
        "    1: params.epochs - 1,\n",
        "    2: params.epochs - 2,\n",
        "    3: 0\n",
        "}\n",
        "params.isModification = False\n",
        "assert(params.numIndividuals%2 == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx7G8lmn0Tso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inheritWeightsFromParents(model, params, parentSegmentTuple, lastGenWeights):\n",
        "    '''\n",
        "    returns model, howManyEpochsToTrain, parentIndex\n",
        "    returns the model which inherits weights from last generation if possible \n",
        "    (and if params.isModification=true)\n",
        "    '''\n",
        "    parents = parentSegmentTuple[0] \n",
        "    numSegments = parentSegmentTuple[1]\n",
        "    epochsToTrain = params.numInheritedStagesToEpochs[numSegments] if params.isModification else params.epochs\n",
        "    trainForEpochs = epochsToTrain\n",
        "    parentIndex = None\n",
        "    if params.isModification and numSegments > 0:\n",
        "        parentIndex = parents[0] # TODO this is a list, might take the parent with the best fitness\n",
        "        loadWeights(model, lastGenWeights[parentIndex], numSegments, params.numNodes)\n",
        "    if model is None:\n",
        "        print('\\t\\t\\t\\ MODEL IS NONE!')\n",
        "    return model, trainForEpochs, parentIndex\n",
        "\n",
        "def createAndEvaluateModel(params, individual, parentSegmentTuple, oldNetworkWeights, lastGenFitness, verbose):\n",
        "    '''\n",
        "    This clears the session to avoid slowdown after training many instances\n",
        "\n",
        "    returns its weights and fitness\n",
        "    '''\n",
        "    # build model\n",
        "    model = CNN_build(params.stageNames, params.numNodes, params.numFilters, individual, params.boxSize, params.numClasses, verbose=0)\n",
        "    model = compile_model(model)\n",
        "    # inherit weights\n",
        "    if oldNetworkWeights is None:\n",
        "        assert(lastGenFitness is None)\n",
        "        assert(parentSegmentTuple is None)\n",
        "        trainForEpochs = params.epochs\n",
        "    else:\n",
        "        assert(lastGenFitness is not None)\n",
        "        assert(parentSegmentTuple is not None)\n",
        "        model, trainForEpochs, parentIndex = inheritWeightsFromParents(model, params, parentSegmentTuple, oldNetworkWeights)\n",
        "\n",
        "    # train or copy from last gen\n",
        "    if trainForEpochs == 0:\n",
        "        assert(lastGenFitness is not None)\n",
        "        assert(oldNetworkWeights is not None)\n",
        "        print('\\t\\t\\t\\Skipping training because model is the same as last gen')\n",
        "        fitness = lastGenFitness[parentIndex]\n",
        "        pseudoWeights = oldNetworkWeights[parentIndex]\n",
        "    else:\n",
        "        history, lossAndAcc = train_model(model, params.xTrain, params.yTrain, params.xTest,\n",
        "                    params.yTest, trainForEpochs,\n",
        "                    params.batchSize, verbose=verbose, validation_split=0.0) \n",
        "        fitness = lossAndAcc[1]\n",
        "        pseudoWeights = toPseudo(model)\n",
        "\n",
        "    K.clear_session()\n",
        "    return pseudoWeights, fitness\n",
        "    \n",
        "def executeSelectionWithGeneticAlgorithm(params):\n",
        "    ''' \n",
        "    args: params object defined above\n",
        "\n",
        "    returns individuals in the last generation, index of the best individual, and their fitnesses, and np matrix of all fitnesses\n",
        "    '''\n",
        "    genetic = Genetic(params.pc, params.qc, params.pm, params.qm, params.numGenerations, params.numIndividuals, params.geneLength, params.bitIndices)\n",
        "    oldNetworksWeights = None\n",
        "    allFitnesses = np.zeros((params.numGenerations, params.numIndividuals))\n",
        "    for i in range(params.numGenerations):\n",
        "        nthGen = i+1\n",
        "        print(f'\\t\\t\\tStarting generation {nthGen}...')\n",
        "        print(f'Creating models from individuals...')\n",
        "        individuals = genetic.getCurrentGeneration()\n",
        "        # print(\"current generation:\", individuals)\n",
        "        newNetworksWeights = []\n",
        "        if i > 0:\n",
        "            print(f'findIndividualsWithSameRoots...')\n",
        "            parentSegmentTuples = genetic.findIndividualsWithSameRoots()\n",
        "            lastGenFitness = allFitnesses[i-1]\n",
        "        else:\n",
        "            parentSegmentTuples = None \n",
        "            lastGenFitness = None\n",
        "        \n",
        "        currGenFitness = []\n",
        "        for j, individual in enumerate(individuals):\n",
        "            print(f\"Creating and evaluating indiv #{j}\")\n",
        "            parentSegmentTuple = None if parentSegmentTuples is None else parentSegmentTuples[j]\n",
        "            newNetWeight, fitness = createAndEvaluateModel(params, individual, parentSegmentTuple,\n",
        "                                                           oldNetworksWeights, lastGenFitness, params.verbose)\n",
        "            newNetworksWeights.append(newNetWeight)\n",
        "            currGenFitness.append(fitness)\n",
        "\n",
        "        currGenFitness = np.array(currGenFitness) \n",
        "        allFitnesses[i] = currGenFitness\n",
        "        print(f'this gen fitnesses: {currGenFitness}')\n",
        "        if i < params.numGenerations - 1:\n",
        "            genetic.newGeneration(fitness=currGenFitness)\n",
        "            oldNetworksWeights = newNetworksWeights\n",
        "\n",
        "    bestIdx = np.argmax(currGenFitness)\n",
        "    print(f'The best individual {individuals[bestIdx]} had fitness (accuracy): {currGenFitness[bestIdx]}')\n",
        "\n",
        "    return individuals, bestIdx, currGenFitness, allFitnesses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdSVY0xOnvKS",
        "colab_type": "text"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqXfftoHnfM",
        "colab_type": "code",
        "outputId": "a84088ee-116c-46d5-d942-2f2343665b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = False\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "current generation: [[0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0]\n",
            " [1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1]\n",
            " [0 1 1 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 1]]\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 1.3887 - acc: 0.5143\n",
            "1000/1000 [==============================] - 0s 383us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 547us/step - loss: 1.1660 - acc: 0.6140\n",
            "1000/1000 [==============================] - 0s 385us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 3s 303us/step - loss: 1.4043 - acc: 0.5091\n",
            "1000/1000 [==============================] - 0s 273us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 537us/step - loss: 1.6198 - acc: 0.4403\n",
            "1000/1000 [==============================] - 0s 370us/step\n",
            "this gen fitnesses: [0.647 0.868 0.826 0.731]\n",
            "proba: [0.         0.45661157 0.36983471 0.17355372]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "current generation: [[0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0]\n",
            " [0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1]\n",
            " [1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 0]]\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 501us/step - loss: 1.2185 - acc: 0.5790\n",
            "1000/1000 [==============================] - 0s 373us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 458us/step - loss: 1.4610 - acc: 0.5015\n",
            "1000/1000 [==============================] - 0s 339us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 3s 300us/step - loss: 1.1615 - acc: 0.5936\n",
            "1000/1000 [==============================] - 0s 267us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 493us/step - loss: 1.5652 - acc: 0.4690\n",
            "1000/1000 [==============================] - 0s 356us/step\n",
            "this gen fitnesses: [0.796 0.725 0.876 0.754]\n",
            "proba: [0.28286853 0.         0.60159363 0.11553785]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "current generation: [[0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0]\n",
            " [0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1]\n",
            " [1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0]]\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 498us/step - loss: 1.3621 - acc: 0.5132\n",
            "1000/1000 [==============================] - 0s 379us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 1.3176 - acc: 0.5419\n",
            "1000/1000 [==============================] - 0s 324us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 3s 316us/step - loss: 1.4336 - acc: 0.4939\n",
            "1000/1000 [==============================] - 0s 286us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 5s 512us/step - loss: 1.7660 - acc: 0.3976\n",
            "1000/1000 [==============================] - 0s 358us/step\n",
            "this gen fitnesses: [0.795 0.762 0.768 0.748]\n",
            "The best individual [0 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 0] had fitness (accuracy): 0.795\n",
            "CPU times: user 1min 7s, sys: 8.55 s, total: 1min 15s\n",
            "Wall time: 1min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAAN4N9PnlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotEvolutionProgress(allFit, takeBestN):\n",
        "    topn = np.zeros((params.numGenerations, takeBestN))\n",
        "    for i, row in enumerate(allFit):\n",
        "        row.sort()\n",
        "        topn[i] = row[-takeBestN:]\n",
        "\n",
        "    for i, col in reversed(list(enumerate(topn.T))):\n",
        "        plt.plot(range(1, params.numGenerations+1), col, label=f'#{takeBestN - i}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "# plotEvolutionProgress(np.random.randn(params.numGenerations, params.numIndividuals), takeBestN = 2)\n",
        "plotEvolutionProgress(allFitnesses, takeBestN = 10)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs1lDrRlnywQ",
        "colab_type": "text"
      },
      "source": [
        "## Modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHdNEUGn1HP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "845830d0-ae5a-49be-9f77-30459855b8e3"
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 506us/step - loss: 1.5650 - acc: 0.4514\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.3758 - acc: 0.8976\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.2201 - acc: 0.9410\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.1203 - acc: 0.9659\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.1024 - acc: 0.9723\n",
            "1000/1000 [==============================] - 0s 373us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 560us/step - loss: 1.2026 - acc: 0.5906\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.2421 - acc: 0.9301\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1635 - acc: 0.9521\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1609 - acc: 0.9503\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0882 - acc: 0.9722\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 331us/step - loss: 1.1746 - acc: 0.5917\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.2475 - acc: 0.9250\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1367 - acc: 0.9577\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 208us/step - loss: 0.1380 - acc: 0.9585\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 218us/step - loss: 0.0705 - acc: 0.9798\n",
            "1000/1000 [==============================] - 0s 279us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 521us/step - loss: 1.1273 - acc: 0.6225\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.2348 - acc: 0.9304\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.1672 - acc: 0.9512\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.0960 - acc: 0.9710\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 405us/step - loss: 0.0718 - acc: 0.9765\n",
            "1000/1000 [==============================] - 0s 392us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 509us/step - loss: 1.3394 - acc: 0.5244\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.2629 - acc: 0.9205\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1568 - acc: 0.9543\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 379us/step - loss: 0.0981 - acc: 0.9703\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 377us/step - loss: 0.0736 - acc: 0.9776\n",
            "1000/1000 [==============================] - 0s 359us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 1.5237 - acc: 0.4643\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.4829 - acc: 0.8629\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.2270 - acc: 0.9363\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1922 - acc: 0.9424\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1023 - acc: 0.9705\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 532us/step - loss: 1.3216 - acc: 0.5672\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.2878 - acc: 0.9166\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1557 - acc: 0.9537\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.0995 - acc: 0.9726\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.0602 - acc: 0.9837\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 522us/step - loss: 1.5483 - acc: 0.4682\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.3932 - acc: 0.8854\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.2267 - acc: 0.9358\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.1392 - acc: 0.9584\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.0934 - acc: 0.9714\n",
            "1000/1000 [==============================] - 0s 397us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 506us/step - loss: 1.4043 - acc: 0.5044\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.3206 - acc: 0.9055\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 389us/step - loss: 0.2042 - acc: 0.9375\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.1068 - acc: 0.9692\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.0776 - acc: 0.9771\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-00062db08d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'np.random.seed(43) # reproducible\\nparams.isModification = True\\nlastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-1316696d6e4a>\u001b[0m in \u001b[0;36mexecuteSelectionWithGeneticAlgorithm\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mparentSegmentTuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparentSegmentTuples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparentSegmentTuples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             newNetWeight, fitness = createAndEvaluateModel(params, individual, parentSegmentTuple,\n\u001b[0;32m---> 84\u001b[0;31m                                                            oldNetworksWeights, lastGenFitness, params.verbose)\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mnewNetworksWeights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewNetWeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mcurrGenFitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-1316696d6e4a>\u001b[0m in \u001b[0;36mcreateAndEvaluateModel\u001b[0;34m(params, individual, parentSegmentTuple, oldNetworkWeights, lastGenFitness, verbose)\u001b[0m\n\u001b[1;32m     46\u001b[0m         history, lossAndAcc = train_model(model, params.xTrain, params.yTrain, params.xTest,\n\u001b[1;32m     47\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainForEpochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     params.batchSize, verbose=verbose, validation_split=0.0) \n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossAndAcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpseudoWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoPseudo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-9d2c02af1e7e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose, validation_split, callbacks)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print('training and eval')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    511\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    513\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    514\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvhat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvhats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mm_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mv_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0mvhat_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_run_op\u001b[0;34m(a, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_run_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_oper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    922\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mr_binary_op_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    269\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    270\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 271\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    272\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3409\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3411\u001b[0;31m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_NodeDef\u001b[0;34m(op_type, name, device, attrs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNd7V9ajqPkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 3)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuXJhy_ieyQ0",
        "colab_type": "text"
      },
      "source": [
        "# Manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaIZak9OZnqx",
        "colab_type": "code",
        "outputId": "48fbf769-f115-47bc-c0b0-16d245912205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "CPU times: user 369 ms, sys: 156 ms, total: 525 ms\n",
            "Wall time: 1.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwTVIW1He7kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSY8vpXfM8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOeVitcfOyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_90wxfdfRXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGteF_JxgBak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1, mode='min', cooldown=1)\n",
        "estop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmqrhD9fbnX",
        "colab_type": "code",
        "outputId": "648816a3-c608-4888-a1f8-fd475b0145bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "%%time\n",
        "history, result = train_model(model, x_train, y_train, x_test, y_test, 20, 256, 1, 0.2, [reducelr, estop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 11s 220us/step - loss: 0.4362 - acc: 0.8560 - val_loss: 0.0875 - val_acc: 0.9751\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0686 - acc: 0.9800 - val_loss: 0.0523 - val_acc: 0.9843\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0453 - acc: 0.9864 - val_loss: 0.0512 - val_acc: 0.9837\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0385 - val_acc: 0.9890\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9904\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0324 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0268 - val_acc: 0.9924\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0307 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0294 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 8.3924e-04 - acc: 0.9998 - val_loss: 0.0312 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 9s 185us/step - loss: 3.9299e-04 - acc: 0.9999 - val_loss: 0.0314 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 [==============================] - 1s 97us/step\n",
            "CPU times: user 1min 2s, sys: 17.5 s, total: 1min 20s\n",
            "Wall time: 1min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMYjil9fjP13",
        "colab_type": "code",
        "outputId": "5c1f5aa4-1107-4bd2-e5e1-2a0ca19d9541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8214303073883056, 0.393]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq26Lc0ujT2Y",
        "colab_type": "code",
        "outputId": "19bbfc80-5d34-4af1-ce4b-7a2671f20c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "epochs = history.epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.title('Loss/Val loss curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(epochs, loss, color='red', label='training')\n",
        "plt.plot(epochs, val_loss, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-2ec98f4bc73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss/Val loss curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K8N0nlVjZYp",
        "colab_type": "code",
        "outputId": "86feb4c6-2351-4be3-c5b5-989dd4535267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.title('Acc/Val acc curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(epochs, acc, color='red', label='training')\n",
        "plt.plot(epochs, val_acc, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-e2eb1a72036d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Acc/Val acc curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1NovR1tAF3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO:\n",
        "# K.clear_session(), but model weights need to be saved first, and passed to inherit weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVp4A8xQU-fb",
        "colab_type": "text"
      },
      "source": [
        "# Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZObn4NLVDK0",
        "colab_type": "text"
      },
      "source": [
        "* Google Schoolar Searches: [link](https://scholar.google.com/scholar?hl=sr&as_sdt=0%2C5&q=genetic+cnn+handwritting&btnG=)\n",
        "\n",
        "* Fokus na rad: \n",
        " * .pdf: [link](https://arxiv.org/abs/1703.01513)\n",
        " * github: [link](https://arxiv.org/abs/1703.01513)\n",
        "* Dodatno rad:\n",
        " *  .pdf: [link](https://arxiv.org/pdf/1710.10741.pdf)\n",
        " * Clanak na netu: [link](https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164)\n",
        "* Ako sami implementiramo: [link](https://github.com/joeddav/devol/blob/master/devol/devol.py)\n"
      ]
    }
  ]
}