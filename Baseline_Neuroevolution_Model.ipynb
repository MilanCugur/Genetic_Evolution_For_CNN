{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Neuroevolution_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hVp4A8xQU-fb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilanCugur/Neuroevolution-LocalSearch/blob/master/Baseline_Neuroevolution_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfJ-fn_XLnLU",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DoSLvx2LdSl",
        "colab_type": "code",
        "outputId": "31a72ad9-c126-4bbf-a86c-6f1aedd8ec2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoTzVEoMfV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_dataset(path):\n",
        "  \"\"\"\n",
        "  extract DoubledMNIST dataset\n",
        "  Argument: path to .zip file with the dataset\n",
        "  Return value: x_train, y_train, x_test, y_test lists of numpy arrays \n",
        "  \n",
        "  (DoubledMNIST dataset: train size 120k images 56x56, test size 20k images 56x56)\n",
        "  \"\"\"\n",
        "  # import libraries\n",
        "  import os                     # for basic os operations\n",
        "  from zipfile import ZipFile \n",
        "  from skimage import io\n",
        "  import numpy as np\n",
        "  import shutil\n",
        "  \n",
        "  if not path.endswith('.zip'):\n",
        "    raise ValueError(\"Error: path is not '.zip' file\")\n",
        "  \n",
        "  archive = ZipFile(path, 'r')  # extract\n",
        "  archive.extractall('./DoubledMNIST')\n",
        "  archive.close()\n",
        "  del archive\n",
        "  \n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/train'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/train', file))\n",
        "    x_train.append(np.array(img))\n",
        "    y_train.append(int(file.split('_')[1]))\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/test'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/test', file))\n",
        "    x_test.append(np.array(img))\n",
        "    y_test.append(int(file.split('_')[1]))\n",
        "    \n",
        "  shutil.rmtree('./DoubledMNIST')\n",
        "  return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bKQ505PMxBn",
        "colab_type": "code",
        "outputId": "a7f631be-df57-45f3-c06a-56fddfc68231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "_x_train, _y_train, _x_test, _y_test = extract_dataset('./drive/My Drive/ni_sem/DoubledMNIST.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 5s, sys: 16.4 s, total: 1min 21s\n",
            "Wall time: 1min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5K7U7oOg4_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOX_SIZE = 56"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8PNO4_WwR-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "y_train = to_categorical(_y_train)[:]\n",
        "y_test = to_categorical(_y_test)[:]\n",
        "\n",
        "x_train = np.array(_x_train).astype('float32')[:]\n",
        "x_train /= 255\n",
        "x_train = np.reshape(x_train,[-1, BOX_SIZE, BOX_SIZE, 1])\n",
        "\n",
        "x_test = np.array(_x_test).astype('float32')[:]\n",
        "x_test /= 255\n",
        "x_test = np.reshape(x_test, [-1, BOX_SIZE, BOX_SIZE, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKqAN0w0vuPx",
        "colab_type": "code",
        "outputId": "78914ba2-af2f-40a2-cbba-5d996978f702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape, x_train[0]"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((120000, 56, 56, 1),\n",
              " (20000, 56, 56, 1),\n",
              " (120000, 10),\n",
              " (20000, 10),\n",
              " array([[[1.        ],\n",
              "         [1.        ],\n",
              "         [1.        ],\n",
              "         ...,\n",
              "         [0.84313726],\n",
              "         [0.8627451 ],\n",
              "         [0.8745098 ]],\n",
              " \n",
              "        [[1.        ],\n",
              "         [1.        ],\n",
              "         [1.        ],\n",
              "         ...,\n",
              "         [0.8156863 ],\n",
              "         [0.8392157 ],\n",
              "         [0.85490197]],\n",
              " \n",
              "        [[1.        ],\n",
              "         [1.        ],\n",
              "         [1.        ],\n",
              "         ...,\n",
              "         [0.7764706 ],\n",
              "         [0.8039216 ],\n",
              "         [0.8235294 ]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.9607843 ],\n",
              "         [0.9529412 ],\n",
              "         [0.9411765 ],\n",
              "         ...,\n",
              "         [0.9019608 ],\n",
              "         [0.91764706],\n",
              "         [0.92941177]],\n",
              " \n",
              "        [[0.9843137 ],\n",
              "         [0.98039216],\n",
              "         [0.9764706 ],\n",
              "         ...,\n",
              "         [0.9607843 ],\n",
              "         [0.9647059 ],\n",
              "         [0.96862745]],\n",
              " \n",
              "        [[1.        ],\n",
              "         [1.        ],\n",
              "         [1.        ],\n",
              "         ...,\n",
              "         [1.        ],\n",
              "         [1.        ],\n",
              "         [1.        ]]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA_twWHcP-71",
        "colab_type": "code",
        "outputId": "339d7c90-0856-49a2-d715-158990ae98cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(x_train))  # size check\n",
        "print(len(y_train))\n",
        "print(len(x_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000\n",
            "120000\n",
            "20000\n",
            "20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErNLTXJiRXJI",
        "colab_type": "code",
        "outputId": "c966e530-1ce2-4db6-a0ba-2f40a341782a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "from matplotlib import pyplot as plt  # smal demonstration\n",
        "\n",
        "plt.imshow(x_test[19].reshape(BOX_SIZE, BOX_SIZE))\n",
        "plt.show()\n",
        "\n",
        "print(y_test[19])"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng90wQoINdsMICTbYDSMk/H/SgXi7+x4OdwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uungJ3ZiczL",
        "colab_type": "text"
      },
      "source": [
        "# CNN tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDESDezifHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "individual = [1, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbp0WjNmifCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __create_indices(num_nodes):\n",
        "  \"\"\"\n",
        "  num_nodes - number of nodes per each stage\n",
        "\n",
        "  Calculate bits indices (startindex, length) for each stage \n",
        "  \"\"\"\n",
        "  l =  0                              # genome length\n",
        "  bits_indices, i = np.empty((0,2),dtype = np.int32), 0 \n",
        "  for Ks in num_nodes:\n",
        "    length = Ks * (Ks - 1)\n",
        "    bits_indices = np.vstack([bits_indices,[i, i + int(0.5 * length)]])\n",
        "    i += int(0.5 * length)\n",
        "    l += length\n",
        "  l = int(0.5 * l)\n",
        "  return bits_indices, l\n",
        "\n",
        "def CNN_build(stages, num_nodes, n_filters, individual, box_size, n_classes):\n",
        "  \"\"\"\n",
        "  stages - array of stage names\n",
        "  num_nodes - number of conv nodes per each stage\n",
        "  n_filters - number of filters per stage\n",
        "  individual - binary list representing individual architecture\n",
        "  box_size - expect input images like (box_size, box_size)\n",
        "  n_classes - number of output clasees\n",
        "\n",
        "  Build CNN architecture from the given list\n",
        "  \"\"\"\n",
        "  from keras.models import Model\n",
        "  from keras.layers import Input, Conv2D, MaxPool2D, Add, Activation, Flatten, Concatenate, Dense, Dropout, BatchNormalization\n",
        "  from keras.optimizers import Adam  \n",
        "  from keras.losses import categorical_crossentropy\n",
        "  from keras.layers import LeakyReLU, concatenate\n",
        "  from keras.layers.advanced_activations import ReLU\n",
        "  from keras.initializers import glorot_normal\n",
        "  from keras.utils import to_categorical\n",
        "  from keras.utils import Sequence\n",
        "  from sklearn.utils import shuffle\n",
        "  import keras.backend as K\n",
        "  from keras.models import load_model  # Save model params\n",
        "\n",
        "  L = len(individual)\n",
        "  bits_indices, _L= __create_indices(num_nodes)\n",
        "  assert(L==_L)  # small check of the input individual connections info\n",
        "\n",
        "  print('Starting network building..')\n",
        "  image_shape = (BOX_SIZE, BOX_SIZE, 1) \n",
        "  x_input = Input(shape=image_shape)  \n",
        "  previous = None # output from previous stage (initially input of CNN)\n",
        "  # Build stage by stage\n",
        "  for i, (s, Ks, n_filter) in enumerate(zip(stages, num_nodes, n_filters)):\n",
        "    if i==0:\n",
        "      previous = x_input\n",
        "    print('\\nBuild layer', s, ':', Ks, 'nodes,', n_filter, 'filters.')\n",
        "    stage_indices = individual[bits_indices[i][0]:bits_indices[i][1]]                  # connection indices for current stage nodes; ex. [1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "    stage_indexes = np.split(range(int(Ks*(Ks-1)/2)),np.cumsum(range(Ks - 1)))[1:]     # connection indexes for current stage nodes; ex. [array([0]), array([1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]\n",
        "    stage_nodes = []                                                                   # nodes in a stage; ex. [vs1_1, vs1_2, vs1_3] (0, 4 are dummy)\n",
        "    to_him = np.zeros(Ks)                                                              # number of nodes to which i-th node points to\n",
        "    from_him = np.zeros(Ks)                                                            # number of nodes from i-th node to others\n",
        "    print('Stage indices:', stage_indices)\n",
        "    print('Stage indexes:', stage_indexes)\n",
        "\n",
        "    # default stage input node\n",
        "    print('Building '+'v'+str(s)+'_0')\n",
        "    vs0 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_0')(previous)  # TODO\n",
        "    print('Builded '+'v'+str(s)+'_0')\n",
        "\n",
        "    # first node and trivial vs0->vs1\n",
        "    print('Building '+'v'+str(s)+'_1')\n",
        "    vs1 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_1')(vs0) \n",
        "    stage_nodes += [vs1]\n",
        "    print('Builded '+'v'+str(s)+'_1')\n",
        "\n",
        "    for j in range(2, Ks+1):\n",
        "      name = 'v'+str(s)+'_'+str(j)  # name of the current node\n",
        "      print('Building '+name)\n",
        "      #print('Previous nodes: ', stage_nodes)\n",
        "      tonode = stage_indices[stage_indexes[j-2][0]:stage_indexes[j-2][-1]+1]  # slice from stage_indices\n",
        "      input = None  # Input to current node\n",
        "      if sum(tonode)==0:  # empty input, connect to vs0\n",
        "        input = vs0\n",
        "      else:  # have some input\n",
        "        for k, connection in enumerate(tonode):\n",
        "          if connection==1:\n",
        "            from_him[k] += 1\n",
        "            to_him[j-1] += 1\n",
        "            if input is None:\n",
        "              input = stage_nodes[k]\n",
        "            else:\n",
        "              input = Add()([input, stage_nodes[k]])\n",
        "        v = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(j))(input) \n",
        "        stage_nodes += [v]\n",
        "        print('Builded node '+name)\n",
        "\n",
        "    print('from_him: ', from_him)\n",
        "    print('to_him: ', to_him)\n",
        "\n",
        "    for k in range(Ks):\n",
        "      if from_him[k]==0 and to_him[k]==0:  # isolate nodes delete\n",
        "        del stage_nodes[k]\n",
        "\n",
        "    print('Building '+'v'+str(s)+'_'+str(Ks+1))\n",
        "    input = stage_nodes[-1]  # last node no output definitelly\n",
        "    for k in range(len(to_him)):\n",
        "      if from_him[k]==0:  # no connections from that node\n",
        "        input = Add()([input, stage_nodes[k]])\n",
        "    vsKs = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(Ks+1))(input) # defaul stage output node\n",
        "    print('Builded '+'v'+str(s)+str(Ks+1))\n",
        "    previous = MaxPool2D(pool_size=(2,2), padding='same')(vsKs)\n",
        "  \n",
        "  # Adding FC part of NN\n",
        "  x = Flatten(name='flatten')(previous)                                                                                       \n",
        "  x = Dense(units=32, activation='relu', name='next_to_last')(x)         \n",
        "  x = Dense(units=n_classes, activation='softmax', name='last')(x)\n",
        "\n",
        "  # Creaate Model\n",
        "  model = Model(inputs=x_input, outputs=x, name='individual')\n",
        "  print('Created Network builded.')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FND-j48Zie1-",
        "colab_type": "code",
        "outputId": "4dcbf157-b7bd-4878-e52c-9dae16c3b21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, individual, 56, 10)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting network building..\n",
            "\n",
            "Build layer s1 : 3 nodes, 32 filters.\n",
            "Stage indices: [1, 0, 1]\n",
            "Stage indexes: [array([0]), array([1, 2])]\n",
            "Building vs1_0\n",
            "Builded vs1_0\n",
            "Building vs1_1\n",
            "Builded vs1_1\n",
            "Building vs1_2\n",
            "Builded node vs1_2\n",
            "Building vs1_3\n",
            "Builded node vs1_3\n",
            "from_him:  [1. 1. 0.]\n",
            "to_him:  [0. 1. 1.]\n",
            "Building vs1_4\n",
            "Builded vs14\n",
            "\n",
            "Build layer s2 : 4 nodes, 48 filters.\n",
            "Stage indices: [1, 0, 1, 0, 0, 1]\n",
            "Stage indexes: [array([0]), array([1, 2]), array([3, 4, 5])]\n",
            "Building vs2_0\n",
            "Builded vs2_0\n",
            "Building vs2_1\n",
            "Builded vs2_1\n",
            "Building vs2_2\n",
            "Builded node vs2_2\n",
            "Building vs2_3\n",
            "Builded node vs2_3\n",
            "Building vs2_4\n",
            "Builded node vs2_4\n",
            "from_him:  [1. 1. 1. 0.]\n",
            "to_him:  [0. 1. 1. 1.]\n",
            "Building vs2_5\n",
            "Builded vs25\n",
            "\n",
            "Build layer s3 : 5 nodes, 64 filters.\n",
            "Stage indices: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
            "Stage indexes: [array([0]), array([1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]\n",
            "Building vs3_0\n",
            "Builded vs3_0\n",
            "Building vs3_1\n",
            "Builded vs3_1\n",
            "Building vs3_2\n",
            "Builded node vs3_2\n",
            "Building vs3_3\n",
            "Builded node vs3_3\n",
            "Building vs3_4\n",
            "Builded node vs3_4\n",
            "Building vs3_5\n",
            "Builded node vs3_5\n",
            "from_him:  [1. 1. 1. 1. 0.]\n",
            "to_him:  [0. 1. 1. 1. 1.]\n",
            "Building vs3_6\n",
            "Builded vs36\n",
            "Created Network builded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3hhN7e_SZwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  Compile forwarded model, and return it compiled\n",
        "  \"\"\"\n",
        "  from keras.optimizers import Adam  \n",
        "  from keras.losses import categorical_crossentropy\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=1e-3), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmFypCPpShN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_TzENOzS2vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualise_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  plot forwarded model architecture\n",
        "  \"\"\"\n",
        "  from keras.utils import plot_model\n",
        "\n",
        "  print('Model summary: ')\n",
        "  model.summary()\n",
        "  plot_model(model, to_file='model.png')\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rA6YX8CTMcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03f84340-d7b0-4c00-8c2d-a1fdd60ea2e2"
      },
      "source": [
        "visualise_model(model)"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model summary: \n",
            "Model: \"individual\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_99 (InputLayer)           (None, 56, 56, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vs1_0 (Conv2D)                  (None, 56, 56, 32)   320         input_99[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "vs1_1 (Conv2D)                  (None, 56, 56, 32)   9248        vs1_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_2 (Conv2D)                  (None, 56, 56, 32)   9248        vs1_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_3 (Conv2D)                  (None, 56, 56, 32)   9248        vs1_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_84 (Add)                    (None, 56, 56, 32)   0           vs1_3[0][0]                      \n",
            "                                                                 vs1_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_4 (Conv2D)                  (None, 56, 56, 32)   9248        add_84[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling2D) (None, 28, 28, 32)   0           vs1_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_0 (Conv2D)                  (None, 28, 28, 48)   13872       max_pooling2d_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "vs2_1 (Conv2D)                  (None, 28, 28, 48)   20784       vs2_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_2 (Conv2D)                  (None, 28, 28, 48)   20784       vs2_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_3 (Conv2D)                  (None, 28, 28, 48)   20784       vs2_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_4 (Conv2D)                  (None, 28, 28, 48)   20784       vs2_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_85 (Add)                    (None, 28, 28, 48)   0           vs2_4[0][0]                      \n",
            "                                                                 vs2_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_5 (Conv2D)                  (None, 28, 28, 48)   20784       add_85[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling2D) (None, 14, 14, 48)   0           vs2_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_0 (Conv2D)                  (None, 14, 14, 64)   27712       max_pooling2d_38[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "vs3_1 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_2 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_3 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_4 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_5 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_86 (Add)                    (None, 14, 14, 64)   0           vs3_5[0][0]                      \n",
            "                                                                 vs3_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_6 (Conv2D)                  (None, 14, 14, 64)   36928       add_86[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling2D) (None, 7, 7, 64)     0           vs3_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 3136)         0           max_pooling2d_39[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "next_to_last (Dense)            (None, 32)           100384      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "last (Dense)                    (None, 10)           330         next_to_last[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 505,098\n",
            "Trainable params: 505,098\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAH-z7QeUFqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose=1, validation_split=0.0):\n",
        "  \"\"\"\n",
        "  model - compiled CNN model\n",
        "  x_train - input images\n",
        "  y_train - input labels (one hot encoded)\n",
        "  x_test - test images\n",
        "  y_test - test labels (one hot encoded)\n",
        "  epochs - number of epochs\n",
        "  batch_size - mini batch size of training\n",
        "  verbose - verbose of training\n",
        "  validation_split - data split used for validation\n",
        "\n",
        "  Train forwrded model. Return (train history, model obtained test accuracy)\n",
        "  \"\"\"\n",
        "  history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "  return history, model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv7hRnZHWK9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "789f4516-f54a-4f2b-9843-b92a3977f4ed"
      },
      "source": [
        "train_model(model, x_train, y_train, x_test, y_test, 10, 50, 1)"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 95250/120000 [======================>.......] - ETA: 46s - loss: 0.1816 - acc: 0.9420"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-265-68c4444d2190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-264-f2811079a27b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose, validation_split)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mTrain\u001b[0m \u001b[0mforwrded\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mReturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobtained\u001b[0m \u001b[0mtest\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kdgjBhwRq2c",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEWPhebDtHe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimitrijevic kuca kod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxC3nzA0tajA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "\n",
        "L =  0                              # genome length\n",
        "BITS_INDICES, l_bpi = np.empty((0,2),dtype = np.int32), 0 # to keep track of bits for each stage S\n",
        "for Ks in NUM_NODES:\n",
        "    t = Ks * (Ks - 1)\n",
        "    BITS_INDICES = np.vstack([BITS_INDICES,[l_bpi, l_bpi + int(0.5 * t)]])\n",
        "    l_bpi += int(0.5 * t)\n",
        "    L += t\n",
        "L = int(0.5 * L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux8sKNQ-2LNh",
        "colab_type": "code",
        "outputId": "9e0d7792-c039-4606-ecf3-d32d1f3e1572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "BITS_INDICES, L"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0,  3],\n",
              "        [ 3,  9],\n",
              "        [ 9, 19]]), 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60yF_tVWDKI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_EPOCHS = 10 # T\n",
        "BATCH_SIZE = 20\n",
        "TOTAL_BATCHES = train_imgs.shape[0] // BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFU56u2otadr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87e4753e-9a79-4dd0-ba85-40366736c5c5"
      },
      "source": [
        "_y_train[:1000]"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 4,\n",
              " 1,\n",
              " 9,\n",
              " 8,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 9,\n",
              " 4,\n",
              " 3,\n",
              " 7,\n",
              " 0,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 8,\n",
              " 8,\n",
              " 5,\n",
              " 8,\n",
              " 3,\n",
              " 9,\n",
              " 5,\n",
              " 3,\n",
              " 7,\n",
              " 9,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 4,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 5,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 7,\n",
              " 6,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 7,\n",
              " 3,\n",
              " 3,\n",
              " 9,\n",
              " 8,\n",
              " 6,\n",
              " 7,\n",
              " 1,\n",
              " 5,\n",
              " 6,\n",
              " 8,\n",
              " 2,\n",
              " 3,\n",
              " 9,\n",
              " 8,\n",
              " 7,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 3,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 8,\n",
              " 8,\n",
              " 8,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 0,\n",
              " 8,\n",
              " 5,\n",
              " 4,\n",
              " 8,\n",
              " 5,\n",
              " 5,\n",
              " 8,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 6,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 3,\n",
              " 8,\n",
              " 1,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 7,\n",
              " 2,\n",
              " 9,\n",
              " 6,\n",
              " 1,\n",
              " 9,\n",
              " 7,\n",
              " 4,\n",
              " 6,\n",
              " 4,\n",
              " 3,\n",
              " 8,\n",
              " 9,\n",
              " 0,\n",
              " 9,\n",
              " 9,\n",
              " 6,\n",
              " 3,\n",
              " 8,\n",
              " 8,\n",
              " 4,\n",
              " 3,\n",
              " 8,\n",
              " 5,\n",
              " 2,\n",
              " 8,\n",
              " 0,\n",
              " 1,\n",
              " 9,\n",
              " 8,\n",
              " 1,\n",
              " 7,\n",
              " 9,\n",
              " 7,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 0,\n",
              " 4,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 2,\n",
              " 8,\n",
              " 9,\n",
              " 2,\n",
              " 4,\n",
              " 8,\n",
              " 4,\n",
              " 1,\n",
              " 6,\n",
              " 9,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 7,\n",
              " 0,\n",
              " 9,\n",
              " 0,\n",
              " 3,\n",
              " 7,\n",
              " 5,\n",
              " 3,\n",
              " 8,\n",
              " 5,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 9,\n",
              " 2,\n",
              " 1,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 8,\n",
              " 5,\n",
              " 9,\n",
              " 5,\n",
              " 0,\n",
              " 5,\n",
              " 5,\n",
              " 7,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 8,\n",
              " 5,\n",
              " 0,\n",
              " 7,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 2,\n",
              " 8,\n",
              " 3,\n",
              " 8,\n",
              " 0,\n",
              " 7,\n",
              " 9,\n",
              " 2,\n",
              " 2,\n",
              " 9,\n",
              " 0,\n",
              " 6,\n",
              " 1,\n",
              " 1,\n",
              " 6,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 5,\n",
              " 6,\n",
              " 6,\n",
              " 9,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 8,\n",
              " 4,\n",
              " 8,\n",
              " 9,\n",
              " 7,\n",
              " 3,\n",
              " 8,\n",
              " 9,\n",
              " 1,\n",
              " 7,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 7,\n",
              " 5,\n",
              " 1,\n",
              " 9,\n",
              " 8,\n",
              " 8,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 9,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 5,\n",
              " 7,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 4,\n",
              " 9,\n",
              " 5,\n",
              " 1,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 6,\n",
              " 7,\n",
              " 6,\n",
              " 3,\n",
              " 7,\n",
              " 4,\n",
              " 7,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 3,\n",
              " 4,\n",
              " 3,\n",
              " 9,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 8,\n",
              " 6,\n",
              " 4,\n",
              " 9,\n",
              " 3,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 6,\n",
              " 5,\n",
              " 5,\n",
              " 8,\n",
              " 0,\n",
              " 2,\n",
              " 4,\n",
              " 7,\n",
              " 8,\n",
              " 6,\n",
              " 0,\n",
              " 1,\n",
              " 7,\n",
              " 9,\n",
              " 5,\n",
              " 9,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 4,\n",
              " 6,\n",
              " 8,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 8,\n",
              " 1,\n",
              " 0,\n",
              " 8,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 3,\n",
              " 9,\n",
              " 3,\n",
              " 3,\n",
              " 7,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 5,\n",
              " 2,\n",
              " 4,\n",
              " 9,\n",
              " 1,\n",
              " 3,\n",
              " 9,\n",
              " 8,\n",
              " 4,\n",
              " 4,\n",
              " 0,\n",
              " 6,\n",
              " 4,\n",
              " 9,\n",
              " 3,\n",
              " 7,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 9,\n",
              " 1,\n",
              " 5,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 7,\n",
              " 0,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 9,\n",
              " 3,\n",
              " 5,\n",
              " 9,\n",
              " 2,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 7,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 9,\n",
              " 1,\n",
              " 0,\n",
              " 8,\n",
              " 7,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 7,\n",
              " 0,\n",
              " 8,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 9,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 8,\n",
              " 5,\n",
              " 3,\n",
              " 0,\n",
              " 7,\n",
              " 0,\n",
              " 8,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 9,\n",
              " 7,\n",
              " 6,\n",
              " 8,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 8,\n",
              " 8,\n",
              " 5,\n",
              " 8,\n",
              " 3,\n",
              " 2,\n",
              " 6,\n",
              " 9,\n",
              " 6,\n",
              " 9,\n",
              " 8,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 4,\n",
              " 9,\n",
              " 9,\n",
              " 3,\n",
              " 0,\n",
              " 4,\n",
              " 2,\n",
              " 9,\n",
              " 3,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 7,\n",
              " 5,\n",
              " 6,\n",
              " 9,\n",
              " 5,\n",
              " 7,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 9,\n",
              " 0,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 8,\n",
              " 3,\n",
              " 2,\n",
              " 8,\n",
              " 8,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 9,\n",
              " 8,\n",
              " 0,\n",
              " 6,\n",
              " 7,\n",
              " 6,\n",
              " 4,\n",
              " 7,\n",
              " 0,\n",
              " 9,\n",
              " 8,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 8,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 5,\n",
              " 7,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 4,\n",
              " 9,\n",
              " 0,\n",
              " 8,\n",
              " 5,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 5,\n",
              " 7,\n",
              " 6,\n",
              " 9,\n",
              " 8,\n",
              " 6,\n",
              " 7,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 8,\n",
              " 9,\n",
              " 7,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 6,\n",
              " 4,\n",
              " 0,\n",
              " 8,\n",
              " 8,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 6,\n",
              " 9,\n",
              " 9,\n",
              " 9,\n",
              " 4,\n",
              " 7,\n",
              " 0,\n",
              " 8,\n",
              " 7,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 3,\n",
              " 6,\n",
              " 9,\n",
              " 9,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 3,\n",
              " 5,\n",
              " 7,\n",
              " 7,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 8,\n",
              " 8,\n",
              " 4,\n",
              " 9,\n",
              " 5,\n",
              " 7,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 7,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 8,\n",
              " 2,\n",
              " 8,\n",
              " 0,\n",
              " 9,\n",
              " 1,\n",
              " 8,\n",
              " 7,\n",
              " 9,\n",
              " 9,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 2,\n",
              " 6,\n",
              " 9,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 8,\n",
              " 2,\n",
              " 0,\n",
              " 8,\n",
              " 6,\n",
              " 5,\n",
              " 5,\n",
              " 9,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 8,\n",
              " 9,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 3,\n",
              " 4,\n",
              " 3,\n",
              " 5,\n",
              " 7,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 9,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 7,\n",
              " 3,\n",
              " 8,\n",
              " 9,\n",
              " 5,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 0,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 6,\n",
              " 7,\n",
              " 5,\n",
              " 5,\n",
              " 7,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 4,\n",
              " 1,\n",
              " 7,\n",
              " 8,\n",
              " 5,\n",
              " 7,\n",
              " 7,\n",
              " 2,\n",
              " 9,\n",
              " 3,\n",
              " 0,\n",
              " 7,\n",
              " 8,\n",
              " 7,\n",
              " 5,\n",
              " 2,\n",
              " 8,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 2,\n",
              " 9,\n",
              " 4,\n",
              " 1,\n",
              " 8,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 8,\n",
              " 2,\n",
              " 7,\n",
              " 0,\n",
              " 9,\n",
              " 9,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 7,\n",
              " 1,\n",
              " 6,\n",
              " 8,\n",
              " 2,\n",
              " 8,\n",
              " 1,\n",
              " 5,\n",
              " 2,\n",
              " 9,\n",
              " 3,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 8,\n",
              " 2,\n",
              " 9,\n",
              " 4,\n",
              " 2,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 3,\n",
              " 8,\n",
              " 0,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 8,\n",
              " 8,\n",
              " 6,\n",
              " 8,\n",
              " 5,\n",
              " 0,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 8,\n",
              " 0,\n",
              " 9,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 9,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 6,\n",
              " 9,\n",
              " 0,\n",
              " 6,\n",
              " 7,\n",
              " 0,\n",
              " 6,\n",
              " 7,\n",
              " 0,\n",
              " 0,\n",
              " 8,\n",
              " 4,\n",
              " 0,\n",
              " 7,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 7,\n",
              " 5,\n",
              " 5,\n",
              " 3,\n",
              " 8,\n",
              " 4,\n",
              " 6,\n",
              " 3,\n",
              " 6,\n",
              " 8,\n",
              " 3,\n",
              " 6,\n",
              " 9,\n",
              " 5,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 8,\n",
              " 7,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 7,\n",
              " 7,\n",
              " 6,\n",
              " 0,\n",
              " 7,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 4,\n",
              " 9,\n",
              " 6,\n",
              " 1,\n",
              " 9,\n",
              " 9,\n",
              " 8,\n",
              " 4,\n",
              " 2,\n",
              " 8,\n",
              " 2,\n",
              " 9,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 9,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 6,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 5,\n",
              " 5,\n",
              " 8,\n",
              " 5,\n",
              " 3,\n",
              " 3,\n",
              " 5,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 5,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 8,\n",
              " 7,\n",
              " 2,\n",
              " 8,\n",
              " 6,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 8,\n",
              " 0,\n",
              " 9,\n",
              " 2,\n",
              " 6,\n",
              " 7,\n",
              " 5,\n",
              " 9,\n",
              " 7,\n",
              " 5,\n",
              " 1,\n",
              " 8,\n",
              " 7,\n",
              " 6,\n",
              " 0,\n",
              " 7,\n",
              " 6,\n",
              " 9,\n",
              " 7,\n",
              " 4,\n",
              " 5,\n",
              " 7,\n",
              " 7,\n",
              " 8,\n",
              " 4,\n",
              " 4,\n",
              " 8,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 8,\n",
              " 8,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 8,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 4,\n",
              " 6,\n",
              " 5,\n",
              " 0,\n",
              " 5,\n",
              " 8,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 6,\n",
              " 5,\n",
              " 6,\n",
              " 8,\n",
              " 1,\n",
              " 7,\n",
              " 9,\n",
              " 4,\n",
              " 6,\n",
              " 8,\n",
              " 3,\n",
              " 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKUr-9BOyrNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye-j5y1C0ozx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVp4A8xQU-fb",
        "colab_type": "text"
      },
      "source": [
        "# Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZObn4NLVDK0",
        "colab_type": "text"
      },
      "source": [
        "* Google Schoolar Searches: [link](https://scholar.google.com/scholar?hl=sr&as_sdt=0%2C5&q=genetic+cnn+handwritting&btnG=)\n",
        "\n",
        "* Fokus na rad: \n",
        " * .pdf: [link](https://arxiv.org/abs/1703.01513)\n",
        " * github: [link](https://arxiv.org/abs/1703.01513)\n",
        "* Dodatno rad:\n",
        " *  .pdf: [link](https://arxiv.org/pdf/1710.10741.pdf)\n",
        " * Clanak na netu: [link](https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164)\n",
        "* Ako sami implementiramo: [link](https://github.com/joeddav/devol/blob/master/devol/devol.py)\n"
      ]
    }
  ]
}