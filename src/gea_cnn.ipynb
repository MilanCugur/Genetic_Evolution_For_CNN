{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gea_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QdSVY0xOnvKS",
        "bs1lDrRlnywQ",
        "TfbLSwCp032T",
        "2FqoY7lN9hEN",
        "CuXJhy_ieyQ0",
        "hVp4A8xQU-fb"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilanCugur/Neuroevolution-LocalSearch/blob/master/src/gea_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfJ-fn_XLnLU",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DoSLvx2LdSl",
        "colab_type": "code",
        "outputId": "c51d4ff2-3ee5-42d9-b14f-3afa764aebcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoTzVEoMfV6",
        "colab_type": "code",
        "outputId": "8f94c759-4eb8-4e14-e2f9-31f2f58d94c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Add, Activation, Flatten, Concatenate, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam  \n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import LeakyReLU, concatenate\n",
        "from keras.layers.advanced_activations import ReLU\n",
        "from keras.initializers import glorot_normal\n",
        "import keras.backend as K\n",
        "from keras.models import load_model  # Save model params\n",
        "\n",
        "def extract_dataset(path):\n",
        "  \"\"\"\n",
        "  extract DoubledMNIST dataset\n",
        "  Argument: path to .zip file with the dataset\n",
        "  Return value: x_train, y_train, x_test, y_test lists of numpy arrays \n",
        "  \n",
        "  (DoubledMNIST dataset: train size 120k images 56x56, test size 20k images 56x56)\n",
        "  \"\"\"\n",
        "  # import libraries\n",
        "  import os                     # for basic os operations\n",
        "  from zipfile import ZipFile \n",
        "  from skimage import io\n",
        "  import shutil\n",
        "  \n",
        "  if not path.endswith('.zip'):\n",
        "    raise ValueError(\"Error: path is not '.zip' file\")\n",
        "  \n",
        "  archive = ZipFile(path, 'r')  # extract\n",
        "  archive.extractall('./DoubledMNIST')\n",
        "  archive.close()\n",
        "  del archive\n",
        "  \n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/train'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/train', file))\n",
        "    x_train.append(np.array(img))\n",
        "    y_train.append(int(file.split('_')[1]))\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/test'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/test', file))\n",
        "    x_test.append(np.array(img))\n",
        "    y_test.append(int(file.split('_')[1]))\n",
        "    \n",
        "  shutil.rmtree('./DoubledMNIST')\n",
        "  return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bKQ505PMxBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(doubled=0, ntrain=None, ntest=None):\n",
        "    \"\"\"\n",
        "    doubled==0 -> load MNIST; doubled==1-> load DoubledMNIST\n",
        "    ntrain - number of train samples\n",
        "    ntest - number of test samples\n",
        "    \"\"\"\n",
        "\n",
        "    from keras.utils import to_categorical\n",
        "    import numpy as np\n",
        "\n",
        "    if doubled==0:\n",
        "        # load mnist\n",
        "        from keras.datasets import mnist\n",
        "\n",
        "        (_x_train, _y_train), (_x_test, _y_test) = mnist.load_data()\n",
        "        if ntrain==None:\n",
        "            ntrain = _x_train.shape[0]\n",
        "        if ntest==None:\n",
        "            ntest = _x_test.shape[0]\n",
        "        assert ntrain<=_x_train.shape[0] and ntest<=_x_test.shape[0]\n",
        "    else:\n",
        "        # load doubled mnist\n",
        "        _x_train, _y_train, _x_test, _y_test = extract_dataset('./drive/My Drive/ni_sem/DoubledMNIST.zip')\n",
        "\n",
        "    # Prepare images\n",
        "    box_size = _x_train.shape[1]\n",
        "    y_train = to_categorical(_y_train)[:ntrain]\n",
        "    y_test = to_categorical(_y_test)[:ntest]\n",
        "    x_train = np.array(_x_train).astype('float32')[:ntrain]\n",
        "    x_train /= 255\n",
        "    x_train = np.reshape(x_train,[-1, box_size, box_size, 1])\n",
        "    x_test = np.array(_x_test).astype('float32')[:ntest]\n",
        "    x_test /= 255\n",
        "    x_test = np.reshape(x_test, [-1, box_size, box_size, 1])\n",
        "    return x_train, y_train, x_test, y_test, box_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5K7U7oOg4_4",
        "colab_type": "code",
        "outputId": "59f0067f-8227-4f55-8bec-4c91ec09345f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=0, ntrain=10000, ntest=1000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "CPU times: user 369 ms, sys: 128 ms, total: 496 ms\n",
            "Wall time: 1.77 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8PNO4_WwR-E",
        "colab_type": "code",
        "outputId": "092600ad-ed62-414d-eabd-b3699ac37039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28, 1), (10000, 10), (1000, 28, 28, 1), (1000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA_twWHcP-71",
        "colab_type": "code",
        "outputId": "3ddce4de-436f-4ba9-80fc-56f6e543d40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import pyplot as plt  # smal demonstration\n",
        "\n",
        "plt.imshow(x_test[19].reshape((x_test.shape[1], x_test.shape[2])))\n",
        "plt.show()\n",
        "\n",
        "print(y_test[19])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANUElEQVR4nO3dbYxc5XnG8evyZv0SQ1q/4MUYK0Bi\ngkzbOM3WoMRJqWgihy8mXxCugtwKdVMVoiChqoiqCv1UFIVESEWRNsXCQRSCCggnQgHHskCIyLJx\nHb9BYopMsbvYIbZqIMTete9+2EO0wM6z65kzL/b9/0mrOXPuOXtuH+3lZ+acmXkcEQJw7pvR7QYA\ndAZhB5Ig7EAShB1IgrADSXykkzub6VkxW3M7uUsgld/pHZ2ME56s1lLYba+WdK+kPkn/HhF3lx4/\nW3N1la9tZZcACrbG5oa1pp/G2+6TdJ+kr0haLmmt7eXN/j4A7dXKa/aVkl6JiFcj4qSkRyStqact\nAHVrJexLJL0+4f7Bat372B6yvd329lGdaGF3AFrR9rPxETEcEYMRMdivWe3eHYAGWgn7IUlLJ9y/\nuFoHoAe1EvZtkpbZvtT2TEk3StpYT1sA6tb0pbeIGLN9q6SnNX7pbX1E7K2tMwC1auk6e0Q8Jemp\nmnoB0Ea8XRZIgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE\nYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkWprF\nFWinoz+5vFgf++nCYn3Rv71QZztnvZbCbvuApLcknZI0FhGDdTQFoH51jOx/ERFv1vB7ALQRr9mB\nJFoNe0h6xvaLtocme4DtIdvbbW8f1YkWdwegWa0+jV8VEYdsL5K0yfbLEfHcxAdExLCkYUn6mOdH\ni/sD0KSWRvaIOFTdHpH0hKSVdTQFoH5Nh932XNvnv7cs6cuS9tTVGIB6tfI0fkDSE7bf+z3/ERE/\nraUr5DCjr1i+78qHivW/+uU3ivVFZ9zQua3psEfEq5I+XWMvANqIS29AEoQdSIKwA0kQdiAJwg4k\nwUdc0TVj16wo1j87c1uHOsmBkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuA6ew/wZ68s1k99+3ix\n3v+NOY233ferpno6G8zb6263cFZhZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJLjO3gNGVv1Bsb7j\nigeL9as+d0vD2oJ9TbXUEccun9nS9ucfHK2pkxwY2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCa6z\n94CxL/5fS9uff3Cspk4664qbXi7WXx49UazP3LKrWI8z7ujcNuXIbnu97SO290xYN9/2Jtv7q9t5\n7W0TQKum8zT+AUmrP7DuDkmbI2KZpM3VfQA9bMqwR8Rzko5+YPUaSRuq5Q2Srq+5LwA1a/Y1+0BE\njFTLb0gaaPRA20OShiRptj7a5O4AtKrls/ERESqcC4mI4YgYjIjBfs1qdXcAmtRs2A/bXixJ1e2R\n+loC0A7Nhn2jpHXV8jpJT9bTDoB2mfI1u+2HJV0jaaHtg5K+JeluSY/avlnSa5JuaGeTZ7u+BfOL\n9Xs+/Z/F+tX/dWOxPv+ZHWfcUy+Y+5GTxfpolMeiGC1vj/ebMuwRsbZB6dqaewHQRrxdFkiCsANJ\nEHYgCcIOJEHYgST4iGsHvDt4WbH+pTk/K9Zv27GgWJ9/unenZe4bWNSw9neLflLc9uY9NxXrC9W7\n/+5exMgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwnb0D/ndVf0vbX7yl/JXKvex//uaTDWsrZpb/\n/H73wsIpfjvX2c8EIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF19hrM+Gh5Wqt/ueGRYn33ydFi\n/e0lM4v1Yz/6k4a1Sy/4TXHbhbPfKdbv//imYn0qM/RioeritqfmMOlynRjZgSQIO5AEYQeSIOxA\nEoQdSIKwA0kQdiAJR3TuWubHPD+u8rk3+WvfBRcU6z/e+XRb9z+mUw1r9x37VHHbpw8vr7ud93nw\n8h81rC2YMae47bHT7xbr137nH4r1C+99oVg/F22NzToeRyd9A8OUI7vt9baP2N4zYd1dtg/Z3ln9\nXFdnwwDqN52n8Q9IWj3J+u9FxIrq56l62wJQtynDHhHPSTragV4AtFErJ+hutb2repo/r9GDbA/Z\n3m57+6jO3u9SA852zYb9+5I+IWmFpBFJ9zR6YEQMR8RgRAz2a1aTuwPQqqbCHhGHI+JURJyW9ANJ\nK+ttC0Ddmgq77cUT7n5V0p5GjwXQG6b8PLvthyVdI2mh7YOSviXpGtsrJIWkA5K+3sYee1789rfF\n+gPHLyrWPzfn1WL9+oduL9Y/OXywYW3stdeL20qNt63Dtlcazy2/ek75uL11uvwekC98rfRZeWn/\nvcVyOlOGPSLWTrL6/jb0AqCNeLsskARhB5Ig7EAShB1IgrADSfBV0jU4/U7565gf+8KVxfrj/SuK\n9UtGfl6sjxWr7dW37LJi/Y9nPt+w9q+/GSxu++zfX13e9zvlr+CW9k5Rz4WRHUiCsANJEHYgCcIO\nJEHYgSQIO5AEYQeS4Dp7B5x6szxt8tns9TUXFutL+hpPZ73+2T8vbrvs+a3FOhM6nxlGdiAJwg4k\nQdiBJAg7kARhB5Ig7EAShB1IguvsaMnJP2z+avdFz9bYCKbEyA4kQdiBJAg7kARhB5Ig7EAShB1I\ngrADSXCdHV3Td4JPpHfSlCO77aW2t9jeZ3uv7W9W6+fb3mR7f3U7r/3tAmjWdJ7Gj0m6PSKWS7pa\n0i22l0u6Q9LmiFgmaXN1H0CPmjLsETESETuq5bckvSRpiaQ1kjZUD9sg6fp2NQmgdWf0mt32JZI+\nI2mrpIGIGKlKb0gaaLDNkKQhSZqtxt9HBqC9pn023vZ5kh6TdFtEHJ9Yi4hQg+//i4jhiBiMiMF+\nzWqpWQDNm1bYbfdrPOgPRcTj1erDthdX9cWSjrSnRQB1mM7ZeEu6X9JLEfHdCaWNktZVy+skPVl/\newDqMp3X7J+XdJOk3bZ3VuvulHS3pEdt3yzpNUk3tKdFAHWYMuwR8bwkNyhfW287ANqFt8sCSRB2\nIAnCDiRB2IEkCDuQBB9xRUsG/uyNYr3PjceTo1eU//wu+nFTLaEBRnYgCcIOJEHYgSQIO5AEYQeS\nIOxAEoQdSILr7GjJhXOPF+un4nTD2qxjfJV0JzGyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASXGdH\nS36x5fJi/S/fPa9hbdGje4vbnmqqIzTCyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSUx5nd32Ukk/\nlDQgKSQNR8S9tu+S9LeSfl099M6IeKpdjaI3XfLPP296W66jd9Z03lQzJun2iNhh+3xJL9reVNW+\nFxHfaV97AOoynfnZRySNVMtv2X5J0pJ2NwagXmf0mt32JZI+I2lrtepW27tsr7c9r8E2Q7a3294+\nqhMtNQugedMOu+3zJD0m6baIOC7p+5I+IWmFxkf+eybbLiKGI2IwIgb7NauGlgE0Y1pht92v8aA/\nFBGPS1JEHI6IUxFxWtIPJK1sX5sAWjVl2G1b0v2SXoqI705Yv3jCw74qaU/97QGoy3TOxn9e0k2S\ndtveWa27U9Ja2ys0fjnugKSvt6VDALWYztn45yV5khLX1IGzCO+gA5Ig7EAShB1IgrADSRB2IAnC\nDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI6NzO7F9Lem3CqoWS3uxYA2emV3vr1b4k\nemtWnb19PCIumKzQ0bB/aOf29ogY7FoDBb3aW6/2JdFbszrVG0/jgSQIO5BEt8M+3OX9l/Rqb73a\nl0RvzepIb119zQ6gc7o9sgPoEMIOJNGVsNtebfuXtl+xfUc3emjE9gHbu23vtL29y72st33E9p4J\n6+bb3mR7f3U76Rx7XertLtuHqmO30/Z1Xeptqe0ttvfZ3mv7m9X6rh67Ql8dOW4df81uu0/SryR9\nSdJBSdskrY2IfR1tpAHbByQNRkTX34Bh+4uS3pb0w4j4o2rdtyUdjYi7q/8o50XEP/ZIb3dJervb\n03hXsxUtnjjNuKTrJf21unjsCn3doA4ct26M7CslvRIRr0bESUmPSFrThT56XkQ8J+noB1avkbSh\nWt6g8T+WjmvQW0+IiJGI2FEtvyXpvWnGu3rsCn11RDfCvkTS6xPuH1Rvzfcekp6x/aLtoW43M4mB\niBiplt+QNNDNZiYx5TTenfSBacZ75tg1M/15qzhB92GrIuJPJX1F0i3V09WeFOOvwXrp2um0pvHu\nlEmmGf+9bh67Zqc/b1U3wn5I0tIJ9y+u1vWEiDhU3R6R9IR6byrqw+/NoFvdHulyP7/XS9N4TzbN\nuHrg2HVz+vNuhH2bpGW2L7U9U9KNkjZ2oY8PsT23OnEi23MlfVm9NxX1RknrquV1kp7sYi/v0yvT\neDeaZlxdPnZdn/48Ijr+I+k6jZ+R/29J/9SNHhr0dZmkX1Q/e7vdm6SHNf60blTj5zZulrRA0mZJ\n+yX9TNL8HurtQUm7Je3SeLAWd6m3VRp/ir5L0s7q57puH7tCXx05brxdFkiCE3RAEoQdSIKwA0kQ\ndiAJwg4kQdiBJAg7kMT/A8+T6g7j+JKWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uungJ3ZiczL",
        "colab_type": "text"
      },
      "source": [
        "# CNN tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDESDezifHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "\n",
        "# sampleIndividual = [1, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi klasicna CNN\n",
        "# stage1 examples\n",
        "# sampleIndividual = [1, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; trojka eliminisana\n",
        "# sampleIndividual = [0, 1, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; dvojka eliminisana\n",
        "# sampleIndividual = [0, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; jedinica eliminisana\n",
        "# sampleIndividual = [0, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; samo jedna konv.\n",
        "# stage2 examples\n",
        "# sampleIndividual = [1, 0, 1,   0, 0, 0, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->3->4->5\n",
        "# sampleIndividual = [1, 0, 1,   0, 1, 0, 0, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->1->3->5\n",
        "# sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; 0->1->2,3,4->5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbp0WjNmifCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __create_indices(num_nodes):\n",
        "  \"\"\"\n",
        "  num_nodes - number of nodes per each stage\n",
        "\n",
        "  Calculate bits indices (startindex, length) for each stage \n",
        "  \"\"\"\n",
        "  l =  0                              # genome length\n",
        "  bits_indices, i = np.empty((0,2),dtype = np.int32), 0 \n",
        "  for Ks in num_nodes:\n",
        "    length = Ks * (Ks - 1)\n",
        "    bits_indices = np.vstack([bits_indices,[i, i + int(0.5 * length)]])\n",
        "    i += int(0.5 * length)\n",
        "    l += length\n",
        "  l = int(0.5 * l)\n",
        "  return bits_indices, l\n",
        "\n",
        "def CNN_build(stages, num_nodes, n_filters, individual, box_size, n_classes, verbose=0):\n",
        "  \"\"\"\n",
        "  stages - array of stage names\n",
        "  num_nodes - number of conv nodes per each stage\n",
        "  n_filters - number of filters per stage\n",
        "  individual - binary list representing individual architecture\n",
        "  box_size - expect input images like (box_size, box_size)\n",
        "  n_classes - number of output clasees\n",
        "\n",
        "  Build CNN architecture from the given list\n",
        "  \"\"\"\n",
        "\n",
        "  L = len(individual)\n",
        "  bits_indices, _L= __create_indices(num_nodes)\n",
        "  assert(L==_L)  # small check of the input individual connections info\n",
        "\n",
        "  if(verbose):\n",
        "    print('Starting network building..')\n",
        "  image_shape = (box_size, box_size, 1) \n",
        "  x_input = Input(shape=image_shape)  \n",
        "  previous = None # output from previous stage (initially input of CNN)\n",
        "  # Build stage by stage\n",
        "  for i, (s, Ks, n_filter) in enumerate(zip(stages, num_nodes, n_filters)):\n",
        "    if i==0:\n",
        "      previous = x_input\n",
        "    if(verbose):\n",
        "        print('\\nBuild layer', s, ':', Ks, 'nodes,', n_filter, 'filters.')\n",
        "    stage_indices = individual[bits_indices[i][0]:bits_indices[i][1]]                  # connection indices for current stage nodes; ex. [1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "    stage_indexes = np.split(range(int(Ks*(Ks-1)/2)),np.cumsum(range(Ks - 1)))[1:]     # connection indexes for current stage nodes; ex. [array([0]), array([1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]\n",
        "    stage_nodes = []                                                                   # nodes in a stage; ex. [vs1_1, vs1_2, vs1_3] (0, 4 are dummy)\n",
        "    to_him = list(np.zeros(Ks))                                                              # number of nodes to which i-th node points to\n",
        "    from_him = list(np.zeros(Ks))  \n",
        "    if(verbose):                                                          # number of nodes from i-th node to others\n",
        "        print('Stage indices:', stage_indices)\n",
        "        print('Stage indexes:', stage_indexes)\n",
        "\n",
        "    # default stage input node\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_0')\n",
        "    vs0 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_0')(previous)  # TODO\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_0')\n",
        "\n",
        "    # first node and trivial vs0->vs1\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_1')\n",
        "    vs1 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_1')(vs0) \n",
        "    stage_nodes += [vs1]\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_1')\n",
        "\n",
        "    for j in range(2, Ks+1):\n",
        "      name = 'v'+str(s)+'_'+str(j)  # name of the current node\n",
        "      if(verbose):\n",
        "        print('Building '+name)\n",
        "      tonode = stage_indices[stage_indexes[j-2][0]:stage_indexes[j-2][-1]+1]  # slice from stage_indices\n",
        "      input = None  # Input to current node\n",
        "      if sum(tonode)==0:  # empty input, connect to vs0\n",
        "        input = vs0\n",
        "      else:  # have some input\n",
        "        for k, connection in enumerate(tonode):\n",
        "          if connection==1:\n",
        "            from_him[k] += 1\n",
        "            to_him[j-1] += 1\n",
        "            if input is None:\n",
        "              input = stage_nodes[k]\n",
        "            else:\n",
        "              input = Add()([input, stage_nodes[k]])\n",
        "      v = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(j))(input) \n",
        "      stage_nodes += [v]\n",
        "      if(verbose):\n",
        "        print('Builded node '+name)\n",
        "\n",
        "    if(verbose):\n",
        "        print('from_him: ', from_him)\n",
        "        print('to_him: ', to_him)\n",
        "        print('stage_nodes: ', stage_nodes)\n",
        "\n",
        "    if sum(from_him)==sum(to_him)==0:  # only one convolution vs0\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vs0)\n",
        "    else:  # have some of the ordinary nodes\n",
        "        if(verbose):\n",
        "            print('Building '+'v'+str(s)+'_'+str(Ks+1))\n",
        "        input = None  # last node no output definitelly\n",
        "        for k in range(len(stage_nodes)):\n",
        "            if from_him[k]==0 and to_him[k]!=0:  # no connections from that node\n",
        "                if(verbose):\n",
        "                    print('Connect to last node node', k, ' ', stage_nodes[k])\n",
        "                if input is None:\n",
        "                    input = stage_nodes[k]\n",
        "                else:\n",
        "                    input = Add()([input, stage_nodes[k]])\n",
        "        vsKs = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(Ks+1))(input) # defaul stage output node\n",
        "        if(verbose):\n",
        "            print('Builded '+'v'+str(s)+str(Ks+1))\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vsKs)\n",
        "  \n",
        "  # Adding FC part of NN\n",
        "  x = Flatten(name='flatten')(previous)                                                                                       \n",
        "  x = Dense(units=32, activation='relu', name='next_to_last')(x)         \n",
        "  x = Dense(units=n_classes, activation='softmax', name='last')(x)\n",
        "\n",
        "  # Creaate Model\n",
        "  model = Model(inputs=x_input, outputs=x, name='individual')\n",
        "  if(verbose):\n",
        "    print('Created Network builded.')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3hhN7e_SZwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  Compile forwarded model, and return it compiled\n",
        "  \"\"\"\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=1e-3), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_TzENOzS2vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  plot forwarded model architecture\n",
        "  \"\"\"\n",
        "  from keras.utils import plot_model\n",
        "\n",
        "  print('Model summary: ')\n",
        "  model.summary()\n",
        "  plot_model(model, to_file='model.png')\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAH-z7QeUFqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose=0, validation_split=0.0, callbacks=[]):\n",
        "    \"\"\"\n",
        "    model - compiled CNN model\n",
        "    x_train - input images\n",
        "    y_train - input labels (one hot encoded)\n",
        "    x_test - test images\n",
        "    y_test - test labels (one hot encoded)\n",
        "    epochs - number of epochs\n",
        "    batch_size - mini batch size of training\n",
        "    verbose - verbose of training\n",
        "    validation_split - data split used for validation\n",
        "\n",
        "    Train forwrded model. Returns (train history, model obtained test accuracy)\n",
        "    \"\"\"\n",
        "    if (epochs == 0):\n",
        "        # for faster testing\n",
        "        # print('only eval, without training')\n",
        "        return None, model.evaluate(x_test, y_test)\n",
        "    # print('training and eval')\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split=validation_split, callbacks=callbacks)\n",
        "    return history, model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv7hRnZHWK9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)\n",
        "#model = compile_model(model)\n",
        "#visualize_model(model)\n",
        "#history, result = train_model(model, x_train, y_train, x_test, y_test, 1, 1024, 1)\n",
        "#result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOiF1-tx74y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toPseudo(model):\n",
        "    \"\"\"\n",
        "    model - input CNN model\n",
        "    return - structure that describe model weights for later from that model loading\n",
        "    \"\"\"\n",
        "    return [(layer.get_config()['name'], layer.get_weights()) for layer in model.layers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlLUG0GedB1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadWeights(toModel, fromPseudoModel, numSameStages, numNodesPerStage):\n",
        "    '''\n",
        "    toModel: keras model for which to load weights\n",
        "    fromPseudoModel: list of (layer name, layer weights) from which to load weights\n",
        "    numSameStages: number of first same stages; can be 0, 1, 2, 3; trivial cases 0 and 3\n",
        "    numNodesPerStage: number of nodes per stage; ex. [3,4,5]\n",
        "\n",
        "    You need to call model.compile. This can be done either before or after the model.load_weights \n",
        "    call but must be after the model architecture is specified and before the model.predict call.\n",
        "    returns the model with loaded weights from file\n",
        "\n",
        "    IMPORTANT: toModel and fromModel MUST HAVE exactly the same architecture on first numSameStages! (same indices eqvivalently)\n",
        "    TODO: add critical pool if want more pooling operations in architecture\n",
        "    '''\n",
        "    assert numSameStages<=len(numNodesPerStage)\n",
        "    allflag = (numSameStages==len(numNodesPerStage))  # to load all weights\n",
        "    for i, (name, weights) in enumerate(fromPseudoModel):\n",
        "        #print(name, weights) \n",
        "\n",
        "        if numSameStages==0:\n",
        "            if not allflag:\n",
        "                break\n",
        "\n",
        "        toModel.layers[i].set_weights(weights)\n",
        "\n",
        "        if 'max_pooling' in name:\n",
        "            numSameStages-=1         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kdgjBhwRq2c",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEWPhebDtHe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import random, seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFU56u2otadr",
        "colab_type": "code",
        "outputId": "496c015f-4239-4bd4-b0aa-3bb2e34b66f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.random.seed(42) # reproducible\n",
        "class Genetic:\n",
        "    def __init__(self, pc, qc, pm, qm, numGen, numInd, geneLength, bitIndices):\n",
        "        ''' \n",
        "        pc: probability of crossover - whether crossover process begins\n",
        "        qc: probability of stages being exchanged - while in crossover process\n",
        "        pm: probability of mutation - whether mutation process begins\n",
        "        qm: probability of a per bit mutation - while in mutation process\n",
        "        numGen: number of generations\n",
        "        numInd: number of individuals\n",
        "        bitIndices: 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "        '''\n",
        "        self.pc = pc\n",
        "        self.qc = qc\n",
        "        self.pm = pm\n",
        "        self.qm = qm\n",
        "        self.numGen = numGen\n",
        "        self.currNumGen = 0\n",
        "        self.numInd = numInd\n",
        "        self.geneLength = geneLength\n",
        "        self.bitIndices = bitIndices\n",
        "        self.oldGen = None\n",
        "        self.initFirstGeneration()\n",
        "    \n",
        "    def initFirstGeneration(self):\n",
        "        ''' \n",
        "        initializes the first generation\n",
        "        '''\n",
        "        self.currNumGen = 1\n",
        "        self.currGen = np.random.randint(0, 2, (self.numInd, self.geneLength))\n",
        "\n",
        "    def getCurrentGeneration(self):\n",
        "        return self.currGen\n",
        "\n",
        "    def selection(self, fitness):\n",
        "        '''\n",
        "        returns indices of individuals that survived the selection\n",
        "        '''\n",
        "        npfit = np.array(fitness)\n",
        "        proba = npfit - np.min(npfit) # removes the worst one\n",
        "        proba = proba / np.sum(proba)\n",
        "\n",
        "        return np.random.choice(self.numInd, replace=True, size=self.numInd, p=proba)\n",
        "\n",
        "    def mutate(self, newGen, indices):\n",
        "        '''\n",
        "        mutates individuals in newGen on positions where indices are 0 (because those individuals didn't mate)\n",
        "        '''\n",
        "        for i, had in enumerate(indices):\n",
        "            if had == 0 and np.random.random() <= self.pm:\n",
        "                newGen[i] = self.mutateIndividual(self.currGen[i])\n",
        "            else:\n",
        "                newGen[i] = np.copy(self.currGen[i])\n",
        "\n",
        "    def mutateIndividual(self, individual):\n",
        "        '''\n",
        "        returns a new individual by mutating the given one\n",
        "        '''\n",
        "        mut = np.copy(individual)\n",
        "        for i, val in enumerate(mut):\n",
        "            if np.random.random() <= self.qm:\n",
        "                mut[i] = 1 - mut[i]\n",
        "\n",
        "        return mut\n",
        "\n",
        "    def crossover(self, individualA, individualB):\n",
        "        '''\n",
        "        returns two new individuals by performing crossover on two given individuals.\n",
        "        it takes care to only swap the whole segments, and not bits within segments\n",
        "        '''\n",
        "        a = np.copy(individualA)\n",
        "        b = np.copy(individualB)\n",
        "\n",
        "        for segment in self.bitIndices:\n",
        "            if np.random.random() <= self.qc:\n",
        "                start = segment[0]\n",
        "                end = segment[1]\n",
        "                tmpa = np.copy(a[start:end])\n",
        "                a[start:end] = b[start:end]\n",
        "                b[start:end] = tmpa\n",
        "\n",
        "        return a, b\n",
        "\n",
        "    def newGeneration(self, fitness, verbose=False):\n",
        "        '''\n",
        "        creates a new generation of individuals by selection, crossover, and mutation \n",
        "        of previous generation. Selection is based on the rulet method\n",
        "\n",
        "        fitness - np array of fitness metrics for all individuals, based on which to construct rulet\n",
        "        '''\n",
        "        self.currNumGen += 1\n",
        "        if self.currNumGen > self.numGen:\n",
        "            raise Exception(f\"currNumGen > numGen, {self.currNumGen} > {self.numGen}\")\n",
        "        newGenIdx = self.selection(fitness)\n",
        "        if verbose:\n",
        "            print(f'survived selection: {newGenIdx}')\n",
        "        newGen = np.zeros((self.numInd, self.geneLength), dtype='int32') # np matrix of new generation\n",
        "        hadCrossoverIdx = np.zeros(self.numInd) # tracks if an individial had a crossover\n",
        "        assert(len(newGen)%2 == 0)\n",
        "        # for each pair of neighbours, try crossover\n",
        "        for i in range(0, len(newGen), 2):\n",
        "            if np.random.random() <= self.pc:\n",
        "                newGen[i], newGen[i+1] = self.crossover(self.currGen[newGenIdx[i]], self.currGen[newGenIdx[i+1]])\n",
        "                hadCrossoverIdx[i] = 1\n",
        "                hadCrossoverIdx[i+1] = 1\n",
        "\n",
        "        self.mutate(newGen, hadCrossoverIdx)\n",
        "        \n",
        "        self.oldGen = self.currGen\n",
        "        self.currGen = newGen\n",
        "\n",
        "    def findIndividualsWithSameRoots(self, verbose=False):\n",
        "        '''\n",
        "        for each individual in a new generation finds the indices of individuals in the old generation \n",
        "        which had the same firts n segments\n",
        "\n",
        "        returns a list, where i-th element has a touple (listOfParentsWithSameSegment, numberOfSameSegments)\n",
        "        '''\n",
        "        parentsAndNumSegments = []\n",
        "        for indiv in self.currGen:\n",
        "            parents, numSameSegments = self.hasSameRoots(indiv)\n",
        "            parentsAndNumSegments.append((parents, numSameSegments))\n",
        "            if numSameSegments > 0 and verbose:\n",
        "                print('individual:',indiv)\n",
        "                print(f'has the same {numSameSegments} first segments as:')\n",
        "                print(parents)\n",
        "                print(f'e.g: {self.oldGen[parents[0]]}')\n",
        "\n",
        "        return parentsAndNumSegments\n",
        "\n",
        "\n",
        "    def hasSameRoots(self, individual):\n",
        "        '''\n",
        "        returns indices of individuals from last generations which have the biggest same root as the\n",
        "        given individual, and returns the number of segments which are the same (starting from the first)\n",
        "        '''\n",
        "        for i, segment in reversed(list(enumerate(self.bitIndices))):\n",
        "            nColumns = segment[1]\n",
        "            # print('bools',(self.oldGen[:,:nColumns] == individual[:nColumns]))\n",
        "            # print('oldgen:',self.oldGen)\n",
        "            # print('ind:', individual)\n",
        "            # find rows which have the individual (only look at the part of the colums)\n",
        "            matchedRows = (self.oldGen[:,:nColumns] == individual[:nColumns]).all(axis=1)\n",
        "            sameRootIndividuals = np.where(matchedRows)[0]\n",
        "            if sameRootIndividuals.size > 0:\n",
        "                return sameRootIndividuals, i+1\n",
        "\n",
        "        return np.empty(0), 0\n",
        "\n",
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "BITS_INDICES, geneLength = __create_indices(NUM_NODES)\n",
        "gen = Genetic(0.2, 0.3, 0.8, 0.1, 10, 10, geneLength, BITS_INDICES)\n",
        "print('mean1', np.mean(gen.getCurrentGeneration()))\n",
        "gen.newGeneration(np.random.random(10))\n",
        "print('mean2', np.mean(gen.getCurrentGeneration()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean1 0.5105263157894737\n",
            "mean2 0.5157894736842106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5onkJV5pZ4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import types\n",
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "\n",
        "BIT_INDICES, L = __create_indices(NUM_NODES)\n",
        "# params is used as function parameter throught the core algorithm\n",
        "params = types.SimpleNamespace()\n",
        "params.pc = 0.2 # pc: probability of crossover - whether crossover process begins\n",
        "params.pm = 0.8 # pm: probability of mutation - whether mutation process begins\n",
        "params.qc = 0.3 # qc: probability of stages being exchanged - while in crossover process\n",
        "params.qm = 0.1 # qm: probability of a per bit mutation - while in mutation process\n",
        "params.geneLength = L # number of bits needed to encode the gene\n",
        "params.numGenerations = 20 # 10 # number of generations\n",
        "params.numIndividuals = 20 # 10 # number of individuals\n",
        "params.bitIndices = BITS_INDICES # 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "params.boxSize = box_size # width and height of the input\n",
        "params.numClasses = 10 # number of output classes\n",
        "params.stageNames = STAGES # list containing names of stages\n",
        "params.numFilters = FILTERS # list containing number of filters per stage\n",
        "params.numNodes = NUM_NODES # number of nodes within each stage\n",
        "params.xTrain = x_train # training set data\n",
        "params.yTrain = y_train # training set labels\n",
        "params.xTest = x_test # test set data\n",
        "params.yTest = y_test # test set labels\n",
        "params.epochs = 5 # default number of epochs to train in the first generation\n",
        "params.batchSize = 256\n",
        "params.verbose = True\n",
        "params.numInheritedStagesToEpochs = { # maps number of inherited stages into \n",
        "                                      # number of needed epochs to train it\n",
        "                                      # all: 0epoch, 1stage: 4epoch, 2stage: 3epoch\n",
        "    0: params.epochs,\n",
        "    1: params.epochs - 1,\n",
        "    2: params.epochs - 2,\n",
        "    3: 0\n",
        "}\n",
        "params.isModification = False\n",
        "assert(params.numIndividuals%2 == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx7G8lmn0Tso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inheritWeightsFromParents(model, params, parentSegmentTuple, lastGenWeights):\n",
        "    '''\n",
        "    returns model, howManyEpochsToTrain, parentIndex\n",
        "    returns the model which inherits weights from last generation if possible \n",
        "    (and if params.isModification=true)\n",
        "    '''\n",
        "    parents = parentSegmentTuple[0] \n",
        "    numSegments = parentSegmentTuple[1]\n",
        "    epochsToTrain = params.numInheritedStagesToEpochs[numSegments] if params.isModification else params.epochs\n",
        "    trainForEpochs = epochsToTrain\n",
        "    parentIndex = None\n",
        "    if params.isModification and numSegments > 0:\n",
        "        parentIndex = parents[0] # TODO this is a list, might take the parent with the best fitness\n",
        "        loadWeights(model, lastGenWeights[parentIndex], numSegments, params.numNodes)\n",
        "    if model is None:\n",
        "        print('\\t\\t\\t\\ MODEL IS NONE!')\n",
        "    return model, trainForEpochs, parentIndex\n",
        "\n",
        "def createAndEvaluateModel(params, individual, parentSegmentTuple, oldNetworkWeights, lastGenFitness, verbose):\n",
        "    '''\n",
        "    This clears the session to avoid slowdown after training many instances\n",
        "\n",
        "    returns its weights and fitness\n",
        "    '''\n",
        "    # build model\n",
        "    model = CNN_build(params.stageNames, params.numNodes, params.numFilters, individual, params.boxSize, params.numClasses, verbose=0)\n",
        "    model = compile_model(model)\n",
        "    # inherit weights\n",
        "    if oldNetworkWeights is None:\n",
        "        assert(lastGenFitness is None)\n",
        "        assert(parentSegmentTuple is None)\n",
        "        trainForEpochs = params.epochs\n",
        "    else:\n",
        "        assert(lastGenFitness is not None)\n",
        "        assert(parentSegmentTuple is not None)\n",
        "        model, trainForEpochs, parentIndex = inheritWeightsFromParents(model, params, parentSegmentTuple, oldNetworkWeights)\n",
        "\n",
        "    # train or copy from last gen\n",
        "    if trainForEpochs == 0:\n",
        "        assert(lastGenFitness is not None)\n",
        "        assert(oldNetworkWeights is not None)\n",
        "        print('\\t\\t\\t\\Skipping training because model is the same as last gen')\n",
        "        fitness = lastGenFitness[parentIndex]\n",
        "        pseudoWeights = oldNetworkWeights[parentIndex]\n",
        "    else:\n",
        "        history, lossAndAcc = train_model(model, params.xTrain, params.yTrain, params.xTest,\n",
        "                    params.yTest, trainForEpochs,\n",
        "                    params.batchSize, verbose=params.verbose, validation_split=0.0) \n",
        "        fitness = lossAndAcc[1]\n",
        "        pseudoWeights = toPseudo(model)\n",
        "\n",
        "    K.clear_session()\n",
        "    return pseudoWeights, fitness\n",
        "    \n",
        "def executeSelectionWithGeneticAlgorithm(params):\n",
        "    ''' \n",
        "    args: params object defined above\n",
        "\n",
        "    returns individuals in the last generation, index of the best individual, and their fitnesses, and np matrix of all fitnesses\n",
        "    '''\n",
        "    genetic = Genetic(params.pc, params.qc, params.pm, params.qm, params.numGenerations, params.numIndividuals, params.geneLength, params.bitIndices)\n",
        "    oldNetworksWeights = None\n",
        "    allFitnesses = np.zeros((params.numGenerations, params.numIndividuals))\n",
        "    for i in range(params.numGenerations):\n",
        "        nthGen = i+1\n",
        "        print(f'\\t\\t\\tStarting generation {nthGen}...')\n",
        "        print(f'Creating models from individuals...')\n",
        "        individuals = genetic.getCurrentGeneration()\n",
        "        # print(\"current generation:\", individuals)\n",
        "        newNetworksWeights = []\n",
        "        if i > 0:\n",
        "            print(f'findIndividualsWithSameRoots...')\n",
        "            parentSegmentTuples = genetic.findIndividualsWithSameRoots()\n",
        "            lastGenFitness = allFitnesses[i-1]\n",
        "        else:\n",
        "            parentSegmentTuples = None \n",
        "            lastGenFitness = None\n",
        "        \n",
        "        currGenFitness = []\n",
        "        for j, individual in enumerate(individuals):\n",
        "            print(f\"Creating and evaluating indiv #{j}\")\n",
        "            parentSegmentTuple = None if parentSegmentTuples is None else parentSegmentTuples[j]\n",
        "            newNetWeight, fitness = createAndEvaluateModel(params, individual, parentSegmentTuple,\n",
        "                                                           oldNetworksWeights, lastGenFitness, params.verbose)\n",
        "            newNetworksWeights.append(newNetWeight)\n",
        "            currGenFitness.append(fitness)\n",
        "\n",
        "        currGenFitness = np.array(currGenFitness) \n",
        "        allFitnesses[i] = currGenFitness\n",
        "        print(f'this gen fitnesses: {currGenFitness}')\n",
        "        if i < params.numGenerations - 1:\n",
        "            genetic.newGeneration(fitness=currGenFitness)\n",
        "            oldNetworksWeights = newNetworksWeights\n",
        "\n",
        "    bestIdx = np.argmax(currGenFitness)\n",
        "    print(f'The best individual {individuals[bestIdx]} had fitness (accuracy): {currGenFitness[bestIdx]}')\n",
        "\n",
        "    return individuals, bestIdx, currGenFitness, allFitnesses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAAN4N9PnlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotEvolutionProgress(allFit, takeBestN):\n",
        "    topn = np.zeros((params.numGenerations, takeBestN))\n",
        "    for i, row in enumerate(allFit):\n",
        "        row.sort()\n",
        "        topn[i] = row[-takeBestN:]\n",
        "\n",
        "    for i, col in reversed(list(enumerate(topn.T))):\n",
        "        plt.plot(range(1, params.numGenerations+1), col, label=f'#{takeBestN - i}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "# plotEvolutionProgress(np.random.randn(params.numGenerations, params.numIndividuals), takeBestN = 2)\n",
        "#plotEvolutionProgress(allFitnesses, takeBestN = 1)\n",
        "#allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdSVY0xOnvKS",
        "colab_type": "text"
      },
      "source": [
        "## Baseline: 4 gen x 4 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqXfftoHnfM",
        "colab_type": "code",
        "outputId": "8de7de3c-f1f4-422c-a820-2f9add5cee70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = False\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3412 - acc: 0.8875\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0658 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0418 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0349 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0295 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 232us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.3517 - acc: 0.8828\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0576 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0409 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0316 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0240 - acc: 0.9927\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.3559 - acc: 0.8811\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0663 - acc: 0.9793\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0422 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0313 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0281 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 164us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.4713 - acc: 0.8409\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0632 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0463 - acc: 0.9854\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0353 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0306 - acc: 0.9904\n",
            "10000/10000 [==============================] - 2s 243us/step\n",
            "this gen fitnesses: [0.9913 0.9908 0.9919 0.9859]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3762 - acc: 0.8740\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0626 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0433 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0337 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0288 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.3374 - acc: 0.8942\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0583 - acc: 0.9824\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0413 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0312 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0236 - acc: 0.9927\n",
            "10000/10000 [==============================] - 3s 254us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.3007 - acc: 0.9003\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0591 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0408 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0321 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0263 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 228us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 432us/step - loss: 0.4312 - acc: 0.8558\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.0632 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0449 - acc: 0.9865\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0357 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0290 - acc: 0.9913\n",
            "10000/10000 [==============================] - 3s 251us/step\n",
            "this gen fitnesses: [0.9904 0.9907 0.9906 0.9918]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3777 - acc: 0.8751\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0651 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0439 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0355 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0267 - acc: 0.9922\n",
            "10000/10000 [==============================] - 2s 231us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.3235 - acc: 0.8958\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0618 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0431 - acc: 0.9870\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0332 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0278 - acc: 0.9917\n",
            "10000/10000 [==============================] - 3s 250us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.6310 - acc: 0.7848\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0742 - acc: 0.9772\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0523 - acc: 0.9840\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0390 - acc: 0.9881\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0331 - acc: 0.9896\n",
            "10000/10000 [==============================] - 2s 226us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.3400 - acc: 0.8870\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0599 - acc: 0.9819\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0450 - acc: 0.9862\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0323 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0309 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 241us/step\n",
            "this gen fitnesses: [0.9917 0.9902 0.9912 0.987 ]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.4026 - acc: 0.8650\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0650 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0498 - acc: 0.9851\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0387 - acc: 0.9879\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0323 - acc: 0.9906\n",
            "10000/10000 [==============================] - 2s 239us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 453us/step - loss: 0.2889 - acc: 0.9041\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0531 - acc: 0.9844\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0378 - acc: 0.9888\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0314 - acc: 0.9904\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0233 - acc: 0.9927\n",
            "10000/10000 [==============================] - 3s 253us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.3328 - acc: 0.8904\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0633 - acc: 0.9810\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0441 - acc: 0.9861\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0329 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0262 - acc: 0.9922\n",
            "10000/10000 [==============================] - 2s 230us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.2957 - acc: 0.9057\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0566 - acc: 0.9829\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0404 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0313 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0269 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 244us/step\n",
            "this gen fitnesses: [0.9837 0.9911 0.9882 0.9906]\n",
            "The best individual [1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0] had fitness (accuracy): 0.9911\n",
            "CPU times: user 20min 30s, sys: 6min 24s, total: 26min 55s\n",
            "Wall time: 32min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIPoJK_R0H_O",
        "colab_type": "code",
        "outputId": "a03a809e-6c8a-41ab-b8d7-ac681805d585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 4)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs1lDrRlnywQ",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 4 gen x 4 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHdNEUGn1HP",
        "colab_type": "code",
        "outputId": "c7e00a99-759b-4d76-b81f-af6f7c9113c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.3518 - acc: 0.8850\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0666 - acc: 0.9806\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0432 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0360 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0265 - acc: 0.9919\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.3471 - acc: 0.8852\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0584 - acc: 0.9827\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0398 - acc: 0.9881\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0339 - acc: 0.9893\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0277 - acc: 0.9912\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.3572 - acc: 0.8838\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0677 - acc: 0.9793\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0423 - acc: 0.9870\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0313 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0298 - acc: 0.9903\n",
            "10000/10000 [==============================] - 2s 166us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.4806 - acc: 0.8355\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0678 - acc: 0.9794\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0495 - acc: 0.9852\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0369 - acc: 0.9889\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0310 - acc: 0.9908\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "this gen fitnesses: [0.9917 0.9893 0.9913 0.9885]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.3140 - acc: 0.8940\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0565 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0397 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0299 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0234 - acc: 0.9928\n",
            "10000/10000 [==============================] - 2s 231us/step\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9917 0.9893 0.9876 0.9885]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.2423 - acc: 0.9223\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0485 - acc: 0.9856\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0372 - acc: 0.9890\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0269 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.2373 - acc: 0.9249\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0502 - acc: 0.9847\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0368 - acc: 0.9889\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0287 - acc: 0.9909\n",
            "10000/10000 [==============================] - 3s 254us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9897 0.9886 0.9876 0.9885]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.2035 - acc: 0.9406\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0347 - acc: 0.9895\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0261 - acc: 0.9919\n",
            "10000/10000 [==============================] - 3s 253us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.3373 - acc: 0.8863\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0604 - acc: 0.9810\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0412 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0331 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 20s 341us/step - loss: 0.0265 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 209us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.2554 - acc: 0.9209\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0505 - acc: 0.9852\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0352 - acc: 0.9895\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.0293 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 242us/step\n",
            "this gen fitnesses: [0.9897 0.9925 0.9883 0.9922]\n",
            "The best individual [1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1] had fitness (accuracy): 0.9925\n",
            "CPU times: user 11min 25s, sys: 3min 29s, total: 14min 54s\n",
            "Wall time: 18min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNd7V9ajqPkw",
        "colab_type": "code",
        "outputId": "66a235cb-bfb6-4a0a-8787-ab8cb81eb4e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 4)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfbLSwCp032T",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 20 gen x 2 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLTxO6ll09ah",
        "colab_type": "code",
        "outputId": "b60a1a80-5ba8-473a-d18c-834b0fd387f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.3626 - acc: 0.8795\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0662 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0481 - acc: 0.9858\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0334 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0314 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.3425 - acc: 0.8873\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0595 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0389 - acc: 0.9884\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0332 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0261 - acc: 0.9919\n",
            "10000/10000 [==============================] - 3s 252us/step\n",
            "this gen fitnesses: [0.991  0.9921]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.3743 - acc: 0.8771\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0667 - acc: 0.9798\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0418 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0334 - acc: 0.9897\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0284 - acc: 0.9916\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 418us/step - loss: 0.4037 - acc: 0.8683\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0634 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0469 - acc: 0.9854\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0355 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0310 - acc: 0.9908\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "this gen fitnesses: [0.9896 0.9893]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.2654 - acc: 0.9180\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0554 - acc: 0.9838\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0420 - acc: 0.9874\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0320 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9913 0.9893]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 26s 441us/step - loss: 0.2869 - acc: 0.9105\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.0522 - acc: 0.9840\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.0405 - acc: 0.9876\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.0306 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 248us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 26s 440us/step - loss: 0.2172 - acc: 0.9337\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0410 - acc: 0.9881\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0338 - acc: 0.9900\n",
            "10000/10000 [==============================] - 3s 251us/step\n",
            "this gen fitnesses: [0.9882 0.9865]\n",
            "\t\t\tStarting generation 5...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 27s 442us/step - loss: 0.2547 - acc: 0.9156\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0478 - acc: 0.9858\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0374 - acc: 0.9883\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0298 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 249us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3412 - acc: 0.8876\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0587 - acc: 0.9819\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0393 - acc: 0.9878\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0314 - acc: 0.9903\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0263 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "this gen fitnesses: [0.9895 0.992 ]\n",
            "\t\t\tStarting generation 6...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.1586 - acc: 0.9528\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0327 - acc: 0.9901\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0284 - acc: 0.9916\n",
            "10000/10000 [==============================] - 2s 243us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.987 0.992]\n",
            "\t\t\tStarting generation 7...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.987 0.992]\n",
            "\t\t\tStarting generation 8...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.987 0.992]\n",
            "\t\t\tStarting generation 9...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 26s 441us/step - loss: 0.1657 - acc: 0.9504\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0319 - acc: 0.9905\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0274 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 250us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3311 - acc: 0.8926\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0612 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0410 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0298 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0268 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "this gen fitnesses: [0.992  0.9902]\n",
            "\t\t\tStarting generation 10...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.2730 - acc: 0.9111\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0568 - acc: 0.9827\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0367 - acc: 0.9890\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0313 - acc: 0.9904\n",
            "10000/10000 [==============================] - 2s 239us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.3455 - acc: 0.8870\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0649 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0418 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0339 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0296 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 234us/step\n",
            "this gen fitnesses: [0.9907 0.9885]\n",
            "\t\t\tStarting generation 11...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.1529 - acc: 0.9527\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0428 - acc: 0.9872\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0306 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.2384 - acc: 0.9276\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0504 - acc: 0.9848\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0368 - acc: 0.9889\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0293 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 234us/step\n",
            "this gen fitnesses: [0.9923 0.9907]\n",
            "\t\t\tStarting generation 12...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.2713 - acc: 0.9120\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0546 - acc: 0.9838\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0447 - acc: 0.9869\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0351 - acc: 0.9894\n",
            "10000/10000 [==============================] - 2s 232us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9858 0.9907]\n",
            "\t\t\tStarting generation 13...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.2564 - acc: 0.9153\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0488 - acc: 0.9851\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0363 - acc: 0.9891\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0313 - acc: 0.9906\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "this gen fitnesses: [0.9858 0.9927]\n",
            "\t\t\tStarting generation 14...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9858 0.9927]\n",
            "\t\t\tStarting generation 15...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.4566 - acc: 0.8495\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0670 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0446 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0373 - acc: 0.9889\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0289 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 15s 249us/step - loss: 0.3770 - acc: 0.8751\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0634 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0468 - acc: 0.9860\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0374 - acc: 0.9885\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0291 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 176us/step\n",
            "this gen fitnesses: [0.9875 0.9901]\n",
            "\t\t\tStarting generation 16...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.3939 - acc: 0.8618\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0463 - acc: 0.9864\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0376 - acc: 0.9888\n",
            "10000/10000 [==============================] - 2s 233us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 0.1553 - acc: 0.9523\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0398 - acc: 0.9883\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0294 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 173us/step\n",
            "this gen fitnesses: [0.9916 0.99  ]\n",
            "\t\t\tStarting generation 17...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 1.0689 - acc: 0.6180\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.1359 - acc: 0.9658\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0688 - acc: 0.9819\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0517 - acc: 0.9858\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0364 - acc: 0.9903\n",
            "10000/10000 [==============================] - 2s 217us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.989 0.99 ]\n",
            "\t\t\tStarting generation 18...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.5289 - acc: 0.8377\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0473 - acc: 0.9863\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0317 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 225us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.3368 - acc: 0.8898\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 365us/step - loss: 0.0609 - acc: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0414 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0328 - acc: 0.9903\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0302 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 224us/step\n",
            "this gen fitnesses: [0.9903 0.9913]\n",
            "\t\t\tStarting generation 19...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 15s 249us/step - loss: 0.3377 - acc: 0.8890\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0632 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0455 - acc: 0.9863\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0328 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 14s 232us/step - loss: 0.0287 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 168us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.99   0.9913]\n",
            "\t\t\tStarting generation 20...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.3031 - acc: 0.9001\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0587 - acc: 0.9815\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0398 - acc: 0.9878\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0323 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0264 - acc: 0.9921\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.2482 - acc: 0.9215\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0558 - acc: 0.9829\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0354 - acc: 0.9894\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0304 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 222us/step\n",
            "this gen fitnesses: [0.9877 0.9943]\n",
            "The best individual [0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1] had fitness (accuracy): 0.9943\n",
            "CPU times: user 29min 38s, sys: 9min 6s, total: 38min 44s\n",
            "Wall time: 46min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B3dQCPt9gQN",
        "colab_type": "code",
        "outputId": "16aa4e74-1304-4aad-aa31-d643e819c4a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 2)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVCkLgCRV6htBUDO3bHduHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FqoY7lN9hEN",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 2 gen x 20 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf1-r-G7AFOs",
        "colab_type": "code",
        "outputId": "56f178fb-9ff9-4ce5-b883-f1ee6f93a0dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.3876 - acc: 0.8750\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0704 - acc: 0.9793\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0439 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0367 - acc: 0.9890\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0309 - acc: 0.9904\n",
            "10000/10000 [==============================] - 1s 100us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.2936 - acc: 0.9029\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0553 - acc: 0.9834\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0384 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0316 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0273 - acc: 0.9918\n",
            "10000/10000 [==============================] - 1s 103us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3522 - acc: 0.8898\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0625 - acc: 0.9810\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0442 - acc: 0.9866\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0331 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0272 - acc: 0.9920\n",
            "10000/10000 [==============================] - 1s 77us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.4581 - acc: 0.8456\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0677 - acc: 0.9801\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0445 - acc: 0.9865\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0346 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0284 - acc: 0.9912\n",
            "10000/10000 [==============================] - 1s 106us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.4031 - acc: 0.8736\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0654 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0435 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0310 - acc: 0.9909\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0277 - acc: 0.9915\n",
            "10000/10000 [==============================] - 1s 96us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.3923 - acc: 0.8675\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0714 - acc: 0.9783\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0477 - acc: 0.9856\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0363 - acc: 0.9890\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0321 - acc: 0.9896\n",
            "10000/10000 [==============================] - 1s 106us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 0.4559 - acc: 0.8474\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0706 - acc: 0.9781\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0451 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0365 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0308 - acc: 0.9904\n",
            "10000/10000 [==============================] - 1s 109us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 134us/step - loss: 0.3718 - acc: 0.8817\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0609 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0418 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0331 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0282 - acc: 0.9916\n",
            "10000/10000 [==============================] - 1s 103us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.4742 - acc: 0.8425\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0851 - acc: 0.9752\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0570 - acc: 0.9835\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0424 - acc: 0.9871\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0384 - acc: 0.9885\n",
            "10000/10000 [==============================] - 1s 105us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.3501 - acc: 0.8833\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0636 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0440 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0346 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0276 - acc: 0.9916\n",
            "10000/10000 [==============================] - 1s 97us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.3202 - acc: 0.8999\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0594 - acc: 0.9827\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0428 - acc: 0.9870\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0339 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0269 - acc: 0.9917\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.3404 - acc: 0.8907\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0578 - acc: 0.9825\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0400 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0305 - acc: 0.9906\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0253 - acc: 0.9919\n",
            "10000/10000 [==============================] - 1s 87us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.3721 - acc: 0.8788\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0640 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0416 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0344 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0282 - acc: 0.9917\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.3126 - acc: 0.8980\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0547 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0394 - acc: 0.9882\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0313 - acc: 0.9906\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0284 - acc: 0.9913\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3565 - acc: 0.8831\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0639 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0403 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0310 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0252 - acc: 0.9923\n",
            "10000/10000 [==============================] - 1s 78us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.3306 - acc: 0.8901\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0615 - acc: 0.9815\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0438 - acc: 0.9868\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0353 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0273 - acc: 0.9914\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.3080 - acc: 0.8993\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0614 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0397 - acc: 0.9879\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0331 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0263 - acc: 0.9919\n",
            "10000/10000 [==============================] - 1s 98us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.3643 - acc: 0.8817\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0624 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0437 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0392 - acc: 0.9884\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0302 - acc: 0.9909\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.3666 - acc: 0.8785\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0597 - acc: 0.9816\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0404 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0362 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0288 - acc: 0.9907\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.3566 - acc: 0.8841\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0685 - acc: 0.9790\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0430 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0334 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0288 - acc: 0.9909\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "this gen fitnesses: [0.99   0.9925 0.9867 0.9865 0.9896 0.9879 0.9891 0.991  0.9884 0.9932\n",
            " 0.9874 0.9878 0.9898 0.9936 0.9882 0.9911 0.9885 0.9919 0.9895 0.9922]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.1923 - acc: 0.9368\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0389 - acc: 0.9882\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0281 - acc: 0.9915\n",
            "10000/10000 [==============================] - 1s 101us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.2395 - acc: 0.9220\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0493 - acc: 0.9851\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0329 - acc: 0.9901\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0271 - acc: 0.9918\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.2715 - acc: 0.9121\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0540 - acc: 0.9836\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0352 - acc: 0.9888\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0304 - acc: 0.9906\n",
            "10000/10000 [==============================] - 1s 96us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.2459 - acc: 0.9203\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0490 - acc: 0.9851\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0363 - acc: 0.9885\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0295 - acc: 0.9910\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.2310 - acc: 0.9243\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0493 - acc: 0.9853\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0338 - acc: 0.9893\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0280 - acc: 0.9914\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.2646 - acc: 0.9159\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0542 - acc: 0.9841\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0446 - acc: 0.9865\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0357 - acc: 0.9895\n",
            "10000/10000 [==============================] - 1s 98us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.2801 - acc: 0.9076\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0530 - acc: 0.9842\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0374 - acc: 0.9887\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0301 - acc: 0.9912\n",
            "10000/10000 [==============================] - 1s 103us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.2529 - acc: 0.9167\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0487 - acc: 0.9853\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0385 - acc: 0.9882\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0300 - acc: 0.9910\n",
            "10000/10000 [==============================] - 1s 100us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.2117 - acc: 0.9337\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0399 - acc: 0.9880\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0295 - acc: 0.9912\n",
            "10000/10000 [==============================] - 1s 97us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.3344 - acc: 0.8839\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0550 - acc: 0.9842\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0429 - acc: 0.9875\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0309 - acc: 0.9911\n",
            "10000/10000 [==============================] - 1s 106us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3633 - acc: 0.8822\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0697 - acc: 0.9787\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0440 - acc: 0.9868\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0364 - acc: 0.9890\n",
            "10000/10000 [==============================] - 1s 80us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.2774 - acc: 0.9097\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0495 - acc: 0.9856\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0361 - acc: 0.9890\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0297 - acc: 0.9909\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.1529 - acc: 0.9557\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0334 - acc: 0.9896\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0248 - acc: 0.9921\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9925 0.9929 0.989  0.99   0.9896 0.9917 0.9867 0.9911 0.9903 0.9888\n",
            " 0.9902 0.9876 0.9915 0.9918 0.9882 0.9911 0.9885 0.9919 0.9895 0.9922]\n",
            "The best individual [1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0] had fitness (accuracy): 0.9929\n",
            "CPU times: user 13min 58s, sys: 2min 31s, total: 16min 30s\n",
            "Wall time: 18min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsYjksWrAGES",
        "colab_type": "code",
        "outputId": "01190080-2414-4a75-8ff1-a4a8629db11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 2)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/H85gK2RVF0QKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4qWi23vA1Aj",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 20 gen x 20 individuals, (MNIST/6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOWUaOvEM9QT",
        "colab_type": "code",
        "outputId": "1e82538a-8647-4139-ad49-baf72e4ad6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 563us/step - loss: 1.6660 - acc: 0.4189\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.4824 - acc: 0.8639\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.2324 - acc: 0.9409\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 401us/step - loss: 0.1377 - acc: 0.9625\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.1006 - acc: 0.9694\n",
            "1000/1000 [==============================] - 0s 441us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 609us/step - loss: 1.2173 - acc: 0.5886\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 443us/step - loss: 0.2416 - acc: 0.9298\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.1562 - acc: 0.9531\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.1475 - acc: 0.9587\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 442us/step - loss: 0.0727 - acc: 0.9773\n",
            "1000/1000 [==============================] - 0s 447us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 336us/step - loss: 1.1399 - acc: 0.6049\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 222us/step - loss: 0.2302 - acc: 0.9322\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 227us/step - loss: 0.1246 - acc: 0.9639\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 224us/step - loss: 0.1307 - acc: 0.9613\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 220us/step - loss: 0.0752 - acc: 0.9767\n",
            "1000/1000 [==============================] - 0s 275us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 551us/step - loss: 1.0914 - acc: 0.6362\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 415us/step - loss: 0.2317 - acc: 0.9285\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 417us/step - loss: 0.1584 - acc: 0.9529\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.0910 - acc: 0.9722\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 417us/step - loss: 0.0670 - acc: 0.9795\n",
            "1000/1000 [==============================] - 0s 428us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 540us/step - loss: 1.3536 - acc: 0.5247\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 389us/step - loss: 0.3479 - acc: 0.8985\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1682 - acc: 0.9487\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0967 - acc: 0.9714\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.0871 - acc: 0.9742\n",
            "1000/1000 [==============================] - 0s 370us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 568us/step - loss: 1.5183 - acc: 0.4689\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.4534 - acc: 0.8727\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.2219 - acc: 0.9372\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1933 - acc: 0.9433\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1140 - acc: 0.9671\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 529us/step - loss: 1.2703 - acc: 0.5771\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.2668 - acc: 0.9240\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.1393 - acc: 0.9598\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.1154 - acc: 0.9668\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.0770 - acc: 0.9757\n",
            "1000/1000 [==============================] - 0s 379us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 522us/step - loss: 1.5928 - acc: 0.4507\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.4055 - acc: 0.8821\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.2906 - acc: 0.9164\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 405us/step - loss: 0.1342 - acc: 0.9587\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.1001 - acc: 0.9692\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 512us/step - loss: 1.3681 - acc: 0.5198\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.3895 - acc: 0.8897\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1879 - acc: 0.9489\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1007 - acc: 0.9712\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.0701 - acc: 0.9793\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 1.3622 - acc: 0.5229\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.2965 - acc: 0.9118\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1714 - acc: 0.9492\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.1049 - acc: 0.9693\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 377us/step - loss: 0.0703 - acc: 0.9787\n",
            "1000/1000 [==============================] - 0s 390us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 1.2234 - acc: 0.5844\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2231 - acc: 0.9352\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.1260 - acc: 0.9607\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.1018 - acc: 0.9703\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.0859 - acc: 0.9728\n",
            "1000/1000 [==============================] - 0s 412us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 1.1605 - acc: 0.6178\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 248us/step - loss: 0.2311 - acc: 0.9344\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 250us/step - loss: 0.1541 - acc: 0.9554\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 3s 253us/step - loss: 0.1016 - acc: 0.9703\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.1129 - acc: 0.9653\n",
            "1000/1000 [==============================] - 0s 324us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 575us/step - loss: 1.2704 - acc: 0.5638\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2932 - acc: 0.9123\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.1526 - acc: 0.9537\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.0796 - acc: 0.9762\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0639 - acc: 0.9786\n",
            "1000/1000 [==============================] - 0s 385us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 506us/step - loss: 1.1530 - acc: 0.6048\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.2656 - acc: 0.9240\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1443 - acc: 0.9565\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1266 - acc: 0.9629\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0654 - acc: 0.9813\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 305us/step - loss: 1.2234 - acc: 0.5832\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 209us/step - loss: 0.2958 - acc: 0.9136\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 211us/step - loss: 0.1814 - acc: 0.9478\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 212us/step - loss: 0.1283 - acc: 0.9636\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 209us/step - loss: 0.1000 - acc: 0.9673\n",
            "1000/1000 [==============================] - 0s 269us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 1.1627 - acc: 0.5964\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.3208 - acc: 0.9080\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.1352 - acc: 0.9594\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 369us/step - loss: 0.1057 - acc: 0.9681\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0749 - acc: 0.9767\n",
            "1000/1000 [==============================] - 0s 338us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 482us/step - loss: 1.3871 - acc: 0.5223\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.3492 - acc: 0.9016\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.1750 - acc: 0.9486\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.1230 - acc: 0.9635\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 0.0813 - acc: 0.9751\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 503us/step - loss: 2.1667 - acc: 0.1889\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.6785 - acc: 0.7920\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.2162 - acc: 0.9369\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1514 - acc: 0.9553\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.0916 - acc: 0.9732\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 1.5228 - acc: 0.4723\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.4746 - acc: 0.8671\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.1954 - acc: 0.9448\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.1376 - acc: 0.9631\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.1112 - acc: 0.9668\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 551us/step - loss: 1.2704 - acc: 0.5748\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.2902 - acc: 0.9187\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1512 - acc: 0.9552\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1214 - acc: 0.9644\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0922 - acc: 0.9732\n",
            "1000/1000 [==============================] - 0s 414us/step\n",
            "this gen fitnesses: [0.953 0.963 0.971 0.97  0.962 0.965 0.978 0.96  0.945 0.969 0.975 0.969\n",
            " 0.969 0.958 0.971 0.957 0.958 0.965 0.962 0.962]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 541us/step - loss: 1.3016 - acc: 0.5956\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2095 - acc: 0.9394\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.1501 - acc: 0.9550\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0759 - acc: 0.9778\n",
            "1000/1000 [==============================] - 0s 396us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 2.3399 - acc: 0.1481\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.9962 - acc: 0.6880\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.2782 - acc: 0.9243\n",
            "1000/1000 [==============================] - 0s 406us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 1.0146 - acc: 0.6580\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.2145 - acc: 0.9368\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 342us/step - loss: 0.1664 - acc: 0.9529\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 344us/step - loss: 0.1095 - acc: 0.9687\n",
            "1000/1000 [==============================] - 0s 338us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 1.1754 - acc: 0.6019\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.2820 - acc: 0.9186\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1664 - acc: 0.9499\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1028 - acc: 0.9693\n",
            "1000/1000 [==============================] - 0s 398us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 309us/step - loss: 1.3912 - acc: 0.5370\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.2979 - acc: 0.9094\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 229us/step - loss: 0.1510 - acc: 0.9528\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.0876 - acc: 0.9728\n",
            "1000/1000 [==============================] - 0s 289us/step\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 535us/step - loss: 1.4410 - acc: 0.5081\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.2944 - acc: 0.9164\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.1476 - acc: 0.9561\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.1081 - acc: 0.9680\n",
            "1000/1000 [==============================] - 0s 385us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 489us/step - loss: 1.2471 - acc: 0.5966\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.2144 - acc: 0.9401\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1427 - acc: 0.9579\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 492us/step - loss: 0.9091 - acc: 0.7095\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1434 - acc: 0.9596\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0873 - acc: 0.9747\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 492us/step - loss: 0.9396 - acc: 0.7127\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1548 - acc: 0.9557\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0912 - acc: 0.9735\n",
            "1000/1000 [==============================] - 0s 378us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.2574 - acc: 0.5890\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.2237 - acc: 0.9337\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1285 - acc: 0.9616\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1047 - acc: 0.9698\n",
            "1000/1000 [==============================] - 0s 368us/step\n",
            "this gen fitnesses: [0.975 0.909 0.961 0.971 0.962 0.965 0.978 0.96  0.945 0.965 0.975 0.969\n",
            " 0.952 0.958 0.971 0.957 0.942 0.959 0.97  0.961]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.7745 - acc: 0.7408\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.1914 - acc: 0.9416\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 0.0897 - acc: 0.9736\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.0685 - acc: 0.9782\n",
            "1000/1000 [==============================] - 0s 354us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 555us/step - loss: 1.5084 - acc: 0.4928\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.3587 - acc: 0.8969\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.2054 - acc: 0.9456\n",
            "1000/1000 [==============================] - 0s 388us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.5155 - acc: 0.5327\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 416us/step - loss: 0.3211 - acc: 0.9048\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 416us/step - loss: 0.1646 - acc: 0.9482\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 415us/step - loss: 0.0853 - acc: 0.9727\n",
            "1000/1000 [==============================] - 0s 376us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 324us/step - loss: 1.0635 - acc: 0.6693\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 232us/step - loss: 0.2180 - acc: 0.9392\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 233us/step - loss: 0.1200 - acc: 0.9658\n",
            "1000/1000 [==============================] - 0s 296us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 543us/step - loss: 0.9416 - acc: 0.6850\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.1775 - acc: 0.9452\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0918 - acc: 0.9736\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.0651 - acc: 0.9806\n",
            "1000/1000 [==============================] - 0s 395us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 550us/step - loss: 0.9617 - acc: 0.6779\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1985 - acc: 0.9412\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1383 - acc: 0.9582\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0943 - acc: 0.9722\n",
            "1000/1000 [==============================] - 0s 394us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 310us/step - loss: 0.9580 - acc: 0.6906\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.1632 - acc: 0.9503\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 229us/step - loss: 0.1146 - acc: 0.9675\n",
            "1000/1000 [==============================] - 0s 287us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 474us/step - loss: 1.4353 - acc: 0.5341\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.2191 - acc: 0.9340\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.1104 - acc: 0.9665\n",
            "1000/1000 [==============================] - 0s 370us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 1.4935 - acc: 0.4923\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.4803 - acc: 0.8394\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1972 - acc: 0.9416\n",
            "1000/1000 [==============================] - 0s 367us/step\n",
            "this gen fitnesses: [0.975 0.909 0.961 0.971 0.979 0.945 0.978 0.96  0.954 0.941 0.965 0.969\n",
            " 0.948 0.958 0.964 0.948 0.942 0.959 0.97  0.944]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 2.2903 - acc: 0.1438\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 1.3174 - acc: 0.5681\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.4004 - acc: 0.8822\n",
            "1000/1000 [==============================] - 0s 394us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 499us/step - loss: 1.3784 - acc: 0.5263\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 403us/step - loss: 0.2715 - acc: 0.9229\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1496 - acc: 0.9595\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.0923 - acc: 0.9720\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 0.9960 - acc: 0.6976\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1882 - acc: 0.9453\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1030 - acc: 0.9695\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1620 - acc: 0.9544\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 509us/step - loss: 1.3145 - acc: 0.5560\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.2387 - acc: 0.9266\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 405us/step - loss: 0.1386 - acc: 0.9599\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.1788 - acc: 0.9432\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 536us/step - loss: 1.1034 - acc: 0.6180\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2040 - acc: 0.9395\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1315 - acc: 0.9628\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0990 - acc: 0.9712\n",
            "1000/1000 [==============================] - 0s 420us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 529us/step - loss: 0.9573 - acc: 0.6781\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.1745 - acc: 0.9488\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.1089 - acc: 0.9664\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.0609 - acc: 0.9816\n",
            "1000/1000 [==============================] - 0s 445us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 307us/step - loss: 1.1201 - acc: 0.6314\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.2595 - acc: 0.9328\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.1180 - acc: 0.9674\n",
            "1000/1000 [==============================] - 0s 305us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 555us/step - loss: 1.1184 - acc: 0.6174\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.2393 - acc: 0.9308\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.1168 - acc: 0.9671\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.0787 - acc: 0.9774\n",
            "1000/1000 [==============================] - 0s 419us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 0.9039 - acc: 0.7052\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 376us/step - loss: 0.1804 - acc: 0.9486\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.0959 - acc: 0.9729\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.0826 - acc: 0.9760\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 538us/step - loss: 0.9665 - acc: 0.6666\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1908 - acc: 0.9438\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.1038 - acc: 0.9697\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0699 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 419us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 283us/step - loss: 1.1804 - acc: 0.6047\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 207us/step - loss: 0.2847 - acc: 0.9161\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 210us/step - loss: 0.1437 - acc: 0.9597\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 206us/step - loss: 0.0824 - acc: 0.9756\n",
            "1000/1000 [==============================] - 0s 265us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 1.0071 - acc: 0.6555\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1664 - acc: 0.9549\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.1147 - acc: 0.9653\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.0744 - acc: 0.9785\n",
            "1000/1000 [==============================] - 0s 341us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 1.3179 - acc: 0.5481\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.2560 - acc: 0.9276\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1439 - acc: 0.9595\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1015 - acc: 0.9707\n",
            "1000/1000 [==============================] - 0s 344us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 1.0542 - acc: 0.6491\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.1885 - acc: 0.9452\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.1027 - acc: 0.9702\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 443us/step - loss: 0.0816 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 442us/step\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 0.5816 - acc: 0.8192\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0995 - acc: 0.9695\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0782 - acc: 0.9780\n",
            "1000/1000 [==============================] - 0s 408us/step\n",
            "this gen fitnesses: [0.938 0.909 0.965 0.955 0.951 0.947 0.978 0.96  0.959 0.967 0.969 0.97\n",
            " 0.965 0.958 0.946 0.962 0.964 0.953 0.97  0.96 ]\n",
            "\t\t\tStarting generation 5...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 584us/step - loss: 0.7857 - acc: 0.7409\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.1369 - acc: 0.9603\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.0947 - acc: 0.9713\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.0688 - acc: 0.9790\n",
            "1000/1000 [==============================] - 0s 449us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 546us/step - loss: 0.8820 - acc: 0.6976\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1758 - acc: 0.9486\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.0945 - acc: 0.9721\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0775 - acc: 0.9770\n",
            "1000/1000 [==============================] - 0s 411us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 1.4044 - acc: 0.5226\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 256us/step - loss: 0.2432 - acc: 0.9276\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.1553 - acc: 0.9541\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.1076 - acc: 0.9666\n",
            "1000/1000 [==============================] - 0s 349us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 519us/step - loss: 0.6625 - acc: 0.7874\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.1192 - acc: 0.9643\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.0811 - acc: 0.9755\n",
            "1000/1000 [==============================] - 0s 361us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 498us/step - loss: 0.8904 - acc: 0.6966\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1585 - acc: 0.9523\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1485 - acc: 0.9573\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0760 - acc: 0.9781\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 0.9327 - acc: 0.7200\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1851 - acc: 0.9472\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0991 - acc: 0.9686\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0945 - acc: 0.9707\n",
            "1000/1000 [==============================] - 0s 374us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.967 0.94  0.965 0.953 0.972 0.947 0.978 0.96  0.959 0.967 0.969 0.97\n",
            " 0.965 0.958 0.946 0.962 0.969 0.953 0.953 0.96 ]\n",
            "\t\t\tStarting generation 6...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 523us/step - loss: 0.8826 - acc: 0.7016\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.1711 - acc: 0.9505\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1013 - acc: 0.9693\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.0724 - acc: 0.9777\n",
            "1000/1000 [==============================] - 0s 426us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 1.4484 - acc: 0.5152\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.2690 - acc: 0.9246\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1414 - acc: 0.9602\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.0972 - acc: 0.9722\n",
            "1000/1000 [==============================] - 0s 371us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 325us/step - loss: 1.3349 - acc: 0.5406\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 241us/step - loss: 0.2809 - acc: 0.9126\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 239us/step - loss: 0.1831 - acc: 0.9468\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 235us/step - loss: 0.1132 - acc: 0.9645\n",
            "1000/1000 [==============================] - 0s 308us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 533us/step - loss: 1.3197 - acc: 0.5890\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 419us/step - loss: 0.1922 - acc: 0.9455\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.1070 - acc: 0.9679\n",
            "1000/1000 [==============================] - 0s 443us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 552us/step - loss: 0.7135 - acc: 0.7762\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1978 - acc: 0.9462\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 413us/step - loss: 0.0897 - acc: 0.9753\n",
            "1000/1000 [==============================] - 0s 415us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.8273 - acc: 0.7562\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 202us/step - loss: 0.1695 - acc: 0.9501\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 197us/step - loss: 0.1051 - acc: 0.9685\n",
            "1000/1000 [==============================] - 0s 281us/step\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 487us/step - loss: 1.0769 - acc: 0.6654\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 374us/step - loss: 0.1511 - acc: 0.9551\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.1092 - acc: 0.9677\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.9539 - acc: 0.6800\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 344us/step - loss: 0.2063 - acc: 0.9398\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1165 - acc: 0.9645\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 343us/step - loss: 0.1284 - acc: 0.9632\n",
            "1000/1000 [==============================] - 0s 325us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 306us/step - loss: 1.0056 - acc: 0.6759\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1861 - acc: 0.9470\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 227us/step - loss: 0.0973 - acc: 0.9716\n",
            "1000/1000 [==============================] - 0s 333us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 579us/step - loss: 1.0642 - acc: 0.6546\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.1779 - acc: 0.9463\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.0908 - acc: 0.9726\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1051 - acc: 0.9694\n",
            "1000/1000 [==============================] - 0s 433us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 0.8855 - acc: 0.7058\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.1656 - acc: 0.9542\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 356us/step - loss: 0.1173 - acc: 0.9651\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 354us/step - loss: 0.1030 - acc: 0.9712\n",
            "1000/1000 [==============================] - 0s 344us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 502us/step - loss: 1.1888 - acc: 0.6292\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1691 - acc: 0.9528\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0787 - acc: 0.9772\n",
            "1000/1000 [==============================] - 0s 380us/step\n",
            "this gen fitnesses: [0.967 0.952 0.929 0.956 0.972 0.947 0.97  0.969 0.959 0.962 0.969 0.97\n",
            " 0.965 0.958 0.961 0.956 0.969 0.973 0.958 0.956]\n",
            "\t\t\tStarting generation 7...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 1.7073 - acc: 0.4471\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2852 - acc: 0.9180\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.1432 - acc: 0.9569\n",
            "1000/1000 [==============================] - 0s 440us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 512us/step - loss: 0.8972 - acc: 0.6950\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.1786 - acc: 0.9486\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.1114 - acc: 0.9670\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.0897 - acc: 0.9756\n",
            "1000/1000 [==============================] - 0s 388us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 502us/step - loss: 1.2295 - acc: 0.6282\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.2011 - acc: 0.9421\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1368 - acc: 0.9598\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0798 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 480us/step - loss: 1.1172 - acc: 0.6359\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.1975 - acc: 0.9482\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 377us/step - loss: 0.1065 - acc: 0.9685\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 378us/step - loss: 0.0764 - acc: 0.9783\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 318us/step - loss: 1.2108 - acc: 0.5865\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 225us/step - loss: 0.3488 - acc: 0.8967\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.2064 - acc: 0.9387\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 224us/step - loss: 0.1111 - acc: 0.9675\n",
            "1000/1000 [==============================] - 0s 291us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 1.1441 - acc: 0.6043\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.2068 - acc: 0.9425\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.1113 - acc: 0.9695\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.0729 - acc: 0.9783\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 544us/step - loss: 1.1818 - acc: 0.5906\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1800 - acc: 0.9508\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1534 - acc: 0.9581\n",
            "1000/1000 [==============================] - 0s 397us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.8754 - acc: 0.6989\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.1780 - acc: 0.9496\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 357us/step - loss: 0.0963 - acc: 0.9694\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 358us/step - loss: 0.0811 - acc: 0.9748\n",
            "1000/1000 [==============================] - 0s 333us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 499us/step - loss: 1.0819 - acc: 0.6296\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1936 - acc: 0.9437\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.1248 - acc: 0.9658\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0753 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 373us/step\n",
            "this gen fitnesses: [0.948 0.952 0.929 0.956 0.972 0.947 0.97  0.973 0.959 0.962 0.97  0.951\n",
            " 0.965 0.958 0.961 0.924 0.953 0.962 0.966 0.967]\n",
            "\t\t\tStarting generation 8...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 529us/step - loss: 1.1552 - acc: 0.6000\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2247 - acc: 0.9364\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.1506 - acc: 0.9581\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.0838 - acc: 0.9768\n",
            "1000/1000 [==============================] - 0s 424us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 1.2012 - acc: 0.6362\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1650 - acc: 0.9513\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1003 - acc: 0.9709\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.0664 - acc: 0.9798\n",
            "1000/1000 [==============================] - 0s 425us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 528us/step - loss: 1.0970 - acc: 0.6368\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 413us/step - loss: 0.2126 - acc: 0.9397\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.1208 - acc: 0.9625\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.0799 - acc: 0.9757\n",
            "1000/1000 [==============================] - 0s 390us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 498us/step - loss: 1.3545 - acc: 0.5447\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.2648 - acc: 0.9243\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1426 - acc: 0.9593\n",
            "1000/1000 [==============================] - 0s 380us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 470us/step - loss: 1.4278 - acc: 0.5418\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.2222 - acc: 0.9366\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 369us/step - loss: 0.1122 - acc: 0.9670\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.0729 - acc: 0.9782\n",
            "1000/1000 [==============================] - 0s 381us/step\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.948 0.952 0.929 0.956 0.97  0.947 0.97  0.973 0.959 0.962 0.964 0.951\n",
            " 0.969 0.961 0.961 0.924 0.952 0.962 0.966 0.967]\n",
            "\t\t\tStarting generation 9...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 579us/step - loss: 2.0633 - acc: 0.2697\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.6709 - acc: 0.7743\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2602 - acc: 0.9365\n",
            "1000/1000 [==============================] - 0s 418us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 459us/step - loss: 1.1847 - acc: 0.5875\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.2694 - acc: 0.9292\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1531 - acc: 0.9547\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.0913 - acc: 0.9752\n",
            "1000/1000 [==============================] - 0s 359us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 481us/step - loss: 0.9495 - acc: 0.6693\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.1421 - acc: 0.9532\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.1123 - acc: 0.9655\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0799 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 351us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 463us/step - loss: 0.8825 - acc: 0.6969\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.1593 - acc: 0.9517\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0913 - acc: 0.9708\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.0734 - acc: 0.9766\n",
            "1000/1000 [==============================] - 0s 359us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.2127 - acc: 0.6003\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.2423 - acc: 0.9336\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 419us/step - loss: 0.1457 - acc: 0.9599\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 417us/step - loss: 0.0940 - acc: 0.9720\n",
            "1000/1000 [==============================] - 0s 401us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 1.0312 - acc: 0.6428\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.1826 - acc: 0.9492\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1357 - acc: 0.9603\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0837 - acc: 0.9754\n",
            "1000/1000 [==============================] - 0s 377us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 556us/step - loss: 0.8557 - acc: 0.7148\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.1596 - acc: 0.9537\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.1027 - acc: 0.9715\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1115 - acc: 0.9655\n",
            "1000/1000 [==============================] - 0s 383us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 319us/step - loss: 1.0096 - acc: 0.6755\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 223us/step - loss: 0.1801 - acc: 0.9466\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.1520 - acc: 0.9553\n",
            "1000/1000 [==============================] - 0s 282us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 496us/step - loss: 0.8260 - acc: 0.7262\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1509 - acc: 0.9548\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.0908 - acc: 0.9729\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0728 - acc: 0.9785\n",
            "1000/1000 [==============================] - 0s 376us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 1.1201 - acc: 0.6265\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.2313 - acc: 0.9371\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1263 - acc: 0.9661\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1579 - acc: 0.9564\n",
            "1000/1000 [==============================] - 0s 367us/step\n",
            "this gen fitnesses: [0.948 0.944 0.974 0.912 0.97  0.947 0.97  0.968 0.959 0.962 0.964 0.973\n",
            " 0.973 0.963 0.961 0.948 0.952 0.962 0.974 0.969]\n",
            "\t\t\tStarting generation 10...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 1.1676 - acc: 0.5787\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.2067 - acc: 0.9419\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1004 - acc: 0.9706\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0786 - acc: 0.9779\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 1.5247 - acc: 0.4942\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.3387 - acc: 0.9076\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.1577 - acc: 0.9555\n",
            "1000/1000 [==============================] - 0s 375us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.1761 - acc: 0.6693\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1498 - acc: 0.9580\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.1173 - acc: 0.9652\n",
            "1000/1000 [==============================] - 0s 401us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 560us/step - loss: 0.7499 - acc: 0.7551\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1320 - acc: 0.9625\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1029 - acc: 0.9709\n",
            "1000/1000 [==============================] - 0s 399us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 511us/step - loss: 0.9984 - acc: 0.6636\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1725 - acc: 0.9507\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0764 - acc: 0.9782\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1212 - acc: 0.9649\n",
            "1000/1000 [==============================] - 0s 398us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 569us/step - loss: 0.9079 - acc: 0.7020\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1870 - acc: 0.9429\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.0925 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0573 - acc: 0.9837\n",
            "1000/1000 [==============================] - 0s 407us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.9918 - acc: 0.6845\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1612 - acc: 0.9533\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0883 - acc: 0.9745\n",
            "1000/1000 [==============================] - 0s 328us/step\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.4961 - acc: 0.5574\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 415us/step - loss: 0.2729 - acc: 0.9105\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1535 - acc: 0.9545\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.968 0.944 0.951 0.959 0.97  0.964 0.97  0.968 0.959 0.962 0.965 0.973\n",
            " 0.973 0.972 0.962 0.948 0.952 0.962 0.934 0.969]\n",
            "\t\t\tStarting generation 11...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 505us/step - loss: 1.4597 - acc: 0.4835\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 0.2850 - acc: 0.9265\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1635 - acc: 0.9599\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0910 - acc: 0.9764\n",
            "1000/1000 [==============================] - 0s 398us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 535us/step - loss: 0.9535 - acc: 0.6833\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1701 - acc: 0.9502\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0865 - acc: 0.9733\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0846 - acc: 0.9738\n",
            "1000/1000 [==============================] - 0s 406us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.7617 - acc: 0.7319\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.1452 - acc: 0.9567\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0936 - acc: 0.9721\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.0577 - acc: 0.9813\n",
            "1000/1000 [==============================] - 0s 350us/step\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 509us/step - loss: 0.9242 - acc: 0.6904\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 401us/step - loss: 0.1523 - acc: 0.9545\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0851 - acc: 0.9753\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0724 - acc: 0.9790\n",
            "1000/1000 [==============================] - 0s 378us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 518us/step - loss: 0.8795 - acc: 0.7198\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1420 - acc: 0.9573\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.2007 - acc: 0.9411\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.0664 - acc: 0.9806\n",
            "1000/1000 [==============================] - 0s 377us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 292us/step - loss: 1.2151 - acc: 0.5831\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 214us/step - loss: 0.2329 - acc: 0.9325\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 214us/step - loss: 0.1463 - acc: 0.9575\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 217us/step - loss: 0.0966 - acc: 0.9721\n",
            "1000/1000 [==============================] - 0s 267us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 511us/step - loss: 1.2017 - acc: 0.5840\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.2136 - acc: 0.9396\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1073 - acc: 0.9698\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1087 - acc: 0.9683\n",
            "1000/1000 [==============================] - 0s 387us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 1.1481 - acc: 0.6202\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.1686 - acc: 0.9517\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1042 - acc: 0.9682\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.0876 - acc: 0.9737\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 503us/step - loss: 2.2209 - acc: 0.1898\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.7681 - acc: 0.7546\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.2070 - acc: 0.9408\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 483us/step - loss: 1.0622 - acc: 0.6461\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1570 - acc: 0.9550\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1065 - acc: 0.9684\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0833 - acc: 0.9749\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 537us/step - loss: 0.9903 - acc: 0.6680\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1691 - acc: 0.9524\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1163 - acc: 0.9670\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0946 - acc: 0.9738\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "this gen fitnesses: [0.968 0.962 0.985 0.959 0.97  0.972 0.97  0.968 0.974 0.954 0.968 0.953\n",
            " 0.92  0.972 0.962 0.948 0.967 0.962 0.934 0.972]\n",
            "\t\t\tStarting generation 12...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 558us/step - loss: 1.2365 - acc: 0.5931\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.3244 - acc: 0.9121\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1414 - acc: 0.9584\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1061 - acc: 0.9684\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.0868 - acc: 0.9741\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.9942 - acc: 0.6888\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1419 - acc: 0.9601\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0765 - acc: 0.9779\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 0.9884 - acc: 0.6707\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1612 - acc: 0.9568\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1188 - acc: 0.9692\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.2310 - acc: 0.5776\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.2016 - acc: 0.9410\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1032 - acc: 0.9718\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0959 - acc: 0.9715\n",
            "1000/1000 [==============================] - 0s 385us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 515us/step - loss: 1.0448 - acc: 0.6572\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.1392 - acc: 0.9586\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1360 - acc: 0.9571\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 413us/step - loss: 0.0698 - acc: 0.9788\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 534us/step - loss: 1.3993 - acc: 0.5516\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1968 - acc: 0.9421\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1521 - acc: 0.9537\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0709 - acc: 0.9784\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 1.5430 - acc: 0.4833\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1912 - acc: 0.9447\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.0902 - acc: 0.9719\n",
            "1000/1000 [==============================] - 0s 395us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 1.5581 - acc: 0.5160\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1956 - acc: 0.9459\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.1645 - acc: 0.9559\n",
            "1000/1000 [==============================] - 0s 333us/step\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 567us/step - loss: 1.3085 - acc: 0.5665\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.2687 - acc: 0.9214\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1877 - acc: 0.9437\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1064 - acc: 0.9700\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0657 - acc: 0.9811\n",
            "1000/1000 [==============================] - 0s 405us/step\n",
            "this gen fitnesses: [0.968 0.961 0.985 0.97  0.97  0.972 0.967 0.959 0.975 0.954 0.98  0.965\n",
            " 0.92  0.972 0.969 0.948 0.967 0.962 0.934 0.971]\n",
            "\t\t\tStarting generation 13...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 2.2765 - acc: 0.2031\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.5576 - acc: 0.8292\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.1983 - acc: 0.9396\n",
            "1000/1000 [==============================] - 0s 413us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 444us/step - loss: 0.9740 - acc: 0.6734\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 344us/step - loss: 0.1579 - acc: 0.9508\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 342us/step - loss: 0.0804 - acc: 0.9758\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 343us/step - loss: 0.0536 - acc: 0.9842\n",
            "1000/1000 [==============================] - 0s 335us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 467us/step - loss: 1.1945 - acc: 0.6430\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.1065 - acc: 0.9698\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0622 - acc: 0.9802\n",
            "1000/1000 [==============================] - 0s 365us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 489us/step - loss: 1.2135 - acc: 0.5763\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1807 - acc: 0.9510\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0985 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0672 - acc: 0.9800\n",
            "1000/1000 [==============================] - 0s 372us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 1.2222 - acc: 0.5711\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.3573 - acc: 0.8994\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1262 - acc: 0.9648\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.0919 - acc: 0.9712\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 313us/step - loss: 1.3471 - acc: 0.5652\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 233us/step - loss: 0.3310 - acc: 0.9057\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 230us/step - loss: 0.1709 - acc: 0.9468\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.1164 - acc: 0.9643\n",
            "1000/1000 [==============================] - 0s 287us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 532us/step - loss: 1.2733 - acc: 0.5647\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 405us/step - loss: 0.2148 - acc: 0.9363\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 408us/step - loss: 0.1222 - acc: 0.9628\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.0968 - acc: 0.9702\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 2.0434 - acc: 0.2971\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.4022 - acc: 0.8819\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1643 - acc: 0.9521\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.8196 - acc: 0.7282\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1520 - acc: 0.9579\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0809 - acc: 0.9752\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 338us/step - loss: 0.0666 - acc: 0.9816\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 312us/step - loss: 1.0118 - acc: 0.6605\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.1820 - acc: 0.9454\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.0981 - acc: 0.9698\n",
            "1000/1000 [==============================] - 0s 292us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 1.2380 - acc: 0.5847\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.2001 - acc: 0.9427\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.1124 - acc: 0.9671\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0802 - acc: 0.9765\n",
            "1000/1000 [==============================] - 0s 401us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.968 0.95  0.955 0.975 0.753 0.972 0.948 0.959 0.975 0.963 0.953 0.952\n",
            " 0.92  0.972 0.952 0.961 0.967 0.962 0.972 0.971]\n",
            "\t\t\tStarting generation 14...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.0847 - acc: 0.6259\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.2118 - acc: 0.9383\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1412 - acc: 0.9602\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1021 - acc: 0.9710\n",
            "1000/1000 [==============================] - 0s 397us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 1.0488 - acc: 0.6545\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 277us/step - loss: 0.1614 - acc: 0.9542\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 277us/step - loss: 0.0980 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 277us/step - loss: 0.0802 - acc: 0.9763\n",
            "1000/1000 [==============================] - 0s 287us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 480us/step - loss: 0.8791 - acc: 0.6848\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1008 - acc: 0.9726\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0706 - acc: 0.9788\n",
            "1000/1000 [==============================] - 0s 367us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.1032 - acc: 0.6273\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.1654 - acc: 0.9534\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0806 - acc: 0.9746\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.0773 - acc: 0.9759\n",
            "1000/1000 [==============================] - 0s 394us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 342us/step - loss: 1.2847 - acc: 0.5745\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 245us/step - loss: 0.3646 - acc: 0.8920\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 249us/step - loss: 0.1632 - acc: 0.9505\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 249us/step - loss: 0.1111 - acc: 0.9655\n",
            "1000/1000 [==============================] - 0s 311us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 492us/step - loss: 1.0044 - acc: 0.6475\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.1768 - acc: 0.9484\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 380us/step - loss: 0.1026 - acc: 0.9696\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0707 - acc: 0.9788\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 291us/step - loss: 1.1096 - acc: 0.6189\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 216us/step - loss: 0.2711 - acc: 0.9211\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1652 - acc: 0.9506\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1032 - acc: 0.9695\n",
            "1000/1000 [==============================] - 0s 274us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 484us/step - loss: 1.0538 - acc: 0.6454\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1881 - acc: 0.9470\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0873 - acc: 0.9765\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.0608 - acc: 0.9811\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 510us/step - loss: 0.9058 - acc: 0.7149\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1466 - acc: 0.9566\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.1075 - acc: 0.9672\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.0816 - acc: 0.9747\n",
            "1000/1000 [==============================] - 0s 370us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 1.1231 - acc: 0.6466\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.1610 - acc: 0.9514\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.1126 - acc: 0.9677\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0622 - acc: 0.9801\n",
            "1000/1000 [==============================] - 0s 349us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 0.7711 - acc: 0.7532\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.1466 - acc: 0.9612\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.1079 - acc: 0.9699\n",
            "1000/1000 [==============================] - 0s 415us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 2s 224us/step - loss: 1.0559 - acc: 0.6547\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.2419 - acc: 0.9284\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.1223 - acc: 0.9631\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.0865 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 245us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 328us/step - loss: 0.6663 - acc: 0.7898\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 229us/step - loss: 0.1120 - acc: 0.9678\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 227us/step - loss: 0.0808 - acc: 0.9743\n",
            "1000/1000 [==============================] - 0s 285us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.0477 - acc: 0.6508\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1610 - acc: 0.9535\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1016 - acc: 0.9699\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0767 - acc: 0.9768\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 514us/step - loss: 0.9374 - acc: 0.6876\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1494 - acc: 0.9542\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 408us/step - loss: 0.0869 - acc: 0.9716\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.0723 - acc: 0.9774\n",
            "1000/1000 [==============================] - 0s 386us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 541us/step - loss: 2.2074 - acc: 0.1671\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.6606 - acc: 0.8013\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1710 - acc: 0.9520\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.968 0.962 0.923 0.968 0.753 0.972 0.949 0.958 0.975 0.955 0.946 0.942\n",
            " 0.965 0.948 0.967 0.944 0.956 0.952 0.948 0.971]\n",
            "\t\t\tStarting generation 15...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.9905 - acc: 0.6689\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.1725 - acc: 0.9503\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0835 - acc: 0.9760\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0838 - acc: 0.9738\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 296us/step - loss: 1.0721 - acc: 0.6286\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.2233 - acc: 0.9362\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 218us/step - loss: 0.1603 - acc: 0.9514\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 219us/step - loss: 0.1200 - acc: 0.9629\n",
            "1000/1000 [==============================] - 0s 278us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.8150 - acc: 0.7314\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.1303 - acc: 0.9627\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.0845 - acc: 0.9756\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.0867 - acc: 0.9757\n",
            "1000/1000 [==============================] - 0s 350us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.0537 - acc: 0.6584\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1432 - acc: 0.9575\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1023 - acc: 0.9711\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.0663 - acc: 0.9801\n",
            "1000/1000 [==============================] - 0s 368us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 491us/step - loss: 1.5992 - acc: 0.4457\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.5759 - acc: 0.8194\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.2550 - acc: 0.9230\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1368 - acc: 0.9621\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 505us/step - loss: 1.3305 - acc: 0.5742\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1604 - acc: 0.9523\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0899 - acc: 0.9717\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.0590 - acc: 0.9813\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 497us/step - loss: 1.0935 - acc: 0.6306\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.2150 - acc: 0.9398\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1509 - acc: 0.9567\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.0800 - acc: 0.9761\n",
            "1000/1000 [==============================] - 0s 371us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 2s 222us/step - loss: 0.8903 - acc: 0.7170\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 158us/step - loss: 0.1731 - acc: 0.9495\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.0951 - acc: 0.9724\n",
            "1000/1000 [==============================] - 0s 261us/step\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 1.3464 - acc: 0.5283\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.3273 - acc: 0.9127\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1202 - acc: 0.9649\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0896 - acc: 0.9715\n",
            "1000/1000 [==============================] - 0s 327us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 494us/step - loss: 1.2062 - acc: 0.6449\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1814 - acc: 0.9505\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1035 - acc: 0.9697\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 2.0327 - acc: 0.3189\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.5969 - acc: 0.8240\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1584 - acc: 0.9549\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 547us/step - loss: 1.0940 - acc: 0.6861\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.2172 - acc: 0.9377\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1188 - acc: 0.9667\n",
            "1000/1000 [==============================] - 0s 418us/step\n",
            "this gen fitnesses: [0.944 0.962 0.923 0.966 0.973 0.945 0.949 0.954 0.978 0.955 0.946 0.971\n",
            " 0.965 0.948 0.92  0.944 0.976 0.97  0.959 0.956]\n",
            "\t\t\tStarting generation 16...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 1.2102 - acc: 0.5991\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.1964 - acc: 0.9439\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.0924 - acc: 0.9746\n",
            "1000/1000 [==============================] - 0s 294us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 1.0549 - acc: 0.6634\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1578 - acc: 0.9548\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1065 - acc: 0.9715\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.0692 - acc: 0.9796\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 514us/step - loss: 1.1140 - acc: 0.6025\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.1772 - acc: 0.9470\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.0849 - acc: 0.9758\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.0624 - acc: 0.9807\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 559us/step - loss: 1.1048 - acc: 0.6355\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1409 - acc: 0.9610\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1116 - acc: 0.9675\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.0663 - acc: 0.9798\n",
            "1000/1000 [==============================] - 0s 404us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.9416 - acc: 0.6913\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 334us/step - loss: 0.1733 - acc: 0.9488\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 334us/step - loss: 0.0906 - acc: 0.9744\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 336us/step - loss: 0.0942 - acc: 0.9726\n",
            "1000/1000 [==============================] - 0s 320us/step\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.9493 - acc: 0.7291\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.1358 - acc: 0.9580\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.0891 - acc: 0.9715\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 279us/step - loss: 0.0514 - acc: 0.9832\n",
            "1000/1000 [==============================] - 0s 296us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 1.0799 - acc: 0.6253\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 0.1590 - acc: 0.9545\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0856 - acc: 0.9753\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.0670 - acc: 0.9801\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 501us/step - loss: 0.7873 - acc: 0.7239\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1620 - acc: 0.9521\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.0962 - acc: 0.9710\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 401us/step - loss: 0.0989 - acc: 0.9698\n",
            "1000/1000 [==============================] - 0s 368us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 525us/step - loss: 0.8314 - acc: 0.7173\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1348 - acc: 0.9608\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.1112 - acc: 0.9695\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.0977 - acc: 0.9721\n",
            "1000/1000 [==============================] - 0s 377us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 487us/step - loss: 1.0426 - acc: 0.6669\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.2435 - acc: 0.9309\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.0971 - acc: 0.9712\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0716 - acc: 0.9785\n",
            "1000/1000 [==============================] - 0s 371us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 538us/step - loss: 0.9572 - acc: 0.6886\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1547 - acc: 0.9519\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.0958 - acc: 0.9718\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0814 - acc: 0.9754\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "this gen fitnesses: [0.944 0.962 0.947 0.979 0.964 0.975 0.949 0.954 0.978 0.973 0.946 0.971\n",
            " 0.965 0.948 0.959 0.951 0.97  0.961 0.972 0.969]\n",
            "\t\t\tStarting generation 17...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 553us/step - loss: 0.8288 - acc: 0.7446\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1261 - acc: 0.9606\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0826 - acc: 0.9748\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0781 - acc: 0.9777\n",
            "1000/1000 [==============================] - 0s 418us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.8990 - acc: 0.7144\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.2085 - acc: 0.9438\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0891 - acc: 0.9745\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0828 - acc: 0.9756\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 489us/step - loss: 2.4978 - acc: 0.2492\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.5596 - acc: 0.8293\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.2062 - acc: 0.9365\n",
            "1000/1000 [==============================] - 0s 365us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.8550 - acc: 0.7029\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1475 - acc: 0.9556\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0753 - acc: 0.9768\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.0831 - acc: 0.9735\n",
            "1000/1000 [==============================] - 0s 344us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.9369 - acc: 0.6859\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.1698 - acc: 0.9526\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0966 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.0596 - acc: 0.9834\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 477us/step - loss: 0.8176 - acc: 0.7331\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.1483 - acc: 0.9564\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 377us/step - loss: 0.1161 - acc: 0.9656\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 378us/step - loss: 0.0648 - acc: 0.9809\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 1.2921 - acc: 0.5482\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1561 - acc: 0.9543\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0894 - acc: 0.9730\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0692 - acc: 0.9786\n",
            "1000/1000 [==============================] - 0s 335us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 0.8209 - acc: 0.7166\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1611 - acc: 0.9503\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.0987 - acc: 0.9712\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.0675 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 378us/step\n",
            "this gen fitnesses: [0.944 0.959 0.947 0.979 0.964 0.975 0.969 0.953 0.978 0.973 0.972 0.967\n",
            " 0.965 0.948 0.971 0.966 0.97  0.961 0.972 0.96 ]\n",
            "\t\t\tStarting generation 18...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 0.8468 - acc: 0.7235\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1279 - acc: 0.9631\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0838 - acc: 0.9743\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0740 - acc: 0.9775\n",
            "1000/1000 [==============================] - 0s 369us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.9803 - acc: 0.6785\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1791 - acc: 0.9489\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.1048 - acc: 0.9694\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0711 - acc: 0.9792\n",
            "1000/1000 [==============================] - 0s 337us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 0.9599 - acc: 0.6792\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1666 - acc: 0.9527\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.1019 - acc: 0.9697\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.0576 - acc: 0.9829\n",
            "1000/1000 [==============================] - 0s 359us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 532us/step - loss: 1.3326 - acc: 0.5375\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2576 - acc: 0.9293\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1378 - acc: 0.9622\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0730 - acc: 0.9795\n",
            "1000/1000 [==============================] - 0s 396us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 497us/step - loss: 1.2779 - acc: 0.5967\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1705 - acc: 0.9516\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1206 - acc: 0.9635\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.0616 - acc: 0.9816\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 473us/step - loss: 0.7778 - acc: 0.7538\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 374us/step - loss: 0.1153 - acc: 0.9636\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 376us/step - loss: 0.0669 - acc: 0.9798\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.0580 - acc: 0.9821\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.944 0.97  0.969 0.962 0.971 0.975 0.969 0.953 0.978 0.973 0.972 0.963\n",
            " 0.965 0.948 0.971 0.966 0.97  0.977 0.972 0.96 ]\n",
            "\t\t\tStarting generation 19...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 480us/step - loss: 0.8959 - acc: 0.7257\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.1245 - acc: 0.9623\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.0671 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 1.2228 - acc: 0.5561\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 0.2566 - acc: 0.9263\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 0.1480 - acc: 0.9556\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 0.1105 - acc: 0.9695\n",
            "1000/1000 [==============================] - 0s 349us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 1.1285 - acc: 0.5921\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2072 - acc: 0.9413\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1151 - acc: 0.9663\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.0763 - acc: 0.9761\n",
            "1000/1000 [==============================] - 0s 408us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 343us/step - loss: 1.4014 - acc: 0.5420\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.3179 - acc: 0.9003\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 232us/step - loss: 0.1924 - acc: 0.9427\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 234us/step - loss: 0.1199 - acc: 0.9644\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 235us/step - loss: 0.0814 - acc: 0.9739\n",
            "1000/1000 [==============================] - 0s 291us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.9228 - acc: 0.3042\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.7125 - acc: 0.7811\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.2054 - acc: 0.9436\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1078 - acc: 0.9711\n",
            "1000/1000 [==============================] - 0s 381us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 479us/step - loss: 1.6765 - acc: 0.4851\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.2780 - acc: 0.9205\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1421 - acc: 0.9630\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 293us/step - loss: 1.1699 - acc: 0.5972\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 192us/step - loss: 0.2283 - acc: 0.9333\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 191us/step - loss: 0.1533 - acc: 0.9541\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 191us/step - loss: 0.0955 - acc: 0.9714\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 191us/step - loss: 0.0835 - acc: 0.9741\n",
            "1000/1000 [==============================] - 0s 260us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 483us/step - loss: 1.4258 - acc: 0.4868\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.3449 - acc: 0.8971\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1445 - acc: 0.9556\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 514us/step - loss: 1.0649 - acc: 0.6684\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.1279 - acc: 0.9634\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.1199 - acc: 0.9654\n",
            "1000/1000 [==============================] - 0s 390us/step\n",
            "this gen fitnesses: [0.973 0.96  0.969 0.962 0.971 0.965 0.947 0.941 0.95  0.973 0.972 0.963\n",
            " 0.965 0.948 0.971 0.966 0.97  0.967 0.955 0.968]\n",
            "\t\t\tStarting generation 20...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 472us/step - loss: 0.9644 - acc: 0.7122\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 338us/step - loss: 0.1436 - acc: 0.9598\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0842 - acc: 0.9754\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0947 - acc: 0.9742\n",
            "1000/1000 [==============================] - 0s 343us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 512us/step - loss: 1.7752 - acc: 0.3718\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 408us/step - loss: 0.4119 - acc: 0.8627\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1793 - acc: 0.9535\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.0949 - acc: 0.9734\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 494us/step - loss: 1.0829 - acc: 0.6152\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1624 - acc: 0.9563\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0860 - acc: 0.9754\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.0688 - acc: 0.9812\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 306us/step - loss: 1.2082 - acc: 0.5818\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 216us/step - loss: 0.2548 - acc: 0.9251\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1641 - acc: 0.9521\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1044 - acc: 0.9674\n",
            "1000/1000 [==============================] - 0s 274us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 484us/step - loss: 1.0297 - acc: 0.6623\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.2159 - acc: 0.9397\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0906 - acc: 0.9744\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0589 - acc: 0.9826\n",
            "1000/1000 [==============================] - 0s 375us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 1.1868 - acc: 0.5991\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.3385 - acc: 0.8937\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.1330 - acc: 0.9635\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.1492 - acc: 0.9598\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.0226 - acc: 0.6785\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1794 - acc: 0.9479\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1004 - acc: 0.9701\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.0933 - acc: 0.9703\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 537us/step - loss: 0.9836 - acc: 0.6807\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1286 - acc: 0.9609\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0793 - acc: 0.9761\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0571 - acc: 0.9818\n",
            "1000/1000 [==============================] - 0s 435us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 1.2422 - acc: 0.6321\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1648 - acc: 0.9544\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1043 - acc: 0.9687\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 1.3259 - acc: 0.5665\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.2618 - acc: 0.9364\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.1448 - acc: 0.9615\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 358us/step - loss: 0.1171 - acc: 0.9691\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.9969 - acc: 0.6774\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 337us/step - loss: 0.2154 - acc: 0.9407\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 337us/step - loss: 0.1105 - acc: 0.9700\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0831 - acc: 0.9759\n",
            "1000/1000 [==============================] - 0s 339us/step\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.973 0.96  0.964 0.958 0.963 0.965 0.952 0.973 0.95  0.973 0.957 0.963\n",
            " 0.916 0.968 0.971 0.954 0.959 0.95  0.955 0.968]\n",
            "The best individual [0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0] had fitness (accuracy): 0.973\n",
            "CPU times: user 47min 9s, sys: 10min 3s, total: 57min 12s\n",
            "Wall time: 1h 6min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHqh5JrxgTDq",
        "colab_type": "text"
      },
      "source": [
        "Baseline 20 gen x 20 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOPhKQ-JgR3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = False\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CrCDRDMA5fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 5)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHBMZCkDA5kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%time\n",
        "#import sys\n",
        "#import time\n",
        "#old_stdout = sys.stdout\n",
        "#sys.stdout = open('20_20_full_modification.txt', 'w')\n",
        "#\n",
        "#start = time.time()\n",
        "#np.random.seed(43) # reproducible\n",
        "#params.isModification = True\n",
        "#lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)\n",
        "#end = time.time()\n",
        "#print('TIME OF TRAINING: ', end-start, 'seconds.')\n",
        "#sys.stdout = old_stdout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg-dwM_JMfuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm '20_20_full_modification.txt'\n",
        "#sys.stdout = old_stdout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuXJhy_ieyQ0",
        "colab_type": "text"
      },
      "source": [
        "# Manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaIZak9OZnqx",
        "colab_type": "code",
        "outputId": "48fbf769-f115-47bc-c0b0-16d245912205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "CPU times: user 369 ms, sys: 156 ms, total: 525 ms\n",
            "Wall time: 1.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwTVIW1He7kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSY8vpXfM8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOeVitcfOyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_90wxfdfRXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGteF_JxgBak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1, mode='min', cooldown=1)\n",
        "estop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmqrhD9fbnX",
        "colab_type": "code",
        "outputId": "648816a3-c608-4888-a1f8-fd475b0145bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "%%time\n",
        "history, result = train_model(model, x_train, y_train, x_test, y_test, 20, 256, 1, 0.2, [reducelr, estop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 11s 220us/step - loss: 0.4362 - acc: 0.8560 - val_loss: 0.0875 - val_acc: 0.9751\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0686 - acc: 0.9800 - val_loss: 0.0523 - val_acc: 0.9843\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0453 - acc: 0.9864 - val_loss: 0.0512 - val_acc: 0.9837\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0385 - val_acc: 0.9890\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0313 - val_acc: 0.9904\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 9s 186us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0324 - val_acc: 0.9894\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0268 - val_acc: 0.9924\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0307 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0294 - val_acc: 0.9928\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 9s 184us/step - loss: 8.3924e-04 - acc: 0.9998 - val_loss: 0.0312 - val_acc: 0.9933\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 9s 185us/step - loss: 3.9299e-04 - acc: 0.9999 - val_loss: 0.0314 - val_acc: 0.9936\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 00011: early stopping\n",
            "10000/10000 [==============================] - 1s 97us/step\n",
            "CPU times: user 1min 2s, sys: 17.5 s, total: 1min 20s\n",
            "Wall time: 1min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMYjil9fjP13",
        "colab_type": "code",
        "outputId": "5c1f5aa4-1107-4bd2-e5e1-2a0ca19d9541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8214303073883056, 0.393]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq26Lc0ujT2Y",
        "colab_type": "code",
        "outputId": "19bbfc80-5d34-4af1-ce4b-7a2671f20c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "epochs = history.epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.title('Loss/Val loss curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(epochs, loss, color='red', label='training')\n",
        "plt.plot(epochs, val_loss, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-2ec98f4bc73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss/Val loss curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K8N0nlVjZYp",
        "colab_type": "code",
        "outputId": "86feb4c6-2351-4be3-c5b5-989dd4535267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.title('Acc/Val acc curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(epochs, acc, color='red', label='training')\n",
        "plt.plot(epochs, val_acc, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-e2eb1a72036d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Acc/Val acc curve'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1NovR1tAF3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO:\n",
        "# K.clear_session(), but model weights need to be saved first, and passed to inherit weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVp4A8xQU-fb",
        "colab_type": "text"
      },
      "source": [
        "# Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZObn4NLVDK0",
        "colab_type": "text"
      },
      "source": [
        "* Google Schoolar Searches: [link](https://scholar.google.com/scholar?hl=sr&as_sdt=0%2C5&q=genetic+cnn+handwritting&btnG=)\n",
        "\n",
        "* Fokus na rad: \n",
        " * .pdf: [link](https://arxiv.org/abs/1703.01513)\n",
        " * github: [link](https://arxiv.org/abs/1703.01513)\n",
        "* Dodatno rad:\n",
        " *  .pdf: [link](https://arxiv.org/pdf/1710.10741.pdf)\n",
        " * Clanak na netu: [link](https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164)\n",
        "* Ako sami implementiramo: [link](https://github.com/joeddav/devol/blob/master/devol/devol.py)\n"
      ]
    }
  ]
}