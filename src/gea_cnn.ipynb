{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gea_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QdSVY0xOnvKS",
        "bs1lDrRlnywQ",
        "TfbLSwCp032T",
        "2FqoY7lN9hEN",
        "z4qWi23vA1Aj",
        "aHqh5JrxgTDq",
        "vstiUgUrivpq",
        "3xJLUTkD3Vd0"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilanCugur/Genetic_Evolution_For_CNN/blob/master/src/gea_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfJ-fn_XLnLU",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DoSLvx2LdSl",
        "colab_type": "code",
        "outputId": "d34e3ebe-8036-4db5-9317-adfb57965d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoTzVEoMfV6",
        "colab_type": "code",
        "outputId": "b9645f02-4c9c-4f92-d13a-e523b716bd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Add, Activation, Flatten, Concatenate, Dense, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam  \n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import LeakyReLU, concatenate\n",
        "from keras.layers.advanced_activations import ReLU\n",
        "from keras.initializers import glorot_normal\n",
        "import keras.backend as K\n",
        "from keras.models import load_model  # Save model params\n",
        "\n",
        "def extract_dataset(path):\n",
        "  \"\"\"\n",
        "  extract DoubledMNIST dataset\n",
        "  Argument: path to .zip file with the dataset\n",
        "  Return value: x_train, y_train, x_test, y_test lists of numpy arrays \n",
        "  \n",
        "  (DoubledMNIST dataset: train size 120k images 56x56, test size 20k images 56x56)\n",
        "  \"\"\"\n",
        "  # import libraries\n",
        "  import os                     # for basic os operations\n",
        "  from zipfile import ZipFile \n",
        "  from skimage import io\n",
        "  import shutil\n",
        "  \n",
        "  if not path.endswith('.zip'):\n",
        "    raise ValueError(\"Error: path is not '.zip' file\")\n",
        "  \n",
        "  archive = ZipFile(path, 'r')  # extract\n",
        "  archive.extractall('./DoubledMNIST')\n",
        "  archive.close()\n",
        "  del archive\n",
        "  \n",
        "  x_train = []\n",
        "  y_train = []\n",
        "  x_test = []\n",
        "  y_test = []\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/train'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/train', file))\n",
        "    x_train.append(np.array(img))\n",
        "    y_train.append(int(file.split('_')[1]))\n",
        "  \n",
        "  for file in os.listdir('./DoubledMNIST/test'):\n",
        "    img = io.imread(os.path.join('./DoubledMNIST/test', file))\n",
        "    x_test.append(np.array(img))\n",
        "    y_test.append(int(file.split('_')[1]))\n",
        "    \n",
        "  shutil.rmtree('./DoubledMNIST')\n",
        "  return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bKQ505PMxBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist(doubled=0, ntrain=None, ntest=None):\n",
        "    \"\"\"\n",
        "    doubled==0 -> load MNIST; doubled==1-> load DoubledMNIST\n",
        "    ntrain - number of train samples\n",
        "    ntest - number of test samples\n",
        "    \"\"\"\n",
        "\n",
        "    from keras.utils import to_categorical\n",
        "    import numpy as np\n",
        "\n",
        "    if doubled==0:\n",
        "        # load mnist\n",
        "        from keras.datasets import mnist\n",
        "\n",
        "        (_x_train, _y_train), (_x_test, _y_test) = mnist.load_data()\n",
        "        if ntrain==None:\n",
        "            ntrain = _x_train.shape[0]\n",
        "        if ntest==None:\n",
        "            ntest = _x_test.shape[0]\n",
        "        assert ntrain<=_x_train.shape[0] and ntest<=_x_test.shape[0]\n",
        "    else:\n",
        "        # load doubled mnist\n",
        "        _x_train, _y_train, _x_test, _y_test = extract_dataset('./drive/My Drive/ni_sem/DoubledMNIST.zip')\n",
        "\n",
        "    # Prepare images\n",
        "    box_size = _x_train.shape[1]\n",
        "    y_train = to_categorical(_y_train)[:ntrain]\n",
        "    y_test = to_categorical(_y_test)[:ntest]\n",
        "    x_train = np.array(_x_train).astype('float32')[:ntrain]\n",
        "    x_train /= 255\n",
        "    x_train = np.reshape(x_train,[-1, box_size, box_size, 1])\n",
        "    x_test = np.array(_x_test).astype('float32')[:ntest]\n",
        "    x_test /= 255\n",
        "    x_test = np.reshape(x_test, [-1, box_size, box_size, 1])\n",
        "    return x_train, y_train, x_test, y_test, box_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5K7U7oOg4_4",
        "colab_type": "code",
        "outputId": "91c73b29-f908-430b-c4da-19d868b881b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=0) #, ntrain=10000, ntest=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "CPU times: user 376 ms, sys: 112 ms, total: 488 ms\n",
            "Wall time: 3.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8PNO4_WwR-E",
        "colab_type": "code",
        "outputId": "a776b62a-c286-4072-af57-1e0bfe651911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA_twWHcP-71",
        "colab_type": "code",
        "outputId": "79d188a4-ae55-46fa-e6b6-cea85bcd5a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "from matplotlib import pyplot as plt  # smal demonstration\n",
        "\n",
        "plt.imshow(x_test[19].reshape((x_test.shape[1], x_test.shape[2])))\n",
        "plt.show()\n",
        "\n",
        "print(y_test[19])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndiAJwg4kQdiBJAg7kMT/A8+T6g7j+JKWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uungJ3ZiczL",
        "colab_type": "text"
      },
      "source": [
        "# CNN tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HDESDezifHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "\n",
        "# sampleIndividual = [1, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi klasicna CNN\n",
        "# stage1 examples\n",
        "# sampleIndividual = [1, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; trojka eliminisana\n",
        "# sampleIndividual = [0, 1, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; dvojka eliminisana\n",
        "# sampleIndividual = [0, 0, 1,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; jedinica eliminisana\n",
        "# sampleIndividual = [0, 0, 0,   1, 0, 1, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; samo jedna konv.\n",
        "# stage2 examples\n",
        "# sampleIndividual = [1, 0, 1,   0, 0, 0, 0, 0, 1,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->3->4->5\n",
        "# sampleIndividual = [1, 0, 1,   0, 1, 0, 0, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi 0->1->3->5\n",
        "# sampleIndividual = [1, 0, 1,   1, 1, 0, 1, 0, 0,  1, 0, 1, 0, 0, 1, 0, 0, 0, 1]; radi; 0->1->2,3,4->5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbp0WjNmifCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __create_indices(num_nodes):\n",
        "  \"\"\"\n",
        "  num_nodes - number of nodes per each stage\n",
        "\n",
        "  Calculate bits indices (startindex, length) for each stage \n",
        "  \"\"\"\n",
        "  l =  0                              # genome length\n",
        "  bits_indices, i = np.empty((0,2),dtype = np.int32), 0 \n",
        "  for Ks in num_nodes:\n",
        "    length = Ks * (Ks - 1)\n",
        "    bits_indices = np.vstack([bits_indices,[i, i + int(0.5 * length)]])\n",
        "    i += int(0.5 * length)\n",
        "    l += length\n",
        "  l = int(0.5 * l)\n",
        "  return bits_indices, l\n",
        "\n",
        "def CNN_build(stages, num_nodes, n_filters, individual, box_size, n_classes, verbose=0):\n",
        "  \"\"\"\n",
        "  stages - array of stage names\n",
        "  num_nodes - number of conv nodes per each stage\n",
        "  n_filters - number of filters per stage\n",
        "  individual - binary list representing individual architecture\n",
        "  box_size - expect input images like (box_size, box_size)\n",
        "  n_classes - number of output clasees\n",
        "\n",
        "  Build CNN architecture from the given list\n",
        "  \"\"\"\n",
        "\n",
        "  L = len(individual)\n",
        "  bits_indices, _L= __create_indices(num_nodes)\n",
        "  assert(L==_L)  # small check of the input individual connections info\n",
        "\n",
        "  if(verbose):\n",
        "    print('Starting network building..')\n",
        "  image_shape = (box_size, box_size, 1) \n",
        "  x_input = Input(shape=image_shape)  \n",
        "  previous = None # output from previous stage (initially input of CNN)\n",
        "  # Build stage by stage\n",
        "  for i, (s, Ks, n_filter) in enumerate(zip(stages, num_nodes, n_filters)):\n",
        "    if i==0:\n",
        "      previous = x_input\n",
        "    if(verbose):\n",
        "        print('\\nBuild layer', s, ':', Ks, 'nodes,', n_filter, 'filters.')\n",
        "    stage_indices = individual[bits_indices[i][0]:bits_indices[i][1]]                  # connection indices for current stage nodes; ex. [1, 0, 1, 0, 0, 1, 0, 0, 0, 1]\n",
        "    stage_indexes = np.split(range(int(Ks*(Ks-1)/2)),np.cumsum(range(Ks - 1)))[1:]     # connection indexes for current stage nodes; ex. [array([0]), array([1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]\n",
        "    stage_nodes = []                                                                   # nodes in a stage; ex. [vs1_1, vs1_2, vs1_3] (0, 4 are dummy)\n",
        "    to_him = list(np.zeros(Ks))                                                              # number of nodes to which i-th node points to\n",
        "    from_him = list(np.zeros(Ks))  \n",
        "    if(verbose):                                                          # number of nodes from i-th node to others\n",
        "        print('Stage indices:', stage_indices)\n",
        "        print('Stage indexes:', stage_indexes)\n",
        "\n",
        "    # default stage input node\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_0')\n",
        "    vs0 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_0')(previous)  # TODO\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_0')\n",
        "\n",
        "    # first node and trivial vs0->vs1\n",
        "    if(verbose):\n",
        "        print('Building '+'v'+str(s)+'_1')\n",
        "    vs1 = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_1')(vs0) \n",
        "    stage_nodes += [vs1]\n",
        "    if(verbose):\n",
        "        print('Builded '+'v'+str(s)+'_1')\n",
        "\n",
        "    for j in range(2, Ks+1):\n",
        "      name = 'v'+str(s)+'_'+str(j)  # name of the current node\n",
        "      if(verbose):\n",
        "        print('Building '+name)\n",
        "      tonode = stage_indices[stage_indexes[j-2][0]:stage_indexes[j-2][-1]+1]  # slice from stage_indices\n",
        "      input = None  # Input to current node\n",
        "      if sum(tonode)==0:  # empty input, connect to vs0\n",
        "        input = vs0\n",
        "      else:  # have some input\n",
        "        for k, connection in enumerate(tonode):\n",
        "          if connection==1:\n",
        "            from_him[k] += 1\n",
        "            to_him[j-1] += 1\n",
        "            if input is None:\n",
        "              input = stage_nodes[k]\n",
        "            else:\n",
        "              input = Add()([input, stage_nodes[k]])\n",
        "      v = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(j))(input) \n",
        "      stage_nodes += [v]\n",
        "      if(verbose):\n",
        "        print('Builded node '+name)\n",
        "\n",
        "    if(verbose):\n",
        "        print('from_him: ', from_him)\n",
        "        print('to_him: ', to_him)\n",
        "        print('stage_nodes: ', stage_nodes)\n",
        "\n",
        "    if sum(from_him)==sum(to_him)==0:  # only one convolution vs0\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vs0)\n",
        "    else:  # have some of the ordinary nodes\n",
        "        if(verbose):\n",
        "            print('Building '+'v'+str(s)+'_'+str(Ks+1))\n",
        "        input = None  # last node no output definitelly\n",
        "        for k in range(len(stage_nodes)):\n",
        "            if from_him[k]==0 and to_him[k]!=0:  # no connections from that node\n",
        "                if(verbose):\n",
        "                    print('Connect to last node node', k, ' ', stage_nodes[k])\n",
        "                if input is None:\n",
        "                    input = stage_nodes[k]\n",
        "                else:\n",
        "                    input = Add()([input, stage_nodes[k]])\n",
        "        vsKs = Conv2D(filters=n_filter, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='v'+str(s)+'_'+str(Ks+1))(input) # defaul stage output node\n",
        "        if(verbose):\n",
        "            print('Builded '+'v'+str(s)+str(Ks+1))\n",
        "        previous = MaxPool2D(pool_size=(2,2), padding='same')(vsKs)\n",
        "  \n",
        "  # Adding FC part of NN\n",
        "  x = Flatten(name='flatten')(previous)                                                                                       \n",
        "  x = Dense(units=32, activation='relu', name='next_to_last')(x)         \n",
        "  x = Dense(units=n_classes, activation='softmax', name='last')(x)\n",
        "\n",
        "  # Creaate Model\n",
        "  model = Model(inputs=x_input, outputs=x, name='individual')\n",
        "  if(verbose):\n",
        "    print('Created Network builded.')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3hhN7e_SZwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  Compile forwarded model, and return it compiled\n",
        "  \"\"\"\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=1e-3), loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_TzENOzS2vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_model(model):\n",
        "  \"\"\"\n",
        "  model - created Keras model\n",
        "\n",
        "  plot forwarded model architecture\n",
        "  \"\"\"\n",
        "  from keras.utils import plot_model\n",
        "\n",
        "  print('Model summary: ')\n",
        "  model.summary()\n",
        "  plot_model(model, to_file='model.png')\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAH-z7QeUFqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, epochs, batch_size, verbose=0, validation_split=0.0, callbacks=[]):\n",
        "    \"\"\"\n",
        "    model - compiled CNN model\n",
        "    x_train - input images\n",
        "    y_train - input labels (one hot encoded)\n",
        "    x_test - test images\n",
        "    y_test - test labels (one hot encoded)\n",
        "    epochs - number of epochs\n",
        "    batch_size - mini batch size of training\n",
        "    verbose - verbose of training\n",
        "    validation_split - data split used for validation\n",
        "\n",
        "    Train forwrded model. Returns (train history, model obtained test accuracy)\n",
        "    \"\"\"\n",
        "    if (epochs == 0):\n",
        "        # for faster testing\n",
        "        # print('only eval, without training')\n",
        "        return None, model.evaluate(x_test, y_test)\n",
        "    # print('training and eval')\n",
        "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_split=validation_split, callbacks=callbacks)\n",
        "    return history, model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv7hRnZHWK9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)\n",
        "#model = compile_model(model)\n",
        "#visualize_model(model)\n",
        "#history, result = train_model(model, x_train, y_train, x_test, y_test, 1, 1024, 1)\n",
        "#result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOiF1-tx74y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def toPseudo(model):\n",
        "    \"\"\"\n",
        "    model - input CNN model\n",
        "    return - structure that describe model weights for later from that model loading\n",
        "    \"\"\"\n",
        "    return [(layer.get_config()['name'], layer.get_weights()) for layer in model.layers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlLUG0GedB1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadWeights(toModel, fromPseudoModel, numSameStages, numNodesPerStage):\n",
        "    '''\n",
        "    toModel: keras model for which to load weights\n",
        "    fromPseudoModel: list of (layer name, layer weights) from which to load weights\n",
        "    numSameStages: number of first same stages; can be 0, 1, 2, 3; trivial cases 0 and 3\n",
        "    numNodesPerStage: number of nodes per stage; ex. [3,4,5]\n",
        "\n",
        "    You need to call model.compile. This can be done either before or after the model.load_weights \n",
        "    call but must be after the model architecture is specified and before the model.predict call.\n",
        "    returns the model with loaded weights from file\n",
        "\n",
        "    IMPORTANT: toModel and fromModel MUST HAVE exactly the same architecture on first numSameStages! (same indices eqvivalently)\n",
        "    TODO: add critical pool if want more pooling operations in architecture\n",
        "    '''\n",
        "    assert numSameStages<=len(numNodesPerStage)\n",
        "    allflag = (numSameStages==len(numNodesPerStage))  # to load all weights\n",
        "    for i, (name, weights) in enumerate(fromPseudoModel):\n",
        "        #print(name, weights) \n",
        "\n",
        "        if numSameStages==0:\n",
        "            if not allflag:\n",
        "                break\n",
        "\n",
        "        toModel.layers[i].set_weights(weights)\n",
        "\n",
        "        if 'max_pooling' in name:\n",
        "            numSameStages-=1         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kdgjBhwRq2c",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEWPhebDtHe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from random import random, seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFU56u2otadr",
        "colab_type": "code",
        "outputId": "14eeb3dc-5872-4825-db80-340e819c4638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.random.seed(42) # reproducible\n",
        "class Genetic:\n",
        "    def __init__(self, pc, qc, pm, qm, numGen, numInd, geneLength, bitIndices):\n",
        "        ''' \n",
        "        pc: probability of crossover - whether crossover process begins\n",
        "        qc: probability of stages being exchanged - while in crossover process\n",
        "        pm: probability of mutation - whether mutation process begins\n",
        "        qm: probability of a per bit mutation - while in mutation process\n",
        "        numGen: number of generations\n",
        "        numInd: number of individuals\n",
        "        bitIndices: 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "        '''\n",
        "        self.pc = pc\n",
        "        self.qc = qc\n",
        "        self.pm = pm\n",
        "        self.qm = qm\n",
        "        self.numGen = numGen\n",
        "        self.currNumGen = 0\n",
        "        self.numInd = numInd\n",
        "        self.geneLength = geneLength\n",
        "        self.bitIndices = bitIndices\n",
        "        self.oldGen = None\n",
        "        self.initFirstGeneration()\n",
        "    \n",
        "    def initFirstGeneration(self):\n",
        "        ''' \n",
        "        initializes the first generation\n",
        "        '''\n",
        "        self.currNumGen = 1\n",
        "        self.currGen = np.random.randint(0, 2, (self.numInd, self.geneLength))\n",
        "\n",
        "    def getCurrentGeneration(self):\n",
        "        return self.currGen\n",
        "\n",
        "    def selection(self, fitness):\n",
        "        '''\n",
        "        returns indices of individuals that survived the selection\n",
        "        '''\n",
        "        npfit = np.array(fitness)\n",
        "        proba = npfit - np.min(npfit) # removes the worst one\n",
        "        proba = proba / np.sum(proba)\n",
        "\n",
        "        return np.random.choice(self.numInd, replace=True, size=self.numInd, p=proba)\n",
        "\n",
        "    def mutate(self, newGen, indices):\n",
        "        '''\n",
        "        mutates individuals in newGen on positions where indices are 0 (because those individuals didn't mate)\n",
        "        '''\n",
        "        for i, had in enumerate(indices):\n",
        "            if had == 0 and np.random.random() <= self.pm:\n",
        "                newGen[i] = self.mutateIndividual(self.currGen[i])\n",
        "            else:\n",
        "                newGen[i] = np.copy(self.currGen[i])\n",
        "\n",
        "    def mutateIndividual(self, individual):\n",
        "        '''\n",
        "        returns a new individual by mutating the given one\n",
        "        '''\n",
        "        mut = np.copy(individual)\n",
        "        for i, val in enumerate(mut):\n",
        "            if np.random.random() <= self.qm:\n",
        "                mut[i] = 1 - mut[i]\n",
        "\n",
        "        return mut\n",
        "\n",
        "    def crossover(self, individualA, individualB):\n",
        "        '''\n",
        "        returns two new individuals by performing crossover on two given individuals.\n",
        "        it takes care to only swap the whole segments, and not bits within segments\n",
        "        '''\n",
        "        a = np.copy(individualA)\n",
        "        b = np.copy(individualB)\n",
        "\n",
        "        for segment in self.bitIndices:\n",
        "            if np.random.random() <= self.qc:\n",
        "                start = segment[0]\n",
        "                end = segment[1]\n",
        "                tmpa = np.copy(a[start:end])\n",
        "                a[start:end] = b[start:end]\n",
        "                b[start:end] = tmpa\n",
        "\n",
        "        return a, b\n",
        "\n",
        "    def newGeneration(self, fitness, verbose=False):\n",
        "        '''\n",
        "        creates a new generation of individuals by selection, crossover, and mutation \n",
        "        of previous generation. Selection is based on the rulet method\n",
        "\n",
        "        fitness - np array of fitness metrics for all individuals, based on which to construct rulet\n",
        "        '''\n",
        "        self.currNumGen += 1\n",
        "        if self.currNumGen > self.numGen:\n",
        "            raise Exception(f\"currNumGen > numGen, {self.currNumGen} > {self.numGen}\")\n",
        "        newGenIdx = self.selection(fitness)\n",
        "        if verbose:\n",
        "            print(f'survived selection: {newGenIdx}')\n",
        "        newGen = np.zeros((self.numInd, self.geneLength), dtype='int32') # np matrix of new generation\n",
        "        hadCrossoverIdx = np.zeros(self.numInd) # tracks if an individial had a crossover\n",
        "        assert(len(newGen)%2 == 0)\n",
        "        # for each pair of neighbours, try crossover\n",
        "        for i in range(0, len(newGen), 2):\n",
        "            if np.random.random() <= self.pc:\n",
        "                newGen[i], newGen[i+1] = self.crossover(self.currGen[newGenIdx[i]], self.currGen[newGenIdx[i+1]])\n",
        "                hadCrossoverIdx[i] = 1\n",
        "                hadCrossoverIdx[i+1] = 1\n",
        "\n",
        "        self.mutate(newGen, hadCrossoverIdx)\n",
        "        \n",
        "        self.oldGen = self.currGen\n",
        "        self.currGen = newGen\n",
        "\n",
        "    def findIndividualsWithSameRoots(self, verbose=False):\n",
        "        '''\n",
        "        for each individual in a new generation finds the indices of individuals in the old generation \n",
        "        which had the same firts n segments\n",
        "\n",
        "        returns a list, where i-th element has a touple (listOfParentsWithSameSegment, numberOfSameSegments)\n",
        "        '''\n",
        "        parentsAndNumSegments = []\n",
        "        for indiv in self.currGen:\n",
        "            parents, numSameSegments = self.hasSameRoots(indiv)\n",
        "            parentsAndNumSegments.append((parents, numSameSegments))\n",
        "            if numSameSegments > 0 and verbose:\n",
        "                print('individual:',indiv)\n",
        "                print(f'has the same {numSameSegments} first segments as:')\n",
        "                print(parents)\n",
        "                print(f'e.g: {self.oldGen[parents[0]]}')\n",
        "\n",
        "        return parentsAndNumSegments\n",
        "\n",
        "\n",
        "    def hasSameRoots(self, individual):\n",
        "        '''\n",
        "        returns indices of individuals from last generations which have the biggest same root as the\n",
        "        given individual, and returns the number of segments which are the same (starting from the first)\n",
        "        '''\n",
        "        for i, segment in reversed(list(enumerate(self.bitIndices))):\n",
        "            nColumns = segment[1]\n",
        "            # print('bools',(self.oldGen[:,:nColumns] == individual[:nColumns]))\n",
        "            # print('oldgen:',self.oldGen)\n",
        "            # print('ind:', individual)\n",
        "            # find rows which have the individual (only look at the part of the colums)\n",
        "            matchedRows = (self.oldGen[:,:nColumns] == individual[:nColumns]).all(axis=1)\n",
        "            sameRootIndividuals = np.where(matchedRows)[0]\n",
        "            if sameRootIndividuals.size > 0:\n",
        "                return sameRootIndividuals, i+1\n",
        "\n",
        "        return np.empty(0), 0\n",
        "\n",
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "BITS_INDICES, geneLength = __create_indices(NUM_NODES)\n",
        "gen = Genetic(0.2, 0.3, 0.8, 0.1, 10, 10, geneLength, BITS_INDICES)\n",
        "print('mean1', np.mean(gen.getCurrentGeneration()))\n",
        "gen.newGeneration(np.random.random(10))\n",
        "print('mean2', np.mean(gen.getCurrentGeneration()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean1 0.5105263157894737\n",
            "mean2 0.5157894736842106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5onkJV5pZ4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import types\n",
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "\n",
        "BIT_INDICES, L = __create_indices(NUM_NODES)\n",
        "# params is used as function parameter throught the core algorithm\n",
        "params = types.SimpleNamespace()\n",
        "params.pc = 0.2 # pc: probability of crossover - whether crossover process begins\n",
        "params.pm = 0.8 # pm: probability of mutation - whether mutation process begins\n",
        "params.qc = 0.3 # qc: probability of stages being exchanged - while in crossover process\n",
        "params.qm = 0.1 # qm: probability of a per bit mutation - while in mutation process\n",
        "params.geneLength = L # number of bits needed to encode the gene\n",
        "params.numGenerations = 10 # 10 # number of generations\n",
        "params.numIndividuals = 10 # 10 # number of individuals\n",
        "params.bitIndices = BITS_INDICES # 2d matrix where each row has two columns - first is the index, and second is the length of bits in gene that code each segment\n",
        "params.boxSize = box_size # width and height of the input\n",
        "params.numClasses = 10 # number of output classes\n",
        "params.stageNames = STAGES # list containing names of stages\n",
        "params.numFilters = FILTERS # list containing number of filters per stage\n",
        "params.numNodes = NUM_NODES # number of nodes within each stage\n",
        "params.xTrain = x_train # training set data\n",
        "params.yTrain = y_train # training set labels\n",
        "params.xTest = x_test # test set data\n",
        "params.yTest = y_test # test set labels\n",
        "params.epochs = 10 # default number of epochs to train in the first generation\n",
        "params.batchSize = 256\n",
        "params.verbose = True\n",
        "params.numInheritedStagesToEpochs = { # maps number of inherited stages into \n",
        "                                      # number of needed epochs to train it\n",
        "                                      # all: 0epoch, 1stage: 4epoch, 2stage: 3epoch\n",
        "    0: params.epochs,\n",
        "    1: params.epochs - 2,\n",
        "    2: params.epochs - 4,\n",
        "    3: 0\n",
        "}\n",
        "params.isModification = False\n",
        "assert(params.numIndividuals%2 == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx7G8lmn0Tso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inheritWeightsFromParents(model, params, parentSegmentTuple, lastGenWeights):\n",
        "    '''\n",
        "    returns model, howManyEpochsToTrain, parentIndex\n",
        "    returns the model which inherits weights from last generation if possible \n",
        "    (and if params.isModification=true)\n",
        "    '''\n",
        "    parents = parentSegmentTuple[0] \n",
        "    numSegments = parentSegmentTuple[1]\n",
        "    epochsToTrain = params.numInheritedStagesToEpochs[numSegments] if params.isModification else params.epochs\n",
        "    trainForEpochs = epochsToTrain\n",
        "    parentIndex = None\n",
        "    if params.isModification and numSegments > 0:\n",
        "        parentIndex = parents[0] # TODO this is a list, might take the parent with the best fitness\n",
        "        loadWeights(model, lastGenWeights[parentIndex], numSegments, params.numNodes)\n",
        "    if model is None:\n",
        "        print('\\t\\t\\t\\ MODEL IS NONE!')\n",
        "    return model, trainForEpochs, parentIndex\n",
        "\n",
        "def createAndEvaluateModel(params, individual, parentSegmentTuple, oldNetworkWeights, lastGenFitness, verbose):\n",
        "    '''\n",
        "    This clears the session to avoid slowdown after training many instances\n",
        "\n",
        "    returns its weights and fitness\n",
        "    '''\n",
        "    # build model\n",
        "    model = CNN_build(params.stageNames, params.numNodes, params.numFilters, individual, params.boxSize, params.numClasses, verbose=0)\n",
        "    model = compile_model(model)\n",
        "    # inherit weights\n",
        "    if oldNetworkWeights is None:\n",
        "        assert(lastGenFitness is None)\n",
        "        assert(parentSegmentTuple is None)\n",
        "        trainForEpochs = params.epochs\n",
        "    else:\n",
        "        assert(lastGenFitness is not None)\n",
        "        assert(parentSegmentTuple is not None)\n",
        "        model, trainForEpochs, parentIndex = inheritWeightsFromParents(model, params, parentSegmentTuple, oldNetworkWeights)\n",
        "\n",
        "    # train or copy from last gen\n",
        "    if trainForEpochs == 0:\n",
        "        assert(lastGenFitness is not None)\n",
        "        assert(oldNetworkWeights is not None)\n",
        "        print('\\t\\t\\t\\Skipping training because model is the same as last gen')\n",
        "        fitness = lastGenFitness[parentIndex]\n",
        "        pseudoWeights = oldNetworkWeights[parentIndex]\n",
        "    else:\n",
        "        history, lossAndAcc = train_model(model, params.xTrain, params.yTrain, params.xTest,\n",
        "                    params.yTest, trainForEpochs,\n",
        "                    params.batchSize, verbose=params.verbose, validation_split=0.0) \n",
        "        fitness = lossAndAcc[1]\n",
        "        pseudoWeights = toPseudo(model)\n",
        "\n",
        "    K.clear_session()\n",
        "    return pseudoWeights, fitness\n",
        "    \n",
        "def executeSelectionWithGeneticAlgorithm(params):\n",
        "    ''' \n",
        "    args: params object defined above\n",
        "\n",
        "    returns individuals in the last generation, index of the best individual, and their fitnesses, and np matrix of all fitnesses\n",
        "    '''\n",
        "    genetic = Genetic(params.pc, params.qc, params.pm, params.qm, params.numGenerations, params.numIndividuals, params.geneLength, params.bitIndices)\n",
        "    oldNetworksWeights = None\n",
        "    allFitnesses = np.zeros((params.numGenerations, params.numIndividuals))\n",
        "    for i in range(params.numGenerations):\n",
        "        nthGen = i+1\n",
        "        print(f'\\t\\t\\tStarting generation {nthGen}...')\n",
        "        print(f'Creating models from individuals...')\n",
        "        individuals = genetic.getCurrentGeneration()\n",
        "        # print(\"current generation:\", individuals)\n",
        "        newNetworksWeights = []\n",
        "        if i > 0:\n",
        "            print(f'findIndividualsWithSameRoots...')\n",
        "            parentSegmentTuples = genetic.findIndividualsWithSameRoots()\n",
        "            lastGenFitness = allFitnesses[i-1]\n",
        "        else:\n",
        "            parentSegmentTuples = None \n",
        "            lastGenFitness = None\n",
        "        \n",
        "        currGenFitness = []\n",
        "        for j, individual in enumerate(individuals):\n",
        "            print(f\"Creating and evaluating indiv #{j}\")\n",
        "            parentSegmentTuple = None if parentSegmentTuples is None else parentSegmentTuples[j]\n",
        "            newNetWeight, fitness = createAndEvaluateModel(params, individual, parentSegmentTuple,\n",
        "                                                           oldNetworksWeights, lastGenFitness, params.verbose)\n",
        "            newNetworksWeights.append(newNetWeight)\n",
        "            currGenFitness.append(fitness)\n",
        "\n",
        "        currGenFitness = np.array(currGenFitness) \n",
        "        allFitnesses[i] = currGenFitness\n",
        "        print(f'this gen fitnesses: {currGenFitness}')\n",
        "        if i < params.numGenerations - 1:\n",
        "            genetic.newGeneration(fitness=currGenFitness)\n",
        "            oldNetworksWeights = newNetworksWeights\n",
        "\n",
        "    bestIdx = np.argmax(currGenFitness)\n",
        "    print(f'The best individual {individuals[bestIdx]} had fitness (accuracy): {currGenFitness[bestIdx]}')\n",
        "\n",
        "    return individuals, bestIdx, currGenFitness, allFitnesses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAAN4N9PnlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotEvolutionProgress(allFit, takeBestN):\n",
        "    topn = np.zeros((params.numGenerations, takeBestN))\n",
        "    for i, row in enumerate(allFit):\n",
        "        row.sort()\n",
        "        topn[i] = row[-takeBestN:]\n",
        "\n",
        "    for i, col in reversed(list(enumerate(topn.T))):\n",
        "        plt.plot(range(1, params.numGenerations+1), col, label=f'#{takeBestN - i}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "# plotEvolutionProgress(np.random.randn(params.numGenerations, params.numIndividuals), takeBestN = 2)\n",
        "#plotEvolutionProgress(allFitnesses, takeBestN = 1)\n",
        "#allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdSVY0xOnvKS",
        "colab_type": "text"
      },
      "source": [
        "## Baseline: 4 gen x 4 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqXfftoHnfM",
        "colab_type": "code",
        "outputId": "8de7de3c-f1f4-422c-a820-2f9add5cee70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = False\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3412 - acc: 0.8875\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0658 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0418 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0349 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0295 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 232us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.3517 - acc: 0.8828\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0576 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0409 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0316 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0240 - acc: 0.9927\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.3559 - acc: 0.8811\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0663 - acc: 0.9793\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0422 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0313 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0281 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 164us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.4713 - acc: 0.8409\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0632 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0463 - acc: 0.9854\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0353 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0306 - acc: 0.9904\n",
            "10000/10000 [==============================] - 2s 243us/step\n",
            "this gen fitnesses: [0.9913 0.9908 0.9919 0.9859]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3762 - acc: 0.8740\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0626 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0433 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0337 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0288 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.3374 - acc: 0.8942\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0583 - acc: 0.9824\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0413 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0312 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0236 - acc: 0.9927\n",
            "10000/10000 [==============================] - 3s 254us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.3007 - acc: 0.9003\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0591 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0408 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0321 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0263 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 228us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 432us/step - loss: 0.4312 - acc: 0.8558\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.0632 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0449 - acc: 0.9865\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0357 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0290 - acc: 0.9913\n",
            "10000/10000 [==============================] - 3s 251us/step\n",
            "this gen fitnesses: [0.9904 0.9907 0.9906 0.9918]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3777 - acc: 0.8751\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0651 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0439 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0355 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0267 - acc: 0.9922\n",
            "10000/10000 [==============================] - 2s 231us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.3235 - acc: 0.8958\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0618 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0431 - acc: 0.9870\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0332 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0278 - acc: 0.9917\n",
            "10000/10000 [==============================] - 3s 250us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.6310 - acc: 0.7848\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0742 - acc: 0.9772\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0523 - acc: 0.9840\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0390 - acc: 0.9881\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0331 - acc: 0.9896\n",
            "10000/10000 [==============================] - 2s 226us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.3400 - acc: 0.8870\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0599 - acc: 0.9819\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0450 - acc: 0.9862\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0323 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0309 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 241us/step\n",
            "this gen fitnesses: [0.9917 0.9902 0.9912 0.987 ]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.4026 - acc: 0.8650\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0650 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0498 - acc: 0.9851\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0387 - acc: 0.9879\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0323 - acc: 0.9906\n",
            "10000/10000 [==============================] - 2s 239us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 453us/step - loss: 0.2889 - acc: 0.9041\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0531 - acc: 0.9844\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0378 - acc: 0.9888\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0314 - acc: 0.9904\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0233 - acc: 0.9927\n",
            "10000/10000 [==============================] - 3s 253us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.3328 - acc: 0.8904\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0633 - acc: 0.9810\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0441 - acc: 0.9861\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0329 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0262 - acc: 0.9922\n",
            "10000/10000 [==============================] - 2s 230us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.2957 - acc: 0.9057\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0566 - acc: 0.9829\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0404 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0313 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0269 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 244us/step\n",
            "this gen fitnesses: [0.9837 0.9911 0.9882 0.9906]\n",
            "The best individual [1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0] had fitness (accuracy): 0.9911\n",
            "CPU times: user 20min 30s, sys: 6min 24s, total: 26min 55s\n",
            "Wall time: 32min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIPoJK_R0H_O",
        "colab_type": "code",
        "outputId": "a03a809e-6c8a-41ab-b8d7-ac681805d585",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 4)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs1lDrRlnywQ",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 4 gen x 4 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHdNEUGn1HP",
        "colab_type": "code",
        "outputId": "c7e00a99-759b-4d76-b81f-af6f7c9113c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.3518 - acc: 0.8850\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0666 - acc: 0.9806\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0432 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0360 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0265 - acc: 0.9919\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.3471 - acc: 0.8852\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0584 - acc: 0.9827\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0398 - acc: 0.9881\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0339 - acc: 0.9893\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0277 - acc: 0.9912\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.3572 - acc: 0.8838\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0677 - acc: 0.9793\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0423 - acc: 0.9870\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0313 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0298 - acc: 0.9903\n",
            "10000/10000 [==============================] - 2s 166us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.4806 - acc: 0.8355\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0678 - acc: 0.9794\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0495 - acc: 0.9852\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0369 - acc: 0.9889\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0310 - acc: 0.9908\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "this gen fitnesses: [0.9917 0.9893 0.9913 0.9885]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.3140 - acc: 0.8940\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0565 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0397 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0299 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0234 - acc: 0.9928\n",
            "10000/10000 [==============================] - 2s 231us/step\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9917 0.9893 0.9876 0.9885]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.2423 - acc: 0.9223\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0485 - acc: 0.9856\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0372 - acc: 0.9890\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0269 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.2373 - acc: 0.9249\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0502 - acc: 0.9847\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0368 - acc: 0.9889\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0287 - acc: 0.9909\n",
            "10000/10000 [==============================] - 3s 254us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9897 0.9886 0.9876 0.9885]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.2035 - acc: 0.9406\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 26s 431us/step - loss: 0.0347 - acc: 0.9895\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0261 - acc: 0.9919\n",
            "10000/10000 [==============================] - 3s 253us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.3373 - acc: 0.8863\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0604 - acc: 0.9810\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0412 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0331 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 20s 341us/step - loss: 0.0265 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 209us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.2554 - acc: 0.9209\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0505 - acc: 0.9852\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0352 - acc: 0.9895\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.0293 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 242us/step\n",
            "this gen fitnesses: [0.9897 0.9925 0.9883 0.9922]\n",
            "The best individual [1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1] had fitness (accuracy): 0.9925\n",
            "CPU times: user 11min 25s, sys: 3min 29s, total: 14min 54s\n",
            "Wall time: 18min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNd7V9ajqPkw",
        "colab_type": "code",
        "outputId": "66a235cb-bfb6-4a0a-8787-ab8cb81eb4e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 4)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3hUVfrA8e9J7wGSUEPonYQWemgJ\nHQIICCJNqoi47k/FtawNF9taVsUGGKqKqAgEkBaKJLSE3iG0FEoSIL1nzu+PO0BESiAzmZLzeR4e\nkzu3vKN433tPeY+QUqIoiqKUPzamDkBRFEUxDZUAFEVRyimVABRFUcoplQAURVHKKZUAFEVRyik7\nUwfwMLy9vWXt2rVNHYaiKIpF2bdvX4qU0ufO7RaVAGrXrk1MTIypw1AURbEoQoiLd9uumoAURVHK\nKZUAFEVRyimVABRFUcopi+oDUJRHUVBQQEJCArm5uaYOpVScnJzw9fXF3t7e1KEoVkIlAMXqJSQk\n4O7uTu3atRFCmDqcRyKl5Nq1ayQkJFCnTh1Th6NYCdUEpFi93NxcvLy8LPbmDyCEwMvLy+LfYhTz\nohKAUi5Y8s3/Jmv4Dop5UQlAURTFjF3LzGNW+HFyC4oMfm6VABSljL366qts3bqVlStX8v777wPw\nyy+/0KxZM2xsbNRkR+WWrLxCJi6M5se9FzmbnGnw86sEoChlbM+ePXTo0IHt27fTtWtXAJo3b86K\nFStu/a4oBUU6pv+wnyOJacwZ1Zpm1T0Nfg01CkhRysjMmTPZsGED58+fp2PHjpw9e5aIiAiGDx/O\nm2++aerwFDMipeRfvx1m++lkPhjqT8+mVYxyHZUAlHLlnfBjHL+UbtBzNq3uwVuhzR6433//+19G\njBjB4sWL+fTTT+nevTtRUVEGjUWxDh9tOMWK/Ym80KshT7TzM9p1VBOQopSh/fv306JFC06ePEmT\nJk1MHY5ihhZEneebbWcZ3d6P54LrG/Va6g1AKVdK8qRuDAcPHuSpp54iISEBb29vsrOzkVLSsmVL\ndu3ahbOzs0niUszLmsOXmLXmOL2bVmHW4OZGH/qr3gAUpQy0bNmSgwcP0rBhQ44fP05wcDAbNmzg\n4MGD6uavALDzbAov/HyIwFoV+WJUK2xtjD/vQyUARSkjycnJVKxYERsbG06ePEnTpk1vffb777/j\n6+vLrl27GDBgAH369DFhpEpZO34pnacX76O2twvzx7XFyd62TK4rpJRlciFDCAwMlGqMtPKwTpw4\nYTXt7db0XRRN/PVshn2zE1sbwW/PdKJ6BcO/EQoh9kkpA+/crt4AFEVRTOR6Vj7jF+wlt6CIRRPb\nGeXmfz+qE1hRFMUEsvO1Wb6JN3JYOrk9Dau4l3kM6g1AURSljBUW6XjuxwMcTkjli1GtaFu70r13\nzk2HqM+hqMDgcagEoCiKUoaklLz++1EiTiYxa3Bz+jSrev8D1r8Km9+Gq0cNHotKAIqiKGXos02n\n+Tkmnn8E12dMh1r33/n4aji4FLq8CNVbGTwWlQAURVHKyJLdF/liSywjA2vyf70a3n/njCsQ/jxU\nawnd/mWUeFQCUJQydrdy0DNnzqRx48YEBATw2GOPkZqaauIoFUNbf/Qyb646Skjjysx+7AGzfKWE\nVTOgIAeGzgNb46wDrRKAopSxu5WD7tWrF0ePHuXw4cM0bNjwVmJQrMPe89f5x7KDtKxZgTlPtsbO\n9gG33uj5ELsJer8LPg94UyiFEiUAIURfIcQpIUSsEOKVu3xeSwgRIYQ4LITYJoTwLfbZh0KIo/o/\nI4tt/0F/zqNCiDAhhHFSnKKYiZkzZxIQEEB0dDQdO3Zk/vz5PPPMM8yaNYvevXtjZ6eNyu7QoQMJ\nCQkmjlYxlFNXMpi8KBrfis6EjW+Ls8MDZvmmnIGNb0D9ntB2slFje+A8ACGELfAV0AtIAKKFEKul\nlMeL7fYxsFhKuUgIEQy8D4wVQgwAWgMtAUdgmxDiDyllOvADMEZ//I/AZOAbA30vRbm7P16BK0cM\ne86q/tDvgwfuVtJy0GFhYYwcOfIuZ1AszaXUHMaH7cXJ3pbFE9tR0dXh/gcUFcCKKWDvDIO/AjMo\nBtcOiJVSnpNS5gPLgMF37NMU2KL/eWuxz5sCf0opC6WUWcBhoC+AlHKd1AP2Ar4oipV7UDno2bNn\nY2dnx+jRo00QnWJIqdn5jAvbS1ZeIYsmtsO3osuDD9r+EVw6AKGfg/sDhocaQElmAtcA4ov9ngC0\nv2OfQ8BQ4HPgMcBdCOGl3/6WEOITwAXoARR/c0Df9DMWeP5uFxdCTAWmAvj5GW9hBKWcKMGTujGU\npBz0woULWbNmDREREUYvA6wYV25BEZMXxRB3LZtFE9vRpJrHgw+K3ws7PoaWo6HpIOMHieE6gV8C\nugkhDgDdgESgSEq5EVgH7AR+AnYBdy5t/zXaW8KOu51YSjlXShkopQz08fExULiKUrYeVA56/fr1\nfPTRR6xevRoXlxI8KSpmq7BIx3M/HWBf3A0+G9mSjvW8HnxQXiasmAqevtC37B5SSvIGkAjULPa7\nr37bLVLKS2hvAAgh3IBhUspU/Wezgdn6z34ETt88TgjxFuADPP3oX0FRLMP9ykHPmDGDvLw8evXq\nBWgdwd9++62pQlUekZSSN1YdY9Pxq7wd2pQBAdVKduCGV+HGBZiwDpxK8LZgICVJANFAAyFEHbQb\n/xPAk8V3EEJ4A9ellDrgVSBMv90WqCClvCaECAACgI36zyYDfYAQ/XGKYtV8fHxYu3YtALt37/7L\nZ7GxsaYISTGwLyJi+WlvHNO71+OpznVKdtDJdbB/MQT9H9TqZNwA7/DAJiApZSEwA9gAnACWSymP\nCSFmCSFuNlR1B04JIU4DVdA/8QP2wA4hxHFgLjBGfz6Ab/X77hJCHBRCvGmoL6UoilLWftobx2eb\nTzOstS8z+zQq2UGZSbD6OagaAN1fM26Ad1GictBSynVobfnFt71Z7OdfgV/vclwu2kigu51TlaJW\nFMUqbDp+ldd/P0L3Rj58MMy/ZJ34Umo3//xMbbav3QOGiBqBugkriqKUwr6L15nx4378a3jy9ejW\n2D9olu+tAxfC6fXQ90Oo3NioMd6LKgWhKIryiGKTMpi0KIbqFZwJe6otLg4lfKa+dhY2vAZ1u0O7\nqcYM8b5UAlAURXkEV9JyGR8WjZ2NDYsmtMPLzbFkBxYVakM+bR1gyDdgY7rbsGoCUhRFeUhpOQU8\ntWAvaTkFLJvaAT+vh5i7seNjSIyB4QvAo7rxgiwB9QagKGXsbuWg33jjDQICAmjZsiW9e/fm0qVL\nJo5SuZfcgiKmLo7hbHIm345pQ/ManiU/OGGfVu4hYCQ0H2q8IEuoXLwBnL6aQVqO4dfTVErH2d6W\nZtU9yl3Zgz179vDmm2/y2muvMXz4cECrFPruu+8C8MUXXzBr1iw1EcwMFekkLyw/yJ7z1/n8iZYE\nNfAu+cH5WVqhN4/q0P+/xgvyIZSLBPD+uhNsPZVs6jCUuxjcsjofDA14cIlcKzBz5kw2bNjA+fPn\n6dixI2fPniUiIoLhw4fz5pu3p8FkZWWVu6RoCaSUvBN+jHVHrvDvAU0Y3LLGw51g47/h+jl4ag04\nPcRbgxGViwTwYu9GTAqqa+owlDtEX7jOF1vOcPpqJnPHtqFmJePXwPlw74ecvH7SoOdsXKkx/2r3\n4CX7HlQO+vXXX2fx4sV4enqydetWg8aolN7X286yeNdFpnaty+QuD3k/Ob0BYsKg03NQO8g4AT6C\ncpEAHqqNTikzQQ28aelXged/OkDonEi+eKIVXRtad8G/+5WDnj17NrNnz+b9999nzpw5vPPOOyaK\nUrnTLzHx/HfDKYa0rM4rfR9yzH5Wira8Y5XmEPyGcQJ8REIrx28ZAgMDZUxMjKnDUAzs4rUsnl6y\nj9NXM5jZpzHTutU1aBPIiRMn7lp7vyzdqxy0l5fXrXLQN8XFxdG/f3+OHj36t/OYw3cpb7aeTGLy\n4hg61fPi+/FtcbB7iLEzUsKy0dryjlO3QZVmxgrzvoQQ+6SUgXduV6OAFJOr5eXKiumd6O9fjQ/X\nn+TZH/eTlVf44AMtyIPKQZ85c+bWvqtWraJxY9PMDFX+6kDcDab/sJ8m1dz5Zkybh7v5AxxYAqfW\nQshbJrv530+5aAJSzJ+Lgx1fjmpFgK8nH/xxktikTL4bG0gdb1dTh2Yw9ysH/corr3Dq1ClsbGyo\nVauWGgFkBs4lZzJxYTQ+7o4seKodbo4Pebu8fk5bgrROV+gw3ThBlpJqAlLMTuSZFJ77aT+FOsnn\nT7QkuHGVUp3PmppNrOm7mLOk9FyGfrOTnPwifnumE7Uf9kGkqBAW9oekkzB9p7bQiwmpJiDFYgQ1\n8Gb1jCBqVnRh0qIYvog4g05nOQ8qimVLzy1g/IJormfls2BC24e/+QNEfQbxe2DAJya/+d+PSgCK\nWapZyYXfnunEkJY1+HTTaZ5euo+MXDWZTzGuvMIipi3Zx5mrGXwzpg0BvhUe/iSJ+2HbB9B8GAQ8\nbvggDUglAMVsOTvY8umIFrwV2pQtJ5MY/FUUsUmZpg5LsVI6neTF5YfYefYaHw0PoNujDEnOz9YK\nvblV0Z7+zZxKAIpZE0IwoXMdfpjcnrTsAoZ8FcWGY1dMHZZiZaSU/GftCdYcvswr/RoztPUjNtts\nehOunYEhX4NzRcMGaQQqASgWoUNdL8KfC6KejytPL9nHJxtPUaT6BRQDmbfjHGFR55nQuTZPd33E\nqgFnNkP0POjwrFbn3wKoBKBYjOoVnPn56Y6MCPTlyy2xTFoUTVq26hdQSuf3Awm8t+4kAwKq8caA\npo82CTH7Oqx6FnyaQIjlLG+uEoBiUZzsbflwWAD/GdKcqNgUBn0VyakrGaYO66HcrRz0TZ988glC\nCFJSUkwUXfny5+lkZv5ymI51vfh0RAtsbB7h5i8lhD8P2ddg2DywdzJ8oEaiEoBicYQQjOlQi2VT\nO5CdX8SQr6JYc9hy6ufv2bOHDh06sH37drp27Xpre3x8PBs3bsTPz8+E0ZUfhxNSmbZ0Hw2quPPd\nuDY42j1iRdpDP8GJ1RD8b6jqb9ggjax8JICMq9ormmJV2tSqxNrngmha3YMZPx7g/T9OUFikM3VY\n9zRz5kwCAgKIjo6mY8eOzJ8/n2eeeYZZs2YB8H//93989NFHqhR0GbiQksWEBdFUdHFg0YS2eDjZ\nP9qJblyAdS9Drc5apU8LY/2lIKSE3yZB6kUY+QNUCzB1RIoBVfZw4qcpHZi15hjfbT/HscR0vhzV\nioquDnfd/8p775F3wrDloB2bNKbqa689cL/7lYNetWoVNWrUoEWLFgaNTfm75Iw8xi/Yi05KFk9q\nR2WPR2yy0RXB79NACHjsW7CxvDUtrP8NQAjo+bY2Nfv73nB4uakjUgzMwc6G/wzx58Nh/uw9f53Q\nOZEcTUwzdVh3dbdy0NnZ2bz33nu33gQU48nMK2TiwmiS0vMIe6ot9XzcHv1kO7+AuF3a6l4VLLPZ\nrvzUAspMguXjIW6nVpip1yywfcTXPsVsHYxPZdqSfdzIzufDYQEMaVXDLOrn3K8c9JIlSwgJCcHF\nRVsQJyEhgerVq7N3716qVq36l/OYw3exVPmFOiYtimbn2WvMG9emdDWmLh+CeSHQeAA8vlB70DRj\nqhaQW2UYvxraT4PdX8PiIZCplom0Ni1rViD8uSBa1KzAP38+yKzw45jDQ879ykH7+/uTlJTEhQsX\nuHDhAr6+vuzfv/9vN3/l0el0kpd/PcSOMym8P9S/dDf/ghxttq+LFwz8zOxv/vdTfhIAaE/8/T6E\nx76DxBiY202r26FYFR93R36Y3J4JnWsTFnWelMx8Csygc/h+5aAV4/pw/UlWHrzEzD6NGBFYs3Qn\n2/wOJJ/UZvu6VDJMgCZSvhLATS2egIkbQNhAWF848IOpI1IMzN7WhrdCm/HZyBbkF+mITcokO9+0\ni8z4+Piwdu1aAHbv3n3P/S5cuIC3t3dZhWX15u84x3d/nmNcx1pM716vdCc7uwX2fAPtnob6IYYJ\n0ITKZwIAqN4Spm4Hvw6wajqsfREK800dlWJgj7XyxcfNEQGcTc7iepb6b1yerD50if+sPUG/5lV5\nK7RZ6YbYZl+HldPBuxH0so71mstvAgBw9YIxK7Txu9HzYVGoNmdAsSoOdjbUr+yGq4MtCTeySbyR\ng84M+gUU44qKTeHF5QdpV6cSn41sie2jzPK9SUpY+wJkJcPQuWDv/OBjLED5TgAAtnbQ+z8w7Hu4\nchi+6wrxe00dlWJgtjaCOt6u+Lg7ci0rj/PJWWbRL/AwzKEz21IcTUzj6SX7qOvtxrxxgTjZl3KM\n/pFf4Njv0OM1rfXASqgEcJP/cJi0SavjsaA/xCwwdUSKgTg5OXHt2jUAqnk641fJhZyCImKTMi1m\n8XkpJdeuXcPJyXLqzJhK/PVsnloQjYeTHYsmtsPTuZTDvVPjYe1LULMDdP6nYYI0EyWaCSyE6At8\nDtgC86WUH9zxeS0gDPABrgNjpJQJ+s8+BAbod31XSvmzfvsM4J9APcBHSmn66ldVm8OUrbBiCqz5\nJ1zaD/0/BjtHU0emlIKvry8JCQkkJ98e9qsr0pGcmU/iBUkFZ3tcH3bBbxNwcnLC19d8lxc0B9cy\n8xgXtpeCIh0/TelIVc9SJkydDlY+A7IIhn5nkbN97+eBf+uFELbAV0AvIAGIFkKsllIeL7bbx8Bi\nKeUiIUQw8D4wVggxAGgNtAQcgW1CiD+klOlAFLAG2GbIL1RqLpXgyeWwdTbs+ASuHocRi8Gzhqkj\nUx6Rvb09derU+dv2tOwCnv/5ANtOXWZkYE3eGdys9E0Fislk5xcycVEMl1Jz+GFyexpUcS/9SXfN\ngQs7YPBXULF26c9nZkrSBNQOiJVSnpNS5gPLgMF37NMU2KL/eWuxz5sCf0opC6WUWcBhoC+AlPKA\nlPJCKeM3Dhtbrab3iCXaeN+53eBClKmjUgzM08We78e3ZUaP+vwcE8/Iubu5nJZj6rCUR1BQpOPZ\nH/ZzJCGVL0e1IrC2AcbnXzkKW96FxgOh5ejSn88MlSQB1ADii/2eoN9W3CFgqP7nxwB3IYSXfntf\nIYSLEMIb6AE81CwMIcRUIUSMECKm+Ct8mWg6CCZHgKMHLB4Ee+ZqowEUq2FrI3ipTyO+HdOa2KsZ\nhH4ZyZ5z10wdlvIQpJS8uuIIW08l858h/vRuZoAZ1AW52mxf54oQ+oVFz/a9H0N1Ar8EdBNCHAC6\nAYlAkZRyI7AO2An8BOwCih7mxFLKuVLKQClloI/PIyzSXFqVG8PUrVC/F/wxU2sPLFBPidamb/Nq\nrHy2Mx5O9oyev4eFUefVqBsL8fHGU/y6L4F/9mzAk+0NVJRty7uQdExr+nH1Msw5zVBJEkAif31q\n99Vvu0VKeUlKOVRK2Qp4Xb8tVf/P2VLKllLKXoAAThsk8rLk5AlP/AjdX9UWfwjrA6lxpo5KMbAG\nVdxZOaMz3Rv58Hb4cV785RC5BQ/1vKKUsUU7L/DV1rOMaufH8yENDHPS83/Crq8gcBI06GWYc5qp\nkiSAaKCBEKKOEMIBeAJYXXwHIYS3EOLmuV5FGxGEEMJW3xSEECIACAA2Gir4MmVjA91fgVHL4Pp5\nmNsdzm03dVSKgXk42TN3bCD/17MhK/YnMvzbnSTcyDZ1WMpdrDtymbfDj9GraRXeHVzKWb435aTC\n78+AVz1tfpCVe2ACkFIWAjOADcAJYLmU8pgQYpYQYpB+t+7AKSHEaaAKMFu/3R7YIYQ4DsxFGx5a\nCCCE+IcQIgHtjeKwEGK+Ab+X8TTqpw0VdfGGJUNg5xzVL2BlbGwEz/dswPfjA7mYkk3ol5HsjDX9\nKGXltl1nr/HPZQdp7VeRL0e1ws7WQK3Z616CzCvabF8HF8Oc04yVn/UADC0vQ+sPOBEOzYfBoC/B\nwdXUUSkGdi45k6eX7ONsciav9mvC5C511JKNJnbicjojvt1FFU8nfp3WkQoud1/97aEd+VVbPbDH\n69DtZcOc00yo9QAMzdFdGyYa8iYcXaGtNnb9vKmjUgysro8bvz/bmT7NqjJ73Qn+seygyauKlmcJ\nN7J5asFeXB21Wb4Gu/mnJWi1fnzbQtALhjmnBVAJoDSEgC4vwuhftb9Ac7tD7GZTR6UYmJujHV+P\nbs3LfRux5vAlhn69k4vXskwdVrlzIyuf8WF7yc4vYtHEdtSoYKCCbDqdVuWzqFBbK8TW/GeFG4pK\nAIbQoCdM3QaevrB0uDaD2IKa1pQHE0IwvXt9Fk5ox+W0XEK/jGTbqSRTh1Vu5OQXMWlRNPE3cpg/\nLpBGVQ0wy/emPd/C+e3Q9z2t87ccUQnAUCrVgUkboflQiJgFy8dp/QSKVenW0IfwGUFUr+DMhIXR\nfLU1Vs0XMLLCIh3P/bSfA/GpfPFES9rXNeC4/KvHYfPb0Kg/tB5vuPNaCJUADMnBVSsr3Xs2nFwD\n83vCtbOmjkoxMD8vF1ZM70RoQHX+u+EUzyzdT6aFVBW1NFJK/r3yKJtPJDFrcHP6Nq9muJMX5mmz\nfZ08rHq27/2oBGBoQkCnGTB2JWQmwdwecGq9qaNSDMzFwY7Pn2jJvwc0YePxKwz5KoqzyZmmDsvq\nfLb5DMui45nRoz5jO9Qy7Mm3zoarR2DQHHAzQZUBM6ASgLHU7QZPb4eKteCnkbDtQ62zSbEaQggm\nd6nL0kntuZ6Vz5A5UWw+rlaUM5Qf9lzki4gzjAj05cXeDQ178guREPUFtHkKGvU17LktiEoAxlTB\nT+sXaDEKtr0HP4+G3DRTR6UYWKf63qye0Zla3i5MXhzD/zafRqdT/QKlseHYFd5YeZTgxpV57zF/\nw869yE2D36dp/Xa9Zz94fyumEoCx2TvDkG+g30dwZiPMC4bkU6aOSjEw34ou/DqtE0Nb1+B/m88w\ndUkM6bkFpg7LIkVfuM4/fjpAgG8F5jxpwFm+N/3xL0i/BI/NBUc3w57bwqgEUBaEgPZPw7jV2tPH\nvGA4vvrBxykWxcnelk8eb8E7g5qx7VQyQ+ZEceaqGgn2ME5fzWDSwmhqVHAm7Km2uDgYeEz+sZVa\nQceuL0HNtoY9twVSCaAs1e4MU7eDTyNYPlYbLqpT1SatiRCC8Z1q8+OUDqTnFjDkqyjWH71s6rAs\nwuW0HMaH7cXR3pZFE9tRydVAs3xvSr+sLfVavTV0nWnYc1solQDKmmcNmPAHtB6nTRj7cQTk3DB1\nVIqBtatTiTXPdaFBFXemLd3PR+tPUqT6Be4pLbuA8WF7ycwtZNGEdtSsZOBCbDodrJquDf0cOg9s\nS7lQvJVQCcAU7By14nED/6eVlJ7bXVt+TrEqVT2d+PnpDoxqV5Ovt51lwsJoUrPzTR2W2cktKGLK\n4hgupGTz3bg2NK3uYfiLRM+Ds1u0Es/e9Q1/fgulEoApBU6ACeu05ee+7wVHfzN1RIqBOdrZ8v7Q\nAN57zJ9dZ1MYNCeKE5fTTR2W2SjSSZ5fdoDoi9f5dGQLOtXzNvxFkk/BpjehQW8InGj481swlQBM\nrWY7bb5A1QD4dSJsfEMrSqVYlSfb+7FsakfyCosY+vVOVh+6ZOqQTE5KyZurjrLh2FXeHNiUgQHV\nDX+RwnxYMUWbpT9oTrmc7Xs/KgGYA/eqMD4c2k6BnV/A0qGQpRYmtzZtalUk/LkgmlX34B8/HWD2\n2uMUFpXfyYFztsTyw544pnWrx4TOdYxzke0fwOVDWqkH9yrGuYYFUwnAXNg5wICPYfDXELdb6xe4\nfMjUUSkGVtndiR+ndGBcx1rM23GecWF7uZ5V/voFlu2N45NNpxnaugb/6tvIOBeJ2w2Rn0GrMdBk\noHGuYeFUAjA3rUbDxPUgi7RFZg4tM3VEioE52Nkwa3Bz/js8gJiLNwj9MpKjieVnhvjm41d57fcj\ndG3ow4fDAoyzwlpuulborYIf9P3A8Oe3EioBmKMarbX5AjUC4fentZmLRWpWqbV5PLAmv07riJSS\nYd/sZMX+BFOHZHT7Lt5gxk/7aV7Dk29Gt8be0LN8b1r/KqTF62f7GnDtACujEoC5cvOBcSuhw3Rt\nwYrFg7XqoopVCfCtwOrngmjlV4EXlh/i7dXHKLDSfoHYpEwmLYqmqocTYU+1xdXRSCtvnQiHg0u1\npR392hvnGlZCJQBzZmsPfd/XJq4k7ofvukHCPlNHpRiYt5sjSye1Z1JQHRbuvMDo+XtIzsgzdVgG\ndTU9l/Fhe7GzESya2A5vN0fjXCjjKoQ/D9VaQvdXjHMNK6ISgCUIGKFVFbW1gwV9Yf9iU0ekGJid\nrQ1vDGzK50+05HBCKqFfRnIwPtXUYRlEeq42yzc1O58FT7WjlpercS4kJax6FvKzYOhcNdu3BFQC\nsBTVArR+gVqdYPVzsOb/tDHOilUZ3LIGvz3TCTtbwYhvd/FzdJypQyqVvMIipi6OITYpk2/HtsHf\n19N4F4v5HmI3Qa93tXpbygOpBGBJXCrBmBXQ+Z8QEwaLBkLGFVNHpRhYs+qehM8Ion3dSvzrtyO8\n9vsR8gotr2igTid54edD7D53nY8fb0GXBkZcdSvlDGz4N9QLgXZTjHcdK6MSgKWxsYVe78DwBVr9\noO+6QdweU0elGFhFVwcWTmjHtG71+HFPHKPm7uZqeq6pwyoxKSWz1hxn7ZHLvN6/CUNa1TDexYoK\ntNm+9k4w+Cs12/chqARgqZoPhcmbtQVnFg6A6O+1NlDFatjaCF7p15ivnmzNySsZDPwykpgL100d\nVol8u/0cC3deYHJQHaZ0rWvci23/CC4dgNDPwcOAi8aXAyoBWLIqTWHqVqjXA9a+AKtnaIXlFKsy\nIKAav0/vjIuDLU/M3c2SXReQZpzsf92XwIfrTzKoRXVe69/EuBeLj4YdH0OLJ6HpYONeywqpBGDp\nnCvCqJ+h68twYCks6Adp1j+hqLxpVNWd1c8G0aWBN2+sOsbLvx4mt8D8+gW2nkriX78dJqi+Nx8/\n3gIbGyM2x+Rlak0/Hr7QT832fRQqAVgDGxsIfh1G/qB1hn3XDS5EmjoqxcA8Xez5fnxb/hFcn1/2\nJTDiu11cSs0xdVi3HIxPZReROQYAACAASURBVPrS/TSu6s43Y1rjYGfk28uG1+DGBRj6HTgZcXSR\nFVMJwJo0GQhTIrS3gkWDYPe3ql/AytjYCF7o3YjvxrbhXHIWoV9Gsuus6SvHnk/JYuLCaLzdHVgw\noS3uTkYeg39yHexfBJ2f14ZGK49EJQBr49MIpmyBhn1h/b+0WkL52aaOSjGwPs2qsvLZzni62DPm\n+z2ERZ43Wb9AUkYu48K0kWiLJ7ansruTcS+YmaTNhanqDz1eN+61rFyJEoAQoq8Q4pQQIlYI8bf5\n1UKIWkKICCHEYSHENiGEb7HPPhRCHNX/GVlsex0hxB79OX8WQhh4BehyzMkDRi7V/uc4vBzC+sCN\ni6aOSjGw+pXdWPVsZ0IaV2bWmuP8388Hyckv236BjNwCJiyIJiUjnwVPtaWOt5Fm+d4kpXbzz8vQ\nSqTYqdtGaTwwAQghbIGvgH5AU2CUEKLpHbt9DCyWUgYAs4D39ccOAFoDLYH2wEtCiJsLfn4IfCal\nrA/cACaV/usot9jYQLeX4cmftZv/3O5wbpupo1IMzN3Jnm/HtOHFXg1ZdegSw77ZSfz1snnjyy/U\nMW3pPk5dyeCbMa1pUbOC8S+6fxGcXq/Nhals5BFG5UBJ3gDaAbFSynNSynxgGXDneKumwBb9z1uL\nfd4U+FNKWSilzAIOA32FVgA8GPhVv98iYMijfw3lnhr20YaKulWBJY9B1BeqX8DK2NgIngtpQNj4\ntsTfyCZ0TiQ7ziQb9Zo6neSlXw4RFXuND4cF0L1RZaNeD4BrZ2H9a1CnG7R72vjXKwdKkgBqAPHF\nfk/QbyvuEDBU//NjgLsQwku/va8QwkUI4Q30AGoCXkCqlLLwPucEQAgxVQgRI4SISU427l9qq+VV\nT5s01iQUNr2hrT2cn2XqqBQD69G4MuEzgqji7sT4sL18u/2s0foF3lt3gtWHLvFy30YMa+P74ANK\nq6hQW+DF1g6GfKO94SqlZqh/iy8B3YQQB4BuQCJQJKXcCKwDdgI/AbuAh2qklFLOlVIGSikDfXyM\nWEvE2jm6weOLoOc7cHwlzO8F18+ZOirFwGp7u7Jieif6Na/GB3+cZMZPB8jKK3zwgQ9h3p/nmB95\nnqc61eaZbvUMeu572vEJJMbAwM/A04hlJcqZkiSARLSn9pt89dtukVJeklIOlVK2Al7Xb0vV/3O2\nlLKllLIXIIDTwDWgghDC7l7nVIxACAj6J4z5DTIuaf0CZzabOirFwFwd7ZjzZCte7deYP45cZujX\nO7mQYpg3vpUHEpm97gQD/KvxxsCmxlnO8U4J+2D7h+A/ApoPM/71ypGSJIBooIF+1I4D8ASwuvgO\nQghvIcTNc70KhOm32+qbghBCBAABwEapvZduBYbrjxkPrCrtl1FKqF4wTN0Gnn7ww3D482PVL2Bl\nhBA83a0eiya242pGLoPmRLL1ZOlWlNtxJpmZvx6iQ91KfDKiBbbGnOV7U36WNtvXvRr0/6/xr1fO\nPDAB6NvpZwAbgBPAcinlMSHELCHEIP1u3YFTQojTQBVgtn67PbBDCHEcmAuMKdbu/y/gBSFELFqf\nwPcG+k5KSVSsrS0y4/84bHkXfh6jDa1TrEqXBj6EzwiiRkUXJi6K5suIM+h0D5/sjyamMW3JPur5\nuDF3XCBO9rZGiPYuNr6hNVU+9i04l8Eoo3JGmHNRqTsFBgbKmJgYU4dhXaSE3d/Axn+DV3144gfw\nbmDqqBQDy8kv4tUVh1l58BK9m1bhkxEtSjxb9+K1LIZ9sxNHO1tWTO9EFQ8jT/S66fRG+PFx6DgD\n+sx+8P7KPQkh9kkpA+/crrrSyzshoON0GLcKslNgXrA2zV6xKs4Otnw2siVvDGxKxMkkhnwVRWxS\n5gOPS8nMY3zYXgp1kkUT25XdzT8rRVvesXIzCHmzbK5ZDqkEoGjqdNGWnKxUF5aNgq3vg05n6qgU\nAxJCMCmoDksntSc1u4AhX0Wx8di9V5TLyitk4sJorqTn8v34ttSv7FY2gUqpLeyemwrD5oGdkRaQ\nV1QCUIqpUBMmroeWo2H7B1oiyE0zdVSKgXWs50X4c0HU9XFl6pJ9fLrx1N/6BQqKdDzzw36OXUrn\nqydb06ZWxbIL8MBSOLlGe/Kv0qzsrlsOqQSg/JW9s7asXv+PIXYzzO0BSSdNHZViYNUrOLP86Y48\n3saXL7bEMnlxDGk5BYC2nOO/fj3Mn6eTee+x5oQ0qVJ2gV0/D+tfgdpdoMOzZXfdckolAOXvhNAW\n1h6/RhsZND8EjqtRutbGyd6Wj4YH8O6Q5vx5OpnBcyI5fTWDD9efYsWBRF7s1ZCRbf3KLiBdkVa9\nVtiq2b5lRP0bVu6tVkd4ertWdGv5ONj8jvY/qWI1hBCM7VCLn6Z2ICu/iIFfRvLt9rOM6eDHjOD6\nZRtM5GcQvwcGfKw1RyoAHEs5xts736agqMDg51YJQLk/j+rw1FpoMwEiP4UfHodsy1iYXCm5trUr\nsea5INrWrsjQVjV4Z1Dzspnle9OlA7DtfWg2VJubUs5JKYm+Es3Tm57mibVPsPHiRmJTYw1+HTUP\nQCm5fYtg3UvarMwnftAW5FCU0srPhrndtDV+p+/UVrQrp6SU7EjcwbzD8ziYfBAvJy/GNRvHiIYj\ncHN49FFY95oHYHe3nRXlrtqM10Zl/DxWKyY3eA74D3/wcYpyP5vfgpTT2lyUcnrzL9IVseniJuYf\nmc+pG6eo7lqd19u/zpD6Q3CyM97cC5UAlIfjG6j1CywfD79N0l7de76jlelVlIcVuxn2zoUO06Fu\nd1NHU+YKigoIPxdO2NEwLqZfpLZHbf7T+T/0r9sfexsjr6uMSgDKo3CrDONXw4bXYdccuHIYhi8E\nVy9TR6ZYkuzrsPJZ8GkMIW+ZOpoylVOYw4ozK1hwdAFXs6/SpFITPu3+KcE1g7G1KaM6S6gEoDwq\nW3vo/xFUbwVr/qm14Y5cCtVbmjoyxRJIqf29yb4Go38B+zIqMWFi6fnp/HzyZ5YcX8KNvBu0rtya\ndzq9Q6fqncq2011PJQCldFqOgsqNtX6BsD4w8H/aNkW5n0PLtLklPd+GagGmjsboruVcY+mJpSw7\nuYzMgkyCagQx2X8ybaq0MWlcKgEopVe9lba+wC9PwcppWr9An9naW4Ki3OnGRVg3E/w6Qad/mDoa\no7qSdYWFxxby2+nfyCvKo1etXkz2n0wTL/NY0F4lAMUwXL1h7EptRMeuOXDlCIxYpPUXKMpNuiL4\nfZr282PfQhm2d5elC2kXCDsaRvi5cJAwsN5AJjafSB3POqYO7S9UAlAMx9ZOe/Kv3gpWzYDvusHI\nJdrIIUUB2PkFxO2EId9CxVqmjsbgTl0/xbwj89h4YSMOtg483vBxJjSbQDW3aqYO7a5UAlAMz384\n+DSCZaNhQT+tsFyb8aaOSjG1y4dgy2xoOhhaPGHqaAzqYNJB5h2Zx58Jf+Jq78rE5hMZ03QM3s7e\npg7tvlQCUIyjqr/WL/DbJAj/B1zaD/0+UrXdy6uCXFgxFVy8tIECJhjxYmhSSnZd2sW8I/OIuRpD\nBccKPNfqOZ5o/AQeDh6mDq9EVAJQjMelEoz+Fbb8R6sjdPUYjFgCHub5OqwYUcQ7kHwSxvym/b2w\nYDqpY0vcFuYdmcfxa8ep7FKZl9u+zLAGw3CxdzF1eA9FJQDFuGxsoedb2vyA35/R5guMWAx+HUwd\nmVJWzm6F3V9Du6lQv6epo3lkBboC1p9fz/wj8zmXdo6a7jV5u+PbhNYLxcHWwdThPRKVAJSy0XQw\neDfU+gUWDoC+H0DbyVbRFKDcR/Z1WDld+2/f8x1TR/NI8oryWHlmJQuOLSAxM5EGFRvwUdeP6FWr\nF3Y2ln0LtezoS2hb/DZ0Uken6p2MWlhJeYDKTWDKFm3Rj3UvQeJ+6Py81mGsEoH1kRLWvghZSTDq\nJ3CwrOaRrIIslp9azuLji0nJSSHAJ4BX271KV9+uJpm1awzlIgEsPr6Y6CvRONs5E1QjiBC/ELr6\ndsXdwd3UoZU/zhXgiZ9g+4fan0M/gkcNqB8C9UKgbrdyWxHS6hz5BY6tgOA3LKpESGpuKj+e/JEf\nTvxAen46Hap14MMuH9K2alurufHfVC7WAyjQFRB9JZotcVuIiIsgJScFOxs72ldtT0itEHrU7GH2\nw7WsUmo8nI2A2Ag4tx3y0kDYQI1Ara24fog2p8BKJwtZtdR4+KazVibkqXUWUS02KTuJxccWs/z0\ncnIKcwiuGcxk/8n4+1j+uhf3Wg+gXCSA4nRSx+Hkw2yJ28LmuM3EZ8QjELSq3Ipgv2BC/ELwdfc1\nUMRKiRUVQmKMlgzORmjNQ0jtbaBudy0h1AvWVihTzJtOB4sHaSVBpkVCJfOa/Xqn+Ix4FhxdwMrY\nleikjn51+jGp+STqVyzjJTGNSCWAu5BScib1DBEXI4iIi+DUjVMANK7UmBC/EEL8Qqhfob7VvfZZ\nhOzrcHaL9ic2AjKvaNsrN9USQf2e4Nex3FSRtCg7v4SN/4ZBc6D1WFNHc0+xN2L5/uj3/HH+D2yE\nDUPqD2FC8wnUdLe+9YhVAiiB+Ix47c3g4mYOJR9CIvFz9yOklpYM/L39sRFqGeUyJyUkHdcSQexm\niNsFRflg5wy1g273H3g3UJ3JpnblKMzrAQ16a+XBzfC/x9GUo8w7PI8t8VtwtnNmRMMRjGs2jsou\n1lu3SiWAh5SSk3Krz2Dv5b0UykIqO1emh18PetbqSZsqbcpkxR7lLvKz4EKUlgzORsA1/WLZnn5Q\nP/h2Z7KTp2njLG8KcmFeMGQlw/RdWoFAM3FzkfV5R+ax+/JuPBw8GN1kNE82fpIKThVMHZ7RqQRQ\nCml5afyZ8Cdb4rYQmRhJblEuHg4edK/ZnRC/EDW81NRuXPxrZ3J+BghbqNlOSwb1g6FaK7BRb29G\ndXOFuCd/gYa9TR0NoN34tydsZ96ReRxOPoyXkxfjm41nRKMRuNq7mjq8MqMSgIHkFOaw89JOtsRt\nYWv8VjLyM24NLw32C6arb1eLqQNilYoKICH6dnPR5YPadhcvqNtD31wUDO5VTRuntTn/JywaBIET\nYOBnpo6GIl0RGy9uZP6R+Zy+cZoabjWY0GwCQxoMwdG2/NWjUgnACAp0BcRciSEiLoItcVtIzkm+\nNbw02C+YYL9gNbzU1LJStFIEN98QspK07VX8bzcX+XVQRepKIydVG/Jp5wjTdoCD6Z6s84vyCT+r\nLbIelxFHXc+6TPafTN86fct1k22pEoAQoi/wOWALzJdSfnDH57WAMMAHuA6MkVIm6D/7CBgA2ACb\ngOellFIIMRJ4XX/ONVLKfz0oDnNLAMXda3hpy8otb40oUsNLTUyng6tHbyeDuN2gKwB7V6jTRd9c\nFAKV6ppl56XZ+m0KHP0NJm0CX9MscZhdkM1vZ35j4bGFJGUn0dSrKVP8pxDsF6wGblCKBCCEsAVO\nA72ABCAaGCWlPF5sn1/QbuKLhBDBwAQp5VghRCfgv0BX/a6RwKvAEeAA0EZKmSyEWAQsllJG3C8W\nc04Axd0aXhoXQcTFvw4vDfYLpqdfTzW81BzkZcKFHbfnHlw/p22vUOv2RLQ6XcFRzRi/p6O/wa8T\noftr0P2Bz3AGl56fzrKTy1h6fCk38m4QWCWQKf5T6Fi9o/r/q5jSJICOwNtSyj76318FkFK+X2yf\nY0BfKWW80P6tp0kpPfTHzgGCAAH8CYwF3IAPpJQh+uPHAh2llNPvF4ulJIA73RxeGhEXwcGkg7eH\nl/qFEFJLDS81G9fP6ZPBFq1NOz8TbOygZvvbQ02rBqjO5JvSEuGbjlqhtwnry3S2b0pOCkuPL2XZ\nqWVkFWTR1bcrk/0n06pyqzKLwZKUJgEMR7u5T9b/PhZoL6WcUWyfH4E9UsrPhRBDgd8AbynlNSHE\nx8BktAQwR0r5uhCiItpbQBDaW8XPgIOUMvQu158KTAXw8/Nrc/HixUf4+ubjfsNLQ/xCCKwaWK7b\nKs1GYT7E77ndXHTlsLbd1UffmayfmezmY9o4TUWngyVDtA73aZHgVa9MLns58zILji1gxZkV5Bfl\n06d2Hyb5T6JxpcZlcn1LZewEUB3tSb8O2lP+MKA54I3WdzBSv+sm4GUp5Q4hRCjwb0AH7ATqSSmH\n3C8WS30DuJf0/HT+TPiTiIsRRF2KIqcw59bw0mC/YDpV74SznbOpw1QAMpNuz0o+uwWyU7TtVQO0\nt4P6PcG3HdhZZl34h7b7G1j/ira6V+AEo1/ufNp5wo6GsebsGgBC64UysflEanvWNvq1rYFRm4Du\n2N8NOCml9BVCzAScpJTv6j97E8iVUn50xzFTgfpSypfvF4u1JYDiig8v3Ra/jfT8dJztnOlcvTMh\ntULU8FJzotPBlUO3k0H8HtAVgoOb1mdws1SFmdfAeWRJJ+C7blCvB4xaZtQO8xPXTjD/yHw2XdyE\no60jwxoOY3zT8Wa7yLq5Kk0CsEPrBA4BEtE6gZ+UUh4rto83cF1KqRNCzAaKpJRv6kf6TAH6ojUB\nrQf+J6UMF0JUllIm6ZuDtgIjpJSn7xeLNSeA4tTwUguTm67vTN6sJYVUfTNlpbq3RxbV7gKObqaN\n0xAK82F+MKRf1mb7uhmnfML+q/uZd2QekYmRuNm7MarxKEY3GY2Xs5dRrmftSjsMtD/wP7Qhm2FS\nytlCiFlAjJRytb6Z6H1AojUBPSulzNOPIPoabRSQBNZLKV/Qn/MnoIX+ErOklMseFEd5SQDF6aSO\nIylHbhWsi8uI+8vw0mC/YKssXmWxpLzdmRy7WUsMBdlgY6/NN7jVmexvmUNNN70FUf/Tnvwb9TPo\nqaWU7Ly0k7mH57I/aT8VHSsytulYRjYeqd5+S0lNBLMCxYeXbonbwsnrJwFoVLHRrYJ1DSo0UMPf\nzElhnjbf4GZn8tWj2na3KlpTUb0QrSnFjOrm3NOFKG05z9bjYNAXBjutTuqIiItg3uF5nLh+giou\nVZjQfAJDGwxVfWAGohKAFbrb8NKa7jXp6deTYL9gAnwC1PBSc5NxRd+ZvFmboZxzHRDailk3m4t8\n24KtmY0Ey02Db4K0xXmmRRqkOatAV8C6c+v4/uj3nE87Ty2PWkxqPomBdQdib27f38KpBGDlbg4v\n3RK3hT1X9lCoK8TH2efWIjdqeKkZ0hVptYpi9QkhIRpkETh6aJ3JN5uLKtYydaTw+zNweBlM3KAV\n2SuF3MJcVsauZMHRBVzKukTDig2Z4j+FXrV6YatWfzMKlQDKkZvDS29WL1XDSy1ETqo2Ae1mc1Fa\nvLbdq75+3kEI1O5c9rV2jq+C5eOg68sQ/PojnyYzP5Plp5ez+NhiruVeo4VPC6YGTKVLjS6q2dLI\nVAIop3IKc9h1aRcRcRF/G14a7BdMt5rdVAebOZISUs7cTgYXIqEwB2wdtJXQbpaqqNzUuJ3J6Ze1\n2b4V68CkjY/UNHUj9wY/nPiBH0/+SEZ+Bp2qd2Ky/2QCqwSqG38ZUQlA+cvw0q1xW0nKScJO2NGu\nWrtbI4rU8FIzVZALcTtvzz1I0pficq+mn3cQos1QdqlkuGtKCUuHwcWdWpVP7wYPdfjVrKssOr6I\nX0//Sk5hDj39ejLZfzLNvJsZLkalRFQCUP7i1vBSfcG6m8NLW/i0oGetnmp4qblLS9SvmRyhdSbn\npgICarS+3VxUo03p6vPsmQt/zIQBn0DbySU+LD49nrBjYayKXYVO6uhfpz+T/CdRr0LZlItQ/k4l\nAOWepJTEpsayOW7z34eX6gvWqeGlZkxXBIn7bzcXJcaA1GlLYtbpdru5yPMhypEnn4LvumoT2Eb/\nUqJmpjM3zjD/yHzWX1iPnbDjsQaP8VSzp1QZdDOgEoBSYgkZCbfmGhxIOqCGl1qanBtwbtvt5qL0\nRG27d6PbI4tqdwb7ewwEKMyH73tCarw22/cBq6cdTj7M/CPz2Rq/FRc7F0Y2GsnYpmPxcSmnhfLM\nkEoAyiNJyUlha/xWIi5G/G14abBfMG2rtlXDS82ZlNrTfOxm7Q3hQhQU5YGdE9TqdHvugU/j20/5\nEe/Cjo9h5FJo8rcCvfrTSvZe2cu8I/PYc3kPHg4ejGkyhiebPImno2cZfkGlJFQCUEotPT+dHQk7\niIiLuDW81N3Bne6+3QnxC6FTDTW81OwV5MDFKH2pighI0RYrwqOG1plcuQls/De0eBKGfPW3w3VS\nx/b47cw/Mp/DKYfxcfZhfLPxDG84vFwtsm5pVAJQDCq3MJedl3b+ZXipk60TnWt0JsQvRA0vtRSp\n8bdnJp/bDnlp2opoz0T9ZSW0Ql0hGy9sZN6RecSmxlLDrQYTm09kcP3B5XKRdUujEoBiNAW6AvZd\n3UfERa3f4M7hpT1q9lDtwZagqBAuHQCParc6jPOL8ll9djVhR8OIz4innmc9JvlPol+dftjZlN0K\nYErpqASglAmd1HE05Sib4zb/bXhpiJ9WsK6mhxpeau6yC7L59fSvLDq2iKScJJp5NWNKwBR61Oyh\nBgBYoHKdAPIvXsS2YkVsPVSTRFm6Obw0Ik4rZX1zeGnDig3p6deTrr5dcXdQC66bkyJZxMYLG1l6\nYimpeam0q9qOyf6T6VCtgxoGbMHKdQKImzyF7L17cevRA8/Qgbh27YqNQzlZus+MJGQk3KpeenN4\nqWKeuvt2Z5L/JFpWbmnqUBQDKNcJIOfIEdJWh5O+di1F169j4+mJR58+eA4Kxbl1a4SNeqUtayk5\nKcRcjaGgqMDUoSh3aFypMQ0qPlzZB8W8lesEcJMsKCBr1y7SwteQsXkzMicHu+rV8BwYiuegUBzr\n1zdgtIqiKOZBJYA76LKyyNiyhbTV4WRFRYFOh2OTJniGhuIxYAD2VYyz1qmiKEpZUwngPgpTUkhf\n9wdp4eHkHjkCQuDSoT2eoYNw790LWzcrWMxbUZRySyWAEso7f5708DWkhYdTEB+PcHTELbgHnqGD\ncAvqjFCdx4qiWBiVAB6SlJLcQ4e0zuN16yhKTcXW0xP3/v3wDB2Ec6uWalicoigWQSWAUpAFBWRG\nRZG+OpyMLVuQubnY+/riEToQz9BQHOvWLfOYFEUpPwoSE7GvUeORj1cJwECKMrPI2LyJ9NXhZO3e\nDTodTs2a4TkoFI/+/bHzUSUPFEUpHV1WFll795IVGUVWZCT5Fy9Sb+MGHPz8Hul8KgEYQUFSEunr\n1pEevobcY8fAxgbXjh3xHBSKW0hPbN1UdURFUR5MSkneqVNkRUaSGRlFzr59yIIChJMTLu3b4dY5\nCI/QgdhVrPhI51cJwMjyzp4lLTyc9PA1FCQmIpyccA8JwXNQKK6dOiHsVc18RVFuK7xxg6yonWRF\nRpIVFUVhcjIAjg0b4hoUhFtQZ5zbtMHGsfTVVlUCKCNSSnIOHCAtPJyMdX9QlJaGbcWKePTvj+eg\nUJwCAlTnsaKUQ7KwkJxDh8iMjCQrMorco0dBSmw9PXHt3AnXzkG4BnXGvkoVg19bJQATkPn5ZEZG\nkhYeTuaWrci8POz9/PAMDcUzdCAOtWubOkRFUYyoIDGRTH07ftauXegyM8HGBucWLXAN6oxbUBBO\nzZsjbG2NGodKACZWlJFBxsZNpK0JJ3v3HpASp4AAPAcOxGNAf+y8vEwdoqIopaTLySE7OvrWU37+\nuXMA2FWrhltQZ+0pv2MHbD3LdtlMlQDMSMHVq6SvXUdaeDh5J06ArS2unTvhGRqKe0gINi4upg5R\nUZQSkFKSd+bMrdE62TExyPx8hKMjLm3bak/5XbrgULeuSZt+VQIwU3lnzpAWvoa0NeEUXrqMcHHB\nvWcInqGhuHbsiLBTqy4pijkpSk0la9euW0/5hVevAuBQvx5unYNw7dIFl8A22Dg5mTjS21QCMHNS\npyNn3z7SwteQvn49uvR0bL28bnceN2+uOo8VxQRkYSE5R46QFRlFZuQOco8cBZ0OGw8PXDt2vNWW\nb1+tmqlDvSeVACyILj+frD//JG11OJlbtyILCnCoXfvWzONHnQyiKErJFFy5oo3J36HvvE1PBxsb\nnPyb4xbUBdegzjj7+1vMG3qpEoAQoi/wOWALzJdSfnDH57WAMMAHuA6MkVIm6D/7CBgA2ACbgOel\nlFIIMQp4DZDAJf0xKfeLo7wkgOKK0tPJ2LiRtNXhZO/dC4Bzy5Z4hA7Eo18/7CpVMnGEimL5dLm5\nZMfsI2vHDjKjIsmPPQuAXeXK2pj8LkG4duyIbYUKJo700TxyAhBC2AKngV5AAhANjJJSHi+2zy/A\nGinlIiFEMDBBSjlWCNEJ+C/QVb9rJPCq/p+XgKZSyhR9ksiWUr59v1jKYwIoruDyZdLXriVtdTh5\np0+DnR1unTvjMSgU9+BgbJydTR2iolgEKSX5587desrPjo5G5uUhHBxwCWyDq/4p37FBA6toer1X\nAijJ+0s7IFZKeU5/omXAYOB4sX2aAi/of94KrNT/LAEnwAEQgD1wVf+zAFyFENcADyD2Ib9TuWNf\nrRpekyfjNXkyuadOkR4eTtqatWS+uB0bFxfce/XCY1Aorh06GH1csaJYmqL0dLJ27iIrSiu3UHj5\nMgAOdepQYeQI3IKCcGnbtlw9SJUkAdQA4ov9ngC0v2OfQ8BQtGaixwB3IYSXlHKXEGIrcBnthj9H\nSnkCQAjxDHAEyALOAM/e7eJCiKnAVAA/1fZ9i1OjRjg1aoTPCy+QHR1DWvhqMjZsJG3VKux8fPDo\n3x+PQaE4NW1qFU8wivKwZFERuceOkbljB1mRUeQcPgxFRdi4uWmdt9Om4RbUuVRVNi1dSZqAhgN9\npZST9b+PBdpLKWcU26c6MAeoA/wJDAOaA95oSWGkftdNwMvAbmA92o39HPAlcEVK+Z/7xVLem4Ae\nRJeXR+a27aSvCSdj23YoKMChbl2tUunAgTj4+po6REUxqoKrSfraOpFkRe2kKC0NhMCpefNbo3Wc\nAwLKXW2u0jQBJQI1IIWJOwAACTpJREFUi/3uq992i5TyEtobAEIIN2CYlDJVCDEF2C2lzNR/9gfQ\nEcjVH3dWv3058MrDfinlr2wcHfHo0xuPPr0pSk0lfcNG0sPDSf7f5yT/73OcW7fGc1Ao7n36PHJV\nQUUxJ7r8fHJiYm6VW8g7fRoAWx9v3Hr0wDUoCNfOndTf93soyRuAHVoncAjajT8aeFJKeazYPt7A\ndSmlTggxGyiSUr4phBgJTAH6ojUBrQf+B+zT/wmQUiYLId4FXKSUL94vFvUG8GgKEhNJW7OWtPDV\n2ugGe3vcunTRylZ3725WE1YU5X6klORfuEDWjkgyoyLJ3huNzMlB2Nvj3KaNVm4hKAjHRo1U02cx\npR0G2h/txm0L/H979xcbVV4FcPx7+o92Ou3sBtjAQgUTFcIahQJdoC2wGoHITPfBfeDBP5j44J/E\nNftgog8aNzG+GaPGbMy6yfp/zWpMZwQJpiRAgTYIVVm2MWRD2W42gS04bact7cwcH+6ldLv9c2mn\nc+fOPZ+kyR3m13IOh+m58/vd+5tXVPWHIvIicFlVO91poh/hLPqeBb6hqvfdK4h+gXMVkAJ/V9UX\n3J/5VeB5YAoYAI6r6tBCcVgDWB5V5X5/v3OzWSpF9vZtKqJRGg4dItaRILJ7ty0em5KTGx0lc/Hi\n9HYLU+84ExA1mzY5Z/htrdS3tFBRb5+/MR+7Ecy8j+ZyjPX2kk6mGDl1inwmQ9UTT9AYjxNLxFm1\ndaudQRlfaD7PxBvX3at1zjN+tc9ZvI1EiOzdO32WX9PUtPgPM4A1ALOA/MQEo2fOkE6mGD17FrJZ\nVn30IzQmOojFj1L95JN+h2jKXPbOHUa7u52z/O5ucvfuAVC7bdv0jVh127eHbvG2UKwBGE+y9+4x\ncuoU6c4k41euABDZtYvGjgSNhw8XfRtbU550cpKxK1eds/xz57nf3w9A5erV1LfuI9reTv2+fbZN\neoFYAzCPbHJwkOFUinRnksm33kKqq4kePEBjPEH04IGCfFSdCY/JgYHpHTQzPT3o2BhUVRHZsYP6\n9naiba3O1GNFhd+hlh1rAGbJVJWJ69cZ7kySPvE3cnfeo6KhgcYjh2mMJ4js3mUvWvMBudEMY709\n09stTL3t3E9a3dQ0vU9+pOVpKqO2eLvSrAGYgtBcjsylSwx3Jhk5fZr82BhV69cTix+lMZ6gdsvH\n/A7R+ETzee739zvX5J87x1hfH0xNIZEI9S0t1Le3EW1ro2bTJr9DDR1rAKbg8uPjjHR1MdyZZLS7\n21k83rLFufP46FGq163zO0SzwrJDQ2QuXHC2W+i+QG7IuZJ71datzg6arW3UNe+goqbG50jDzRqA\nWVHZu3cZPnmS4WSK8b4+ECHS0kIsEafh0CEqGxv9DtEUgE5NMd7X5+yTf/48E9edPSErH3+c+tZW\nZ2qntZWqtWt9jtTMZA3AFM3krVukk0mGkykmb95EamqIPvMMsUSc+v377WwwYCYHBx9um3zpEvlM\nBiorqduxnWibc5Zf+9Q2WwcqYdYATNGpKhPXrpHuTDJ84gS5oSEqYjEajxwhlohT19xsvzRKUH5s\njExvLxn3LH9yYACA6g0bHt55u2cPlQ0NPkdqvLIGYHyl2SyZixdJJ5OMnP4HOj5O1dq1VMRsaqik\nKEzduoVOTSG1tUSebnE+6LytjZoPb7a7wwNqObuBGrNsUlVFtL2daHs7+UyGka4uRs+eQycn/Q7N\nzBI9cIBoWyt1O3favR5lzhqAKbqK+npiiQSxRMLvUIwJNZuANcaYkLIGYIwxIWUNwBhjQsoagDHG\nhJQ1AGOMCSlrAMYYE1LWAIwxJqSsARhjTEgFaisIEbkDDCzx29cA7xUwHD+VSy7lkgdYLqWqXHJZ\nbh6bVPUDW7QGqgEsh4hcnmsvjCAql1zKJQ+wXEpVueSyUnnYFJAxxoSUNQBjjAmpMDWAX/odQAGV\nSy7lkgdYLqWqXHJZkTxCswZgjDHm/cL0DsAYY8wM1gCMMSakyqoBiMgrInJbRK7N87yIyE9F5IaI\n/FtEmosdo1cecjkoImkR6XO/vlfsGL0QkSYROSMi10XkDRF5fo4xgaiLx1yCUpdaEekVkX+5ufxg\njjGrROQ1ty49IrK5+JEuzGMex0XkzoyafMWPWL0SkUoRuSoiqTmeK2xNVLVsvoD9QDNwbZ7nPwuc\nBATYA/T4HfMycjkIpPyO00Me64Fm97gB+C+wLYh18ZhLUOoiQNQ9rgZ6gD2zxnwdeMk9Pga85nfc\nS8zjOPBzv2N9hJxeAH4/1/+jQtekrN4BqOpZ4O4CQ54Ffq2OS8BjIrK+ONE9Gg+5BIKqvquqV9zj\nEeBNYMOsYYGoi8dcAsH9tx51H1a7X7OvCHkWeNU9fh34tJTYp8J7zCMwRGQjcBR4eZ4hBa1JWTUA\nDzYAb894PEhAX8Cuve5b35Mi8pTfwSzGfbu6A+csbabA1WWBXCAgdXGnGvqA28BpVZ23LqqaBdLA\n6uJGuTgPeQB8zp1efF1Emooc4qP4CfBtID/P8wWtSdgaQDm5grO/xyeBnwF/9TmeBYlIFPgz8C1V\nHfY7nuVYJJfA1EVVc6q6HdgItIjIx/2OaSk85JEENqvqJ4DTPDyDLikiEgduq+o/i/V3hq0BvAPM\n7P4b3T8LHFUdfvDWV1VPANUissbnsOYkItU4vzB/p6p/mWNIYOqyWC5BqssDqvo/4AxwZNZT03UR\nkSogBgwVNzrv5stDVYdU9b778GVgZ7Fj86gV6BCRm8AfgU+JyG9njSloTcLWADqBL7pXnewB0qr6\nrt9BLYWIrHsw9yciLTi1LLkXpxvjr4A3VfXH8wwLRF285BKguqwVkcfc4zrgM0D/rGGdwJfc4+eA\nLnVXH0uFlzxmrSd14KzdlBxV/Y6qblTVzTgLvF2q+vlZwwpak6qlfmMpEpE/4FyFsUZEBoHv4ywK\noaovASdwrji5AYwBX/Yn0sV5yOU54GsikgXGgWOl9uJ0tQJfAP7jztMCfBf4EASuLl5yCUpd1gOv\nikglTpP6k6qmRORF4LKqduI0u9+IyA2cCxKO+RfuvLzk8U0R6QCyOHkc9y3aJVjJmthWEMYYE1Jh\nmwIyxhjjsgZgjDEhZQ3AGGNCyhqAMcaElDUAY4wJKWsAxhgTUtYAjDEmpP4PczLtQNBcMp0AAAAA\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfbLSwCp032T",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 20 gen x 2 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLTxO6ll09ah",
        "colab_type": "code",
        "outputId": "b60a1a80-5ba8-473a-d18c-834b0fd387f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.3626 - acc: 0.8795\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0662 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0481 - acc: 0.9858\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0334 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0314 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.3425 - acc: 0.8873\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0595 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0389 - acc: 0.9884\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0332 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0261 - acc: 0.9919\n",
            "10000/10000 [==============================] - 3s 252us/step\n",
            "this gen fitnesses: [0.991  0.9921]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.3743 - acc: 0.8771\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0667 - acc: 0.9798\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0418 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0334 - acc: 0.9897\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0284 - acc: 0.9916\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 418us/step - loss: 0.4037 - acc: 0.8683\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0634 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0469 - acc: 0.9854\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0355 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0310 - acc: 0.9908\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "this gen fitnesses: [0.9896 0.9893]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.2654 - acc: 0.9180\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0554 - acc: 0.9838\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0420 - acc: 0.9874\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0320 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9913 0.9893]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 26s 441us/step - loss: 0.2869 - acc: 0.9105\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.0522 - acc: 0.9840\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.0405 - acc: 0.9876\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.0306 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 248us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 26s 440us/step - loss: 0.2172 - acc: 0.9337\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0410 - acc: 0.9881\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0338 - acc: 0.9900\n",
            "10000/10000 [==============================] - 3s 251us/step\n",
            "this gen fitnesses: [0.9882 0.9865]\n",
            "\t\t\tStarting generation 5...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 27s 442us/step - loss: 0.2547 - acc: 0.9156\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0478 - acc: 0.9858\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0374 - acc: 0.9883\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0298 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 249us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3412 - acc: 0.8876\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0587 - acc: 0.9819\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0393 - acc: 0.9878\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0314 - acc: 0.9903\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0263 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "this gen fitnesses: [0.9895 0.992 ]\n",
            "\t\t\tStarting generation 6...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.1586 - acc: 0.9528\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0327 - acc: 0.9901\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0284 - acc: 0.9916\n",
            "10000/10000 [==============================] - 2s 243us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.987 0.992]\n",
            "\t\t\tStarting generation 7...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.987 0.992]\n",
            "\t\t\tStarting generation 8...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.987 0.992]\n",
            "\t\t\tStarting generation 9...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 26s 441us/step - loss: 0.1657 - acc: 0.9504\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0319 - acc: 0.9905\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0274 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 250us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3311 - acc: 0.8926\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0612 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0410 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0298 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0268 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "this gen fitnesses: [0.992  0.9902]\n",
            "\t\t\tStarting generation 10...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.2730 - acc: 0.9111\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0568 - acc: 0.9827\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0367 - acc: 0.9890\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0313 - acc: 0.9904\n",
            "10000/10000 [==============================] - 2s 239us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.3455 - acc: 0.8870\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0649 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0418 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0339 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0296 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 234us/step\n",
            "this gen fitnesses: [0.9907 0.9885]\n",
            "\t\t\tStarting generation 11...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.1529 - acc: 0.9527\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0428 - acc: 0.9872\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0306 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.2384 - acc: 0.9276\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0504 - acc: 0.9848\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0368 - acc: 0.9889\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0293 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 234us/step\n",
            "this gen fitnesses: [0.9923 0.9907]\n",
            "\t\t\tStarting generation 12...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.2713 - acc: 0.9120\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0546 - acc: 0.9838\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0447 - acc: 0.9869\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0351 - acc: 0.9894\n",
            "10000/10000 [==============================] - 2s 232us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9858 0.9907]\n",
            "\t\t\tStarting generation 13...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.2564 - acc: 0.9153\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0488 - acc: 0.9851\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0363 - acc: 0.9891\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0313 - acc: 0.9906\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "this gen fitnesses: [0.9858 0.9927]\n",
            "\t\t\tStarting generation 14...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9858 0.9927]\n",
            "\t\t\tStarting generation 15...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.4566 - acc: 0.8495\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0670 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0446 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0373 - acc: 0.9889\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0289 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 15s 249us/step - loss: 0.3770 - acc: 0.8751\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0634 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0468 - acc: 0.9860\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0374 - acc: 0.9885\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.0291 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 176us/step\n",
            "this gen fitnesses: [0.9875 0.9901]\n",
            "\t\t\tStarting generation 16...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.3939 - acc: 0.8618\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0463 - acc: 0.9864\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0376 - acc: 0.9888\n",
            "10000/10000 [==============================] - 2s 233us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 0.1553 - acc: 0.9523\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0398 - acc: 0.9883\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0294 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 173us/step\n",
            "this gen fitnesses: [0.9916 0.99  ]\n",
            "\t\t\tStarting generation 17...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 1.0689 - acc: 0.6180\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.1359 - acc: 0.9658\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0688 - acc: 0.9819\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0517 - acc: 0.9858\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0364 - acc: 0.9903\n",
            "10000/10000 [==============================] - 2s 217us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.989 0.99 ]\n",
            "\t\t\tStarting generation 18...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.5289 - acc: 0.8377\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0473 - acc: 0.9863\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0317 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 225us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.3368 - acc: 0.8898\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 365us/step - loss: 0.0609 - acc: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0414 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0328 - acc: 0.9903\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0302 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 224us/step\n",
            "this gen fitnesses: [0.9903 0.9913]\n",
            "\t\t\tStarting generation 19...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 15s 249us/step - loss: 0.3377 - acc: 0.8890\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0632 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0455 - acc: 0.9863\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.0328 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 14s 232us/step - loss: 0.0287 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 168us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.99   0.9913]\n",
            "\t\t\tStarting generation 20...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.3031 - acc: 0.9001\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0587 - acc: 0.9815\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0398 - acc: 0.9878\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0323 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0264 - acc: 0.9921\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.2482 - acc: 0.9215\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0558 - acc: 0.9829\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0354 - acc: 0.9894\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0304 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 222us/step\n",
            "this gen fitnesses: [0.9877 0.9943]\n",
            "The best individual [0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1] had fitness (accuracy): 0.9943\n",
            "CPU times: user 29min 38s, sys: 9min 6s, total: 38min 44s\n",
            "Wall time: 46min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B3dQCPt9gQN",
        "colab_type": "code",
        "outputId": "16aa4e74-1304-4aad-aa31-d643e819c4a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 2)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3iV1334P0d7IqGBGNoLEBtklliG\nYINn7DiecWyS1GlaN0nTuLV/adzWqeskTpM0jdPEbfAKiRM7tgN4YBtjY7NsCcSUBBJoDwTae53f\nH+deuIgr3au7x/k8j5579a7zvVev3u853ymklGg0Go3G/whwtwAajUajcQ9aAWg0Go2fohWARqPR\n+ClaAWg0Go2fohWARqPR+ClB7hZgIiQkJMj09HR3i6HRaDReRVFR0QUpZeLo7V6lANLT0yksLHS3\nGBqNRuNVCCGqzG3XJiCNRqPxU7QC0Gg0Gj9FKwCNRqPxU7zKB2COwcFBamtr6evrc7codhEWFkZy\ncjLBwcHuFkWj0fgJXq8AamtriY6OJj09HSGEu8WxCSklFy9epLa2loyMDHeLo9Fo/ASvNwH19fUR\nHx/vtQ9/ACEE8fHxXr+K0Wg03oXXKwDAqx/+RnzhM2g0Gu/CJxSARqPR+CoVzV389N0yznc43kKg\nFYCDeeyxx9izZw9vvPEGTz31FACvvPIKc+bMISAgQCeyaTSaCfHx6WZ+8UE5gyOO792iFYCDOXTo\nEMuXL+ejjz5izZo1AMydO5fXXnvt0u8ajUZjLYVVrUyLCWNGbLjDr+31UUCewiOPPMKuXbs4d+4c\nK1asoKKigt27d3PHHXfw+OOPu1s8jUbjpRyuamVJ2mSnXNunFMC/7TjJqfoOh14zb/ok/uXmORaP\ne/rpp7nzzjt58cUX+elPf8q6devYt2+fQ2XRaDT+RX1bL/XtfTzkJAVglQlICLFJCFEmhCgXQjxq\nZn+aEGK3EOKYEOJDIUSyyb4fCSFOGH7uMnPuL4QQXfZ9DM/g8OHDLFiwgNLSUmbPnu1ucTQajZdT\nWNUKwJK0OKdc3+IKQAgRCDwDbARqgc+EENullKdMDvsJ8KKU8gUhxHrgKeB+IcSNwGJgIRAKfCiE\neFtK2WG4dj7gMNVmzUzdGRQXF/Pggw9SW1tLQkICPT09SClZuHAhBw4cIDzc8bY7jUbj+xRVthAR\nEsjsadFOub41K4ClQLmU8qyUcgB4Gbh11DF5wAeG93tM9ucBe6WUQ1LKbuAYsAkuKZangX+07yO4\nn4ULF1JcXExubi6nTp1i/fr17Nq1i+LiYv3w12g0NlNY1crClFiCAp0Tr2PNVWcANSa/1xq2mXIU\nuN3w/jYgWggRb9i+SQgRIYRIAK4FUgzHPQxsl1I2jDe4EOIhIUShEKKwubnZCnHdQ3NzM5MnTyYg\nIIDS0lLy8vIu7Xv99ddJTk7mwIED3HjjjVx//fVulFSj0XgD3f1DlDR0kO8k+z84zgn8XeCXQogH\ngb1AHTAspXxXCHENsB9oBg4Aw0KI6cAXgXWWLiylfBZ4FiA/P9/xgbAOIjExkTfffBOAgwcPXrHv\ntttu47bbbnOHWBqNxksprmljRMKSdOfY/8G6FUAdl2ftAMmGbZeQUtZLKW+XUi4CvmfY1mZ4fVJK\nuVBKuREQwGlgEZANlAshKoEIIUS5vR9Go9FofIXCylaEgEWpsU4bw5oVwGdAjhAiA/Xgvxu41/QA\ng3mnRUo5AjwGbDVsDwRipZQXhRDzgfnAu1LKIWCqyfldUspsR3wgjUaj8QUKq1qYmRTNpDDnlYi3\nuAIwPKwfBnYBJcCfpJQnhRBPCCFuMRy2DigTQpwGkoAnDduDgY+FEKdQZpwvGa6n0Wg0mjEYHpEU\nV7c5LQHMiFU+ACnlW8Bbo7Y9bvL+VeBVM+f1oSKBLF0/yho5NBqNxh843dRJZ/8Q+enOVQC6FpBG\no9F4GJcSwFKd5wAGrQA0Go3G4yiqbCExOpSUOOfmEWkF4GDMlYN+5JFHmDVrFvPnz+e2226jra3N\nzVJqNBpPprCqlfy0yU5vFKUVgIMxVw5648aNnDhxgmPHjpGbm3tJMWg0Gs1omjr6qG3tdboDGHys\nGqg7sbYc9PLly3n11av85RqNRgNAkcH+n+/EBDAjvqUA3n4UGo879ppT58HmH1o8zNpy0Fu3buWu\nu64qiqrRaDSASgALDQogb9okp4+lTUAOxFI56CeffJKgoCDuu+8+N0in0Wi8gaKqFhakxBIS5PzH\ns2+tAKyYqTsDa8pBP//88+zcuZPdu3c73bGj0Wi8k96BYU7Wd/DQmkyXjKdXAA7AUjnod955hx//\n+Mds376diIgId4ur0Wg8lKO1bQyNSKcngBnRCsBBjFcO+uGHH6azs5ONGzeycOFC/vqv/9qNkmo0\nGk/F6ABenOoaBeBbJiA3Ml456PJyXehUo9FYprCyhewpUcRGhLhkPL0C0Gg0Gg9gZERSZEgAcxVa\nAWg0Go0HUNHcRUffkEsSwIz4hAKQ0mMbhVmNL3wGjUZjO4UuTAAz4vUKICwsjIsXL3r1A1RKycWL\nFwkLC3O3KBqNxk0UVrYSHxlCerzrIgW93gmcnJxMbW0tntww3hrCwsJITk52txgajcZNFFW1sNgF\nBeBM8XoFEBwcTEZGhrvF0Gg0Gptp7uyn8mIP9yxNdem4Xm8C0mg0Gm/ncLXR/u86BzBoBaDRaDRu\np6iqlZDAAObOiHHpuFoBaDQajZsprGxhXnIMoUGBLh1XKwCNRqNxI32Dw5yo63BpApgRrQA0Go3G\njZyoa2dgeMSlCWBGtALQaDQaN2JMAHOHAvD6MFCNRjM+PQNDHDrXwsiI7cmSSZPCXO6g9BcKK1vJ\nSIgkPirU5WNrBaDR+Di/2F3Orz+qsOsagQGCQ/9vAwlueEj5MlJKDle3sn7WFLeMrxWARuPDjIxI\nthfXsTIrnkc3z7LpGucudPOtl4vZX3GRWxZMd7CE/s3ZC920dA+4xQEMWgFoND7N4epW6tv7eGTT\nTOYnx9p0jTnTY/j+GyfYX35BKwAHU1TlngQwI9oJrNH4MDuO1hMaFMDnZifZfI3AAMGKrHg+PnPB\nq4sueiJFla3ERgSTmRDllvG1AtBofJSh4RHePN7A+llTiA4Ltutaq7ITqGvrpbqlx0HSaQAKq1pY\nnDqZgADXFYAzRSsAjcZHOXSuhQtdA9zsALNNQXYCAJ+UX7D7WhpFa/cAFc3dbgn/NKIVgEbjo+w4\nWk9kSKBDIkwyEiKZHhPGPq0AHMYl+79WABqNxpEMDI3w9olGrpszlbBg++vLCCFYmZ3A/oqLduUT\naC5TVN1KUIBgQYptznlHoBWARuODfHymmfbeQW5eMM1h11yVnUBbzyCnGjocdk1/pqiylTkzYhyi\noG1FKwCNxsm8dLCKTT/fS9/gsMvG3HG0npjwYFZlJzrsmiuz4wHtB3AEA0MjHK1tc6v5B7QC0Gic\nyuDwCM98UE5pYyc7jzW4ZMzegWHeO9XE5rlTCQly3L/4lOgwZiZFaz+AAzhR307/0IhWABqNL7Pr\nZCONHX1EhgTy3L5zLomj31N2nu6BYYdE/4ymIDuBT8+1uHQ144scNhaAc1MCmBGtADQaJ/L8vkrS\n4iN49IbZnKzvuBT54Ux2HK0nISqU5ZnxDr/2qpx4+odGLj3ANLZRWNlKalwEU6LD3CqHXyiA4po2\n9pSed7cYGj/jeG07hVWtfHlFOl9YPINJYUE8t7/SqWN29g2yu/Q8N82fRqATkouWZsQTFCDYV6HN\nQLYipaSwqtWt8f9GrFIAQohNQogyIUS5EOJRM/vThBC7hRDHhBAfCiGSTfb9SAhxwvBzl8n2bYZr\nnhBCbBVC2JeqOA4/f/80P3jzlLMur9GY5fn9lUSEBPLF/GQiQoK4e2kq75xopKG912ljvneqiYGh\nEYdG/5gSFRrEwpRYPim/6JTr+wPVLT1c6Or3DgUghAgEngE2A3nAPUKIvFGH/QR4UUo5H3gCeMpw\n7o3AYmAhsAz4rhBikuGcbcAsYB4QDnzN7k8zBqtzEjnb3E1tq/+msQ8Oj/j1j6tj15s7+9lxtJ47\nliQzyVCG4f7laUgpeelAldPG3XG0nhmx4SxKcd7DpSA7geO1bbT3DDptDF+msNK9BeBMsaYa6FKg\nXEp5FkAI8TJwK2A6pc4DvmN4vwd4w2T7XinlEDAkhDgGbAL+JKV8y3iyEOJTIBknsTY3gR8Ae09f\n4N5lqc4axmP56Xun+cXuM+4Ww61kJETy9rdWuyzm+g+fVjMwPMIDK9MvbUuJi2BjXhJ/+LSab27I\ncbgsrd0DfHzmAl9dleHU2jKrchL4r91nOHD2IpvmTnXaOL5KUXUr0aFB5E6JdrcoVimAGUCNye+1\nqNm8KUeB24H/Am4DooUQ8Ybt/yKE+E8gAriWKxUHBtPP/cC3zA0uhHgIeAggNdW2h3dWYhTTYsL4\n+EyzXyqAj043k5kYye2LZrhbFLfQ0TfEs3vP8uKBSh5ak+X08QaGRvjdwSrW5iaSlXhllccHV2aw\n62QT24vrufOaFIeO+87JRoZGpFOif0xZmBJLZEgg+8ovaAVgA0WVrSxKc18BOFMc1Q/gu8AvhRAP\nAnuBOmBYSvmuEOIaYD/QDBwARseP/Qq1SvjY3IWllM8CzwLk5+fbtI4XQrAmJ5G3TjQwNDxCUKBf\n+L4BGB6RnG7s5J6lqTy8Psfd4riNssZOfvVhBXcvTb1kknEWb59o4HxnPz+6I/2qfcsz45g1NZrn\n9lfyxfxkhHDcQ2DH0XoyEyKZM32S5YPtIDgwgGWZ8TofwAbaewc5fb6TG+c7x0czUax5EtYBplOV\nZMO2S0gp66WUt0spFwHfM2xrM7w+KaVcKKXcCAjgtPE8IcS/AIlcNh85jdW5CXT2DXG0tt3ZQ3kU\n1S099A4OM2ua+5eb7uSR62fS1jPI/+496/SxnttXSUZCJGtzrs7CFULw4Mp0Sho6OHSuxWFjnu/o\n48DZi9y0YLpDlcpYrMyK5+yFburbnOfQ9kUOV7cipXsLwJlijQL4DMgRQmQIIUKAu4HtpgcIIRKE\nEMZrPQZsNWwPNJiCEELMB+YD7xp+/xpwPXCPlHLEER9mPFZlJxAgYO/pZmcP5VGUGOq2zJ7q3Fmh\npzN3Rgw3zZ/Gbz85R3Nnv9PGOVLdSnFNGw+sSBtzif/5RTOIjQjm+X2VDhv3zeMNSAk3u2hmuSpH\nlYfWq4CJUVTZSmCAYGGq+wrAmWJRARgcuA8Du4ASlAP3pBDiCSHELYbD1gFlQojTQBLwpGF7MPCx\nEOIUyozzJcP1AH5tOPaAEKJYCPG4oz6UOWIjQpifHMvHZ/xLAZQ2dBAgICfJPR2HPIl/uG4m/UMj\nPLOn3GljvLC/kqjQIO7IH9u+HxYcyD1LU3n3VKPDItN2HK1n1tRocpJcs9KbmRRNQlSIVgATpKiq\nlbxpk4gI8YxuvFYZw6WUb0kpc6WUWVLKJw3bHpdSbje8f1VKmWM45mtSyn7D9j4pZZ7hZ7mUstjk\nmkGG6y00/DzhjA9oypqcBIpr/Ct87VRDJ5mJUW6tOOgpZCREcmd+CtsOVVHjhM5W5zv6ePN4A1/M\nTyYqdPx/8C8tT0MIwUsH7Q8JrWnp4XB1G7csdF2/XiEEBdkJfFJ+UbeJtJLB4RGKa9o8Iv7fiP94\nQ4E1uYmMSNjvR1mMpY0dzJ7m3+YfU761IYcAIfjZ+6ctHzxBth2qZmhE8sCKdIvHzogN5/o5Sbz8\naQ29A/bV1XnzuCoyd/N81zZsL8hO4EJXP6ebulw6rrdS0tBB7+CwVgDuYkFKLNGhQez1EzNQR98g\nta29zJrq3w5gU6bGhPHgynReP1JHWWOnw67bPzTMtkNVXDtzCukJkVads6Ugg/beQV4/Umf54HHY\ncbSehSmxpMRF2HWdiaLbRE4MT0oAM+JXCiA4MICV2fHsPX3BL5atxgfcbD+PABrNN9ZlERUaxNO7\nyhx2zTePNXCha4AHTRK/LJGfNpk50yfx/H7bq4RWNHdxsr7D6bH/5pgRG05GQiT7nawAShs7+N7r\nxxkYcnqsiFMpqm5lRmw402LC3S3KJfxKAYAqC1HX1svZC93uFsXplBojgLQJ6ApiI0L4+ppM3i9p\nckh1Tiklz+2rJHtKFKsN0THWYAwJPd3UxYEK22rr7DhajxBw4zz3xJUXZMdz8OxFBoed93D+4dul\nbDtUzdsnXNNPwRlIKSmqbGWxB5l/wA8VwNpcFZv9sR+Eg55q6CQmPJipk9xbctYT2VKQQUJUKD96\np9Tu1eDh6jaO17XzwMr0Ccfg37xgOnGRITZVCZVSsuNoPUvT45ga456/8arsBLoHhjla0+aU65c2\ndvBhmfpffd7JlVSdSV1bL40dfR4T/2/E7xRASlwE6fER7D3j+3ZL5QCOdklikLcRGRrENzdk8+m5\nFj6yczLw3L5zRIcF2VRqIyw4kHuXpvJ+SdOEI5NKGjqpaO52afTPaFZkJiCE8/wAz+49S0RIIN/+\nXA5HqtsodpKicTbGlaYnOYDBDxUAqGigAxUX6R/y3a5GIyOSssZOZvl5Ath43H1NKilx4Ty9q8zm\naqEN7b28faKRu/JTiLQQ+jkWX1qeRqAQvDDBGe6OY/UEBgg2z3VfWYGYiGDmz4hxSj5AfVsv24vr\nueuaFL66KoOo0KAJf0eeQmFlK5EhgR4XkOGXCmB1TiK9g8Mu6c7kLqpbeugZGNYO4HEICQrgOxtz\nOVnfcSmUcqJsO1jNiJR82YrQz7GYGhPG5nnT+GNhDd39Q5ZP4LL5Z1V2AnGRITaP7QhWZidwpLrN\natmt5bl955DAV1dlEB0WzB1Lktl5rJ7znX0OHccVFFW1sih1ssfVIfMsaVzEiizV1Wjvad81A5U2\nagewNdyyYAYzk6L56XunJ+zI7Bsc5vefVvO52UmkxtsXgvngynQ6+4Z4zcqQ0OKaNmpbe90S/TOa\nVdkJDI1IPnVgbaP23kF+f6iam+ZPI3my+m4fWJnO0Ihk28Fqh43jCrr6hyht7PA4BzA4rhqoVxEV\nGsTitMl8fKaZRzfPcvp4fymuo7mzn6+tznT6WEZONXQSICDXRaUBvJXAAMEj18/kay8W8kph7YTK\nhe84Wk9L9wBbJhD6ORaLU2OZnxzD8/vO8aVlqRb9NtuP1hMSFMB1c5LsHttelqRNJjQogE/KL3Dt\nrCkOuea2Q1V0Dwzz0JrL/zMZCZFcO3MK2w5V8zfXZhEa5Jrs9pKGDv7jrRKGbTQTdvcPMeJBBeBM\n8csVAKhooJP1HU4tDAaqNvwPdpbws/dO23wD2UJpQwcZCZG6BIQVbJg9hSVpk/mv3afpG7TOL2QM\n/cxNimJFlv3N14UQbClIp6K5m48tBCgMj0jePNbAtTMTnV7a2hrCggO5Jj3OYX6A/qFhnttXyeqc\nBOZMj7li34Mr07nQ1c9bNprsJoqUkid2nOJIdZvN3ehCggK4Li+Ja9LjXCLzRPDLFQDA6pwEnt5V\nxr7yC3zeiY1S3jvVxIUupWRON3W6zCRT2tjJvOQYywdqEELwj9fP5K5nD/LC/kq+vtZy05jPKls5\n1dDBf9w2z2FRVjfMm8aTb5by/P5K1uReXUrayKfnWjjf2e8R5h8jBdkJ/OidUs539jEl2r6Q1DeO\nqBXzz+5ceNW+1TkJZCVG8ty+Sj6/cIbTI9w+Kb/AgbMX+Zeb89hSkOHUsdyB364A5k6PIS4yxOnl\nobcdqiImXM3SDle7xunc2TdIdUsPsz0s4sCTWZYZz7qZifzqwwraey0XC3x+/zliwoO5zYGTh9Cg\nQO5blsoHpec5N06i4o5j9USEBLLeQeYWR7DKUBbC1oQ2IyMjkmf3niVv2iQKsq9eWRmT547VtnPE\nySGhIyOSH79TxozYcJ/tJOi3CiAgQLAqO4G9Z5xXFuJscxf7Ky7y0JpM4iNDOFzlmhjm003GEhDa\nATwRHrl+Ju29gzy7t2Lc4+raetl1som7l6YQHuJYE9t9y1IJDhS8eKDS7P7B4RHePt7A52YneUxJ\nYYC86ZOICQ+22wy0u/Q8Fc3dfH1t5piz+9sXJxMdFsRzDuynYI63TzRyvK6d72zMdZm/wdX4rQIA\ntZy80NVPSYPjioKZ8odPqwkKEHwxP5lFqbEccdEK4JTh88zSCmBCzJkew80LprP1k8pxQw1fOlCF\nlJL7l6c5XIYpk8K4cd40XimspctMWOW+8gu09gx6lPkHlDN9ZVY8n9g5oXp2bwUzYsPHLW0RGRrE\nXfkpvH28gcZ254SEDg2P8J/vlpGbFOVUE7G78WsFYLSzOqNJTN/gMK8U1XL9nKlMiQ5jUepkzl7o\nprV7wOFjjaa0oYNJYUFMd1N5AG/mHzbmMjg8wi8/MN80pndgmJc/q+a6vKmXwhMdzZaCDLr6h3i1\nsOaqfduP1jMpLIg1udbXHHIVBdkJ1Lf3UXnRtl4LRVUtfFbZytdWZ1iMl//yinSGpWTbIfv7KZjj\n1aJazl7o5rvXzSTQA5q3Owv/UADvfh/+8vBVm5MmhTEzKdop5aHfPtFAW88g9xlsh4tTVQiYK1LZ\nSxs7mTVtki4BYQPpCZHceU0Kf/i0mmozD7K/FNfR1jPIgwXpTpNhQUosi1JjeeFA1RUZyn2Dw7x7\nsolNc6d6pElilZ3loX/z0VliI4K565qxu6kZSY2PYMOsJH5/qNrqyC1r6Rsc5ufvn2FRaiwb89wf\nZutM/EMBDA/C0Zeh6+oH/ZrcBD4710rPgGOzGLcdrCYjIfJSiOCClBgCA4TTHcEjI5LShg7tALaD\nsZrGSCl5fn8ls6ZGsyzDuSF9D65M59yFbj4ymZx8WNZMV/+Qx5l/jKTFRzAjNpx9NtTZqmju4r2S\nJu5fnma1b2NLQToXuwfYecyxIaEvHaiisaOPf7x+ls9PovxDAeRvgZFBKP7dVbtW5yQyMDzCIQdm\nMZY1dlJY1cq9Sy8n9ESEBDFrarTTFUBtay/dA8PaAWwHSZPC2FKQwRvFdZcyqgEOnm2htLGTLQUT\nr/o5UTbPncaU6NArGsfvOFZPfGQIKzLtzztwBqpNZDz7Ky5MOOfl/z4+S3BgAA9MIKluZVY8uUlR\nqmSEgwI5OvoGeebDctbkJjokv8PT8Q8FkDgT0lZB0fMwcmW6/9KMOEKDAhwaDvr7Q1WEBAXwhSXJ\nV2xfnDqZ4uo2pyaEnTL0ANAOYPv4xlrVNOYnJk1jntt3jskRwdy60PlOwZCgAO5fnsZHp5spP99F\nd/8Qu0uauGHeNI+rJ2NKQXYCHX1DnKxvt/qc8519/PlwHXcsSSYhKtTq81RIaAYn6zsodFBdr//d\ne5a2nkH+8fqZDrmep+O5d5Kjyd8CrZVwds8Vm8OCA1maEWcx+9JaegaGeO1wHTfOm3ZVka7FabF0\nDwxfCtN0BqWNHQgBM3UJCLuIiQjmr9dm8X7JeQorW6hp6eH9kibuWZrqsuzqe5alEhIYwIsHKnm/\npIm+wRGPNf8YWZk1cT/AC/srGRwe4a9sKJXy+UXTiQkPvmKlZCvNnf389pNz3Dh/GnNn+EcSpf8o\ngNk3Q0Q8FG69atfa3ETKz3dR39Zr9zA7jzbQ2T9kNnHE6Ah2phmopKGDjPhIh8en+yNbCtJJiArl\nx++U8eKBSoQQfMkJoZ9jkRAVys0LpvNqUS1/+LSaaTFhHllPxpTE6FBmTY22Oh+gu3+Ilw5UcX3e\nVDKs7KVsSkRIEHdfk8I7Jxvt/v99Zk85/UMj/MPGXLuu4034jwIICoVFX4Kyt6HjSqfR6hzHhYNu\nO1RFblKU2X/U1LgIpyeEqQggPft3BBEhQXxrQzafVrbw/P5KNs2ZyvRY1/ZzfXBlOj0Dwxw828JN\n86cR4AUhiauyE/isstWq6JyXP6uho2+Ir6+1vVDi/SvSkFLyu4O2h4TWtPSw7VAVd+ankJkYZfN1\nvA3/UQAASx4EOQxHXrpic25SFEmTQu0uD328tp2jte3ctyzNrJNQCOHUhLDu/iGqLvYwWzeBcRh3\nXZNKalwEg8PS9tDPsx/Czu/YdOq85JhLkwlPN/8YKchJYGBohMLK8e/zweERfvvxWZamx7Eo1faV\nTfLkCK7Lm8ofPrU9JPRn758mQAi+tSHHZjm8Ef9SAHGZkHmtcgYPXw77FEKwOieRT8onHr1gyu8/\nrSIsOGDczEFnJoSVNuoMYEcTEhTAD2+fx9fXZtpuftn3X1D4W+ixLdLs/904m79ancE8L7FLL02P\nIyhAsK9i/AnVm8caqG/vs2v2b+TBgnRaewb5S7F1/RRMKWvs5PUjdTy4Mt1tvZXdhX8pAID8r0BH\nHZS/d8XmNbmJtPcOcqzWNvNMZ98gfymu55YF0y8VfzOHMxPCLjeB0SYgR7IyO4HHNs+2LfSztw3O\n7VXvW8/ZNP7i1Ml878Y8r4lJjwwNYnHq5HH9AFJKfv1RBTlTorh2pv1F7ZZlxDFrajTP7auccEjo\n07vKiAoN4hvrLFeB9TX8TwHM3AxRU6HwuSs2r8pWza1tjQZ6o7ienoFh7ls2vpPQmQlhJQ0dRIcG\nMcPFdmrNOJS/DyOG1WaLbQrAGynITuB4XTttPeZXuh+fuUBpYyd/tSbTIX4NYz+F0sbOCeX0FFW1\n8n5JE19fk0lshHtba7oD/1MAgcGw+Mtw5l1ou9xaLi4yhHkzYmzKB5BSsu1gFXNnTGK+hRr8zkwI\nK21QDmBvmSn6BaU7VfQZQMtZ98riQlblxCPl2OWhf7O3gqRJody60HF+jVsXzmByhPUhoVJKfvRO\nKQlRoT5Z698a/E8BgFIAQkDRC1dsXpOTyJGaNjr6LNeDN+VITRuljZ3cu9S88/eq4Z2QECalpLTR\ndQ1nNFYw1A9n3oNZN8GkGX6lAOYnxxIVGmQ2H+BEXTv7yi+ypSDDoTWNwoIDuWdpKu+eaqSmxXJB\nuo9ON/PpuRa+uSGbyFDPKa3tSvxTAcSmQM51Khpo+PLDfnVOAsMjkv3lE2tqse1gNVGhQdxi5WzG\nGQlhta29dPUPMUtHAHkO5/bCQJdSAHGZfqUAggMDWJ5pvk3kb/aeJSo0yClNVr60XE3CLIWEjoxI\nnt5VRkpcOHdf45vNXqzBP8ZFmBsAACAASURBVBUAKGdwVxOUvXVp0+K0yUSGBE6oOmhbzwA7j9Xz\n+UXTibJyFuGMhLCSBu0A9jhKdkBIFGSuhbgMv1IAoLKCKy/2UNt6eTZe09LDm8fquXdZqlP6GU+P\nDWfTHBUSOl6BxzePN3CyvoPvbMwlJMh/H4P++8mzPwcxKVdkBgcHBrAiK4G9p5utjiT48+E6+odG\nuHep9RmiqXERxDk4IaykoRMhIFeXgPAMRobV5CJno0pCjMuE7mbod14ZEE9jVY4qC2G6ov7tJ+cI\nDFAOW2fxYEE6HX1DvHGk3uz+QUOzl1lTo7llge82e7EG/1UAAYGw+AGVpHPxcgvAtbkJ1Lb2WtXU\nQkrJ7w9VsSg1lrzp1ptehBAsdnBCWGljB2lxEX5ry/Q4agvVA3/WTer3OEOsux9FAuVMiSIxOvSS\nH6C1e4A/flbDrQtnMC3GeZFq+WmTmTN9Es/vN18l9E+FNVRe7LG+2Utvq5oodp13grTuxX8VAMDi\n+0EEqsQwAxMpC3HoXAsVzd0WQz/N4eiEMO0A9jBKd0JAsFoBgIkC8B8zkBCq7/a+8guMjEheOlhF\n7+AwD62xP/HL0rhbCjI43aR6cpvSOzDML3afYUnaZDbMtjL/4L3HYeffw8/mwOvfgIajTpDaPfi3\nAoieCrNuhCO/UxEbqI5QqXERVoWDbjtUzaSwIG6aP3b/0rEw+gGO1Ni/CugZGKLyYrd2AI/F8JBr\nTS9SKgWQsRrCDGHBkw1hhn6kAEDlA1zsHuBobRsv7K9k/awpLjFT3jR/GvGRIVc1jn/hQCVNHf38\n0yYrm71cOKOeD/PvUqVkTv0FfrMGnrsBTm1Xpj4vxr8VAKgy0b0t6o9pYHVOAgcqLjIwNDLmaRe6\n+nnnRANfWJJsU3lgY0LYkWr7/QBljZ1IqR3AY7L3x/DfS2DAtl61E6a5TD3oZ914eVtoFEQl+aEC\nUDkQj712nIvdA06f/RsJCw7k3mWp7C5tutTas713kP/5sIJ1MxNZam1Htw/+HYIj4Lon4Yan4Tun\n1Pu2GvjT/fCLhbD/v1XGtxeiFUDGOjU7M3EGr8lNpHtgeNwonVeLahkclpd6/k4URyaElTSo2a02\nAY3B2Q9VxNepN1wzXulO9Trzxiu3x2X6lQ8AYFpMOJmJkZQ2drIgJdbprTRNuW9ZGoFC8OKBSgCe\n3VtBe+8gj1jb7KXusLpnVvwtRCnTMOGxsPJh+OYRuPMlFUjy7j/DT/Pgze/ChXKnfBZnYZUCEEJs\nEkKUCSHKhRCPmtmfJoTYLYQ4JoT4UAiRbLLvR0KIE4afu0y2ZwghDhmu+UchhHvysAMC1Cqgej+c\nLwVgRVY8gQFiTD/AyIjk94eqWZYRR/YU22fdjkoIK23sIEqXgDDP8OBlm62ZXhBOoXQnzMiHSaNM\ng36WC2DE2Cz+62syXZqlPjUmjM3zpvHHwhoqL3Sz9ZNKblkwnTnTrSyqt/sJCI+DFQ9fvS8wCPJu\ngS1vwdf3Qt6tcPgF+OUS2PZFKN+tTIEejkUFIIQIBJ4BNgN5wD1CiLxRh/0EeFFKOR94AnjKcO6N\nwGJgIbAM+K4QwjhN/RHwMyllNtAKfNX+j2MjC++DwBAoUvWBJoUFszg1dszy0J+UX6C6pcfuRBZH\nJYSVNnQya2q0V9SKdzlNJ2CoD1KWQe1n0HjcueO110L9kSvNP0biMqCz3nWmKA/hyyvS+ca6LK6f\nM9XlY28pSKezb4j7/u8Qg8MjfMfaZi9nP1LdA9d8F8IsrKynLYDb/gf+/iSse0z9/X93O/xquao5\n5sF/b2tWAEuBcinlWSnlAPAycOuoY/KADwzv95jszwP2SimHpJTdwDFgk1DTgPXAq4bjXgA+b/vH\nsJPIBJh9CxT/4dIfa01OIifq27nY1X/V4b8/VE1cZAib5tp3QzsiIUxKSUljh24CMxa1her1hqch\nKOyqIoAOp+xt9WoM/zTFGAnUWulcGTyM7ClR/NOmWdaFXJqjqxkOv3hVP29rWJQSy4LkGOraernr\nmhTSrek6JiXs/jeYlAz5E5iXRk2BdY8qRfD5X6tJ5c5vw8/y4MMfeuSKwBoFMAOoMfm91rDNlKPA\n7Yb3twHRQoh4w/ZNQogIIUQCcC2QAsQDbVLKoXGuCYAQ4iEhRKEQorC52XGN268i/yvQ3w4nXwNg\ndW4iUl7d27Spo4/3Spr4Yn6y3XVMHJEQVtfWS2ffkLb/j0VdEUROganzYc7tcOyPzo0IKt0J8TmQ\naGam6YehoA7h4K9g+9+pngoTRAjBw+tzmBEbzjetbfZSulPdN+sehWAb+gMEhcLCe5RpaMvbkHwN\nfPgUVO2b+LWcjKOcwN8F1gohjgBrgTpgWEr5LvAWsB/4A3AAmFDclJTyWSllvpQyPzEx0UHimiFt\nJSTMvDRDnDcjhtiI4KvMQH/8rIbhEcm9S+2vH+KIhDCjA1iHgI5BbSEk56vif/lfUbV5jr9q+Txb\n6G2Fyk/Mm3/Ab0NB7aZit3p99/sqLHOCbMxLYt+j60maZMXDfGQYdv8AEnJhwT0THusKhFDPlTu2\nqtWAcXXoQVijAOpQs3YjyYZtl5BS1kspb5dSLgK+Z9jWZnh9Ukq5UEq5ERDAaeAiECuECBrrmi7H\n+ICoK4SGowQGCAqyE/j4zOWyEMMjkpc/rWZ1TgJp8RNvYG0OexPCSg01gGZO1Sagq+hthYtnYMYS\n9XtyPiTNVc5gZyzHz7ynav/Pvtn8/vBYVRpaKwDr6b6gnPj5X1Uz69e/fkU3P4dz9GW4UAbr/1k5\neh1BaDSkr4LTuxxzPQdijQL4DMgxRO2EAHcD200PEEIkCCGM13oM2GrYHmgwBSGEmA/MB96V6om6\nB7jDcM4DwF/s/TB2s+CuK+zEa3MSOd/ZT5nBSfth2Xnq2/tsDv00h70JYaWNnaTFR1hdiM6vqCtS\nr8n56lUIFfHVeAzqDzt+vJIdqtnQ9MVjH+OnkUA2U7FHvS66D276qfqbfvIz54w11K9MNdMXKZ+g\nI8ndrCYjJmVnPAGLCsBgp38Y2AWUAH+SUp4UQjwhhDB+S+uAMiHEaSAJeNKwPRj4WAhxCngW+JKJ\n3f+fgO8IIcpRPoGJG/gcTfhkmPsFOP4K9HeyOleFr31sMANtO1TNlOhQNsxOctiQ9iaElTR0MEvP\n/s1TWwSIKx/I8+6E4EjHh4QO9qrQv1k3qNDisfDDXAC7qPhA/V9OW6j+N+d+AT76IdQXO36swq3Q\nXgOf+1c1WXAkuderVw8zA1nlA5BSviWlzJVSZkkpnzRse1xKud3w/lUpZY7hmK9JKfsN2/uklHmG\nn+VSymKTa56VUi6VUmZLKb9oPMftXLITv8K0mHBypkSx90wzta097Ck7z13XpBAc6Lj8OXsSwnoH\nhjl3sVs7gMeirhASZ14Zxhc2CebdAcf/7NjszbMfwWD32PZ/I3GZ6iEz5Bm3u0cjpVIAmdeq4o0A\nN/wEIhOVKWiwz3Fj9XfC3qchYy1krnPcdY1MToMpeXD6Hcdf2w50JvBoZiyBpHnwmbITr85J5NC5\nFl7YX4kA7naA83c0tiaElTWpEhDaAWwGKZUDeEb+1fvyt8BQr4oIchSlOyF0EqSvGf+4uExAQuv4\nDUs0wPlT0NUIWesvb4uIg1t/Cc2l8MEPHDfWgWeg5yJ87l8cd83R5G6C6gMeVTZCK4DRGO3ETceh\nrog1uQkMDI2wdV8l186c4pRsW1sTwkp1E5ixaT2najwlL7l63/RFyixU+JxjnMEjw2ppn3MdBFlI\naNehoNZTboj+MVUAoHp55H9VPbTPfWz/ON0XYP8vld1/hpn7xVHkblJBAuXvO2+MCaIVgDnm36k6\nORU+x7KMeEKCAhgekdy33Dmt4xal2JYQVtrYSWRIICmTI5whlndTa3AAm1sBgDL1NZdA9UH7x6r5\nFHouWDb/gFYAE6HiA0icBTFmUoSu+4HKrH7jb6Cvw75xPv6pMt+t/2f7rmOJ5HwVBeZB0UBaAZgj\nNBrmfRFO/Jnw4Q5WZMaTPDmctblW1g+fIGnxtiWEnWroYKYuAWGeukJVxXHK6KolBuberkw2jnAG\nl+5Ucd7Zn7N8bPhkVSJaK4DxGeiBqv2QtcH8/pBIuO030FEL7zxm+zhtNfDZ/8LCe5W/yJkEBELO\n9XDmXeeGsk4ArQDGwmgnPvpHfnrnAl756xW2p7JbwJaEMCklpQ0d2gE8FrWFytQzVix3SCQsuFvV\nd+++aP4Ya7hU+3+t5ZoxoEyMOhTUMtX7Ybj/avOPKSlLYdXfQ/HvoPRN28b56IeAgLVX1bh0DrnX\nQ18b1BxyzXgW0ApgLKYtUPbAoueIjwxxags7mHhCWH17Hx19Q8yyRgEUboXt37RTQi9iqF/F+luy\n5y7Zoh4yR39v+1jnT6naPtaYf4xoBWCZ8g8gMFRl0o7H2kdh6jx1f3dNsFRMcxkU/x6u+RrEplg+\n3hFkrVed4jwkGkgrgPHI/4qKNqg+4PShJpoQdskBbE0OQNELqphWt/nqpj5H43EYHricADYWSXmQ\nukI5g20oNAYYZp4CZt5g/TlxmdBWrUpVa8xT8QGkrYAQC/6toBC47Vno74Ad35qYU/+DH6ickNXf\nsU/WiRA2yZAVrBWA5zPndgiNcUkd+YkmhJU2qoghiyUg+rsMJZClaoziDxgrgI7lADZlyRZoqYDK\nvbaNVbpTmSKiJ5AcGJcJclgpAc3VtNcpB/1Y9v/RJOXB+u9D2Ztw9A/WnVNXpDK3V/6dqgbsSnI3\nwYXTHpEVrBXAeIREOMZObAUTTQg71dBBSlw40WHB4x9Yf1g9bEDNqvyBukKInmY+emQ0ebcqx6wt\nZaLbalSdmomYf8AkEkhnBJvlrKH8w3j2/9Gs+FtIK4C3/tE6xfr+v0FEAqz4G9tktIeZm9SrB0QD\n6QIylsjfAp/+Bvb9DGaNUeTLGuIyVL3wcVicOpnXDtcyPCItOpxLGzqYbU0CWLXB2ZS1XikAKR2f\n5u5p1BZaH88dHKYaAh36NXQ2TWwmX/aWejVX+388dCjo+JTvVv2Tk+ZYf05AIHz+V/A/BSo09Mvb\nxy7JUbEHzn0Em36oIv5czeR0SJwNp992jwIyQSsAS0yZDWmrVOPn/f9tx3Xy4G/G9yUsSo3lpYNV\nnG7qHDe6p29wmHMXurlx/nTL49YcVDfbnNuh4mE4X6KWzL5K90WVBLbkAevPWbIFDvwSjrykOkBZ\nS8kOFacenzUxGSMTVZ6JVgBXMzKsVgC5myY+UZmcDpueUr0DDv3a/MPV2OwlJkX5+NxF7vXqnutr\nV2HBbkIrAGu484XLfWVtoewt+Oz/oLMRosfuImbaIWw8BXC6qZMRaYUDeGQEaj6DubddXk5X7PZt\nBVBnIQHMHAnZkLFGOctX/f3lujPj0dOi4tRXfXviMgqhVoRaAVxNQ7Eq422t/X80i+6H0rfg/X9V\n9/yUWVfuL9muWjbe+itVXtpdzNwM+36uVjtzb7d8vJPQCsAaIhMg28YbEiAsVimAqn2qmuEYmCaE\n3bcsbczjSg1NYCzmADSXqC5nKcuVPTxxljIDrfw7mz6GV1BXCCJA5QBMhPyvwCsPqu8nZ6Pl40/v\nUr6Vidr/jcRlQtMp2871ZYx+qsx1tp0vBNzyC9WP9/WH4Gu7IdDgJxsegg/+Xf0fLLjbEdLaTvI1\nquH86XfcqgC0E9gVTFuglvyV47eEszYh7FRDBxEhgaTGWQiRMyabpC5Tr1nr1ax1sNdayb2P2kJl\nbguNmth5M29UrSOtjfgq3QnR08ev/T8ecZkqf2BkQg3yfJ/yD9T/S5Qd3f+ipsBNP1Or9r1PX95+\n9A8q+mb9961b5TmTgEBVO8rNWcFaAbiCwCBIWWZVT1BrEsJKG60sAVF9SNmbja0IszbAUJ9SAr7I\nyIhaAdhS0CsoBBZ9Sc3I2mvHP3agx1D7/0bbHepxmTAyaHksf6KvA2o/td38Y0rerTD/btj7E1UX\narBPNXuZkW/7qs3RzNykzF21n7lNBK0AXEV6gUoqs5CMZSkhTEpJSUOndSWgaw4qxWN8SKWtVNmV\nvhoO2lKhnGqWEsDGYskDykl4+KXxjzv7oSoTYs+DREcCXU3lx6pa5kTCP8dj849UOPDrD8GB/4aO\nOlXu2VOi4LI2QECQigZyE1oBuIq0VerVwirAmBA2VmG4xo4+2nsHLZeA7mxSJobU5Ze3hUSo7Epj\nmV1fYyIJYOaYnK4Kuh1+YfxleembKkEwfZVt44BWAOao+EBl5qYsc8z1wmPh88/AxXJl+89ar5z9\nnkLYJJW7UOa+rGCtAFzF9EUQFG7RD2BMCBtrBVByqQeAhRWA0f6fsvzK7VnrlXO4o94qsb2KukLl\na7GnqmP+FuhsGDtVf3hIRXXlXn/ZuWgLUVPV/aAVwGXKd0PGass9FSZC5jpY9g0QgbDhccdd11HM\n3Kya0LvpPtAKwFUEhaiSAVb4AcbrEFbSYGUJiJpDytwzbf6V2432VV80AxkrgNrj4Mu5Xjl3x3IG\n1xxUjWbstSMHBBhCQXU2MKAegK3nHGP/H82mp+DbxyceGeYKjL2C3ZQVrBWAK0lfBU0nVQz5OCxK\nHbtDWGljJ8mTw5lkqQRE9UGYsfjqWOekOSrL0tcUwGAvNJ2w3f5vJDBI+QIqPjD/cC59UylWa2r/\nW0JXBb2M8X50lP3fFCGsKwviDuIyIWGm25rFawXgStIKAGmxuqhpQthoSho6LDuAB3tVCJw5W6oQ\nhrIQe3wrBLHhmHIg2mr/N2Xxl1UuweEXrtxurP2fde3Ew0zNEZehZr22ViL1JSr2QGzqxLOqfYGZ\nm5RlwN7OZjagFYArmbFEzR4t+AHG6hDWNzjM2eYuyw7gusMqxDB1ufn9WeuVGcOe7GZPo87gALZ3\nBQAwaboqRXD4JRgyCcdtOqEKjTkqjDAuU4XldjY45nreyvAgnP1I3ZeeEqHjSnI3q8lLheuDM7QC\ncCXBYSoDsOqTcQ8bKyHsTFOXKgFhrQM4ean5/ZnXqlc33HBOo7ZQ1XcZp9TGhMj/iurzW7rj8jZj\n7f/czY4ZQ0cCKWo/g4FO59j/vYHka1RFWjdEA2kF4GrSC1R9/r72cQ8zlxBW0qiWiLOscQDH50Bk\nvPn9UYkwdb5advsKE6kAag1Z65VJwrRMdMlOtaqyJ0vVFK0AFBUfqCgdTwrRdCWBQZezgl1sltUK\nwNWkFYAcUU7acTCXEFba0El4cCBp8ZFjnzgyohRAqoVY6uwN6jg32B0dTtd5aK92jPnHSEAALHlQ\nJSc1n1Y5FU3HHZtFOmmGaibv7wqgfLf624XHulsS95G7SZllXZwVrBWAq0m+RvUErRzfDGQuIayk\noYPcqdHj9wq4eEall4+O/x9N1gZld7Qgh1dgbwLYWCy6X2VqFj2vKkyCYxVAQKBKPvNnBdDToqpz\nOiP6x5vINmQFuzgaSCsAVxMSoUwVFvIBRieESSkpbeywXALauLIYywFsJGWZyrr0BT9AXaEyIUxb\n4NjrRk2B2TdD8TY48WeYMuey2cZRxGX6dy7A2T2A9F/7v5GwGFWqxcX5AFoBuIP0Aqgvhv6r4/xN\nWZQaeykhrKmjn9aeQSscwJ+qMrPx2eMfFxSisi59IR+gtlDlN1hqIG4L+V+BvjalZJxRRMyYCzCR\nZua+RMUH6uHniUlariZ3s8rSb6102ZBaAbiDtAJVS77m03EPW5w6+VJCmPUO4FEF4MYja716+Hjz\nDHRkRJkQHGn/NyV99WVl6iwFMNit/Bj+hpSq/HPmOuUI9XeMWcEujAbSCsAdpCxTJgsLZiDThDBj\nE5hZ460Aui+owleWHMBGLpWF8GIz0IXT0N/hePu/ESFg3WOq76+jTUygksHAP/0AzWXQWa/t/0bi\nsyAhd+w6VE5AKwB3EBqllrwTSAgraehgRmw4MeHjlIAYqwDcWMRnQUyqd4eDXkoAu8Z5Y8y7A+7e\n5pwkJX8OBTVOPLQCuEzuJhWY4aLoPK0A3EV6gepfO9Az5iGmCWGljR2WzT/VB1WEkbX2VCEge73K\nwhwenIDwHkTtZ6o0syWfh6cSk6qiP/xSAXyg8lViU90tieeQu0ll8bvIN6cVgLtIW6X+0Bbifo0J\nYeXnu6xzAE9fqDKOrSVrvcrCNIZSehu1RaroXYCX3sqBQeoB6G8KYLBPrYDt6bXti6QsUz3EXRQN\n5KX/NT5A6nJVcMxKP8CIhFnj1QAa6lfO0Ik208hYq+TwRj/AQDecP+k8B7Cr8MeqoNUHVFc1bf65\nkktZwbtckhWsFYC7CJukyjFY8AMYE8LAQg2g+mIY7rcc/z+a8FjlQPXGcND6YpVV7SwHsKsw5gL4\nUyhoxW6VBW1PVzVfJfd66LnoklW5VgDuJH2VMgEN9o15iDEhLDQogPTxSkDUGBLAbGmnl71BVRC1\n0KfA43BkBVB3EpcJ/e3e9/3bQ8UeNVkJGeee9leyP+eyXsFaAbiTtAI1a68rGvew+5alcf/ytPFL\nQFQfUg+SqCkTlyNrPSBVs3NvorYQYtMgMsHdktiHv0UCdTaq0tra/GOe8FhIXeESP4BWAO4kbQUg\nLPoB7l2Wyj/flDf2AVKqEFBbm2lPX6yyMb3ND1BX5P2zf/A/BWAMO/b38g/jkbsJzp+C1iqnDmOV\nAhBCbBJClAkhyoUQj5rZnyaE2C2EOCaE+FAIkWyy78dCiJNCiBIhxC+EUMHUQoh7hBDHDee8I4Tw\n8mmcDYRPhqS59hdkazmratfbqgACg5QzuGKP99ihOxqgo8777f+gooBEgB8pgN0QmajufY15Zhp6\nTjg5KcyiAhBCBALPAJuBPOAeIcTo6ehPgBellPOBJ4CnDOeuBAqA+cBc4BpgrRAiCPgv4FrDOceA\nhx3yibyN9AIVvmnaeWqiWFsAbjyyN6gHanOZ7ddwJa5IAHMVQaEwKdk/FMDIiJpoZK333tBdVxCf\npXIk3K0AgKVAuZTyrJRyAHgZuHXUMXmAMYxkj8l+CYQBIUAoEAw0AcLwE2lYEUwC6u34HN5LWoEK\nh6s/Yvs1ag4qE07CTNuvYbTHeks0UO1nKult6jx3S+IY4jL8QwE0HlOrVW3/t0zu9co6YKFopD1Y\nowBmADUmv9catplyFLjd8P42IFoIES+lPIBSCA2Gn11SyhIp5SDwDeA46sGfB/zW3OBCiIeEEIVC\niMLm5mYrP5YXkVagXi20iRyXaoP9354ZVWyqmnF4ix+gtkg9/CeS9ObJ+EsugHGCYWxLqhmbmZth\neMCpkzJHrcG+izLtHAHWAnXAsBAiG5gNJKOUxnohxGohRDBKASwCpqNMQI+Zu7CU8lkpZb6UMj8x\n0UGt+DyJyHhInG0xH2BMelrgQhmkjNH/dyJkrVdyjBOW6hGMDDu3Aqg7iMtUHaF6Wy0f681UfABJ\n8yA6yd2SeD4py9XK3onRQNYogDogxeT3ZMO2S0gp66WUt0spFwHfM2xrQ60GDkopu6SUXcDbwApg\noeGYCimlBP4ErLT3w3gt6QUqimd4aOLnGktJWFsAbjyyNyhzVPUB+6/lTM6XqBLKvuAANnIpEsiL\nS3Nbor9L+auytfnHKgKDIHujUgBOygq2RgF8BuQIITKEECHA3cB20wOEEAlCCOO1HgO2Gt5XY3D6\nGmb9a4ESlALJE0IYp/QbDdv9k7QCGOiChqMTP7f6oEoacURD9LQCZVf3dDOQrySAmeIPoaCVn6j6\nV9r+bz0zNyufiYVcIVuxqACklEOoCJ1dqIf0n6SUJ4UQTwghbjEctg4oE0KcBpKAJw3bXwUqULb+\no8BRKeUOKWU98G/AXiHEMdSK4D8c97G8DHv8ADWHVEkJR3TDCo1SkUSeXh66tlCF0Dq6PaM7mZyu\nXn15BVDxAQSFqyQnjXVkb1C9Q5wUDWRVGx4p5VvAW6O2PW7y/lXUw370ecPA18e45q+BX09EWJ8l\nOkk5YCv3QcG3rD9veFDNDJZscZws2Rvg/X9V2ZrRUx13XUdSV6RWPM6oz+8uQiIgerpvrwAqdqvy\nJ0Gh7pbEewifrBRm2Tuw4XHLx08QHYjrKaQXKNv7RGx9DcdgqM/6DmDWcCkc1ENXAf2dygfgS/Z/\nI74cCdRapbrV6fLPE2fmJlX1tq3a4ZfWCsBTSFulWhs2Hrf+nEsF4BzgADaSNE9laXqqH6DuMCB9\nIwFsNL6cC2AMZdT2/4kz6ya49p8hyPEhz1oBeArpRj/ABMJBqw+q+P1J0xwnR0CAitGu2KOyNj0N\nowN4xmL3yuEM4jKh+7xTE3/cRsVule2ckOtuSbyPuAxY+4hthR4toBWApzBpOkzOsD4f4FIBOAfO\n/o1kb1CRB43HHH9te6ktgrgsiIhztySOx1dDQYeH4OxeyLrWt/w2PoBWAJ5EegFU77du5t1WBV1N\njkkAG40xS9PTykJIqVYAvhT+aYqvhoLWFal+B9r+73FoBeBJpK1SmaDnT1k+tvqQerWnANxYRCcp\nX4CnKYD2WqX0fNEBDGqpD76nAEq2q1yVjLXulkQzCq0APIk0QzK0NX6AmoMQOgmmjNMnwB6yrlU+\nhv4u51zfFi4lgDkg6c0TCY2GyCm+pQAG+6B4G8y60TfNdl6OVgCexOQ0iEmxrj9A9SFlCgkIdI4s\n2RtU1qa9vQocSW0hBIaq1YmvYuwP7CuUbFer2vyvuFsSjRm0AvA00gqgav/4jVl625SZyBkOYCMp\ny1XWpieFg9YVwbT5EBTibkmch6/lAhRuVU779DXulkRjBq0API30AhWBM15jlrpCQDrHAWwkOExl\nbXqKH2B4EOqLfdf+byQuEzrrYaDH3ZLYT9Mpldy45EHd/MVD0X8VT8OaukDVh1QLQWdHw2StV9mb\nTu5LahVNJ1WlUl+NADJidAS3VrpVDIdQ9BwEhsDC+9wtiWYMtALwNOIyIXra+PkANQdVP9XQaOfK\nYgzb84RVgC9WADWHLI2hNwAAC/pJREFUr4SCDnTD0T9C3udVzwuNR6IVgKchhMEPsM+8H2B4SCVD\nOSP8czQJuTBphmf4AWqLICIBYtPcLYlz8ZVQ0BOvqdj/fAcWKtQ4HK0APJH0AhXvfrHi6n1Nx1Uz\nlBQHFoAbCyGUGejsXtua1TgSYwKYr2eShk+G8DjvVwCFWyFxli797OFoBeCJpK1Sr+b8ADWfqldX\nKABQCqC/3WkNKayitw0unPZ9B7ARb48Eqi+G+sMq9NPXFbaXoxWAJ5KQoxKCzPkBqg8qs0xsytX7\nnEHmOkC41w9Qf1i9+moC2Gi8PReg6DkVQjz/LndLorGAVQ1hNC5GCJUVbPQDmM6iag65bvYPKntz\nxmL47H8nVqnUkXQ2qNfpPlgB1BxxmXD8FRjq977mKX0dcOwVmPsFCI91tzQaC+gVgKeSvgo66q4M\nB2yrUdtc4QA2peBbkDBTNatxx0/kFFj+N/7zQInLBKRnhN9OlON/Uj4qnfnrFegVgKeSZtIfwBgZ\nUmMoAOfMBDBz5N2qfjSuwTQUNNGL6udLCYXPqR7VvtivwQfRKwBPJXGWigYx9QPUHILgSN+uhaPx\n3lyA2kJoOqGdv16EVgCeSkCAwQ9gEglUfVA5QgP1ws2niYiD0BjvUwCFWyEkCubd4W5JNFaiFYAn\nk75KNYJuq1FtAptOOLcAnMYzEML7+gP3tMDJ12D+nc7PUNc4DD2V9GRM/QBRSSBHXBsBpHEfcZlQ\nf8TdUljP0ZdhqE87f70MvQLwZJLmQFiMqslfcwgQkHKNu6XSuIK4TLX6Gx50tySWkVLF/s/Ih6na\nP+VNaAXgyQQEQqohH6DmkOr+FRbjbqk0riAuE+SwUgKeTtU+lamtZ/9eh1YAnk56gbIFV+2HVG3+\n8RsuRQJ5QUZw4VY1MZlzm7sl0UwQrQA8HaMfYKhPO4D9CW8JBe1qhlPbYcG9EBLhbmk0E0QrAE9n\n6nwIMURVuDoBTOM+oqaonA9PVwDF21TvaF322SvRCsDTCQxSZqDo6TA53d3SaFyFEJ5fFXRkRDl/\n0wogcaa7pdHYgA4D9QZu/E/oa9fZlf5GXAacL3G3FGNzdo+qVbX+++6WRGMjegXgDcQkq5BQjX8R\nl6kesCPD7pbEPIVbISIeZt/sbkk0NqIVgEbjqcRlKvt6e627JbmajgYoe1s1fPe2ktWaS2gFoNF4\nKp4cCXTkJZWnsORBd0uisQOtADQaT8VTFcDwEBQ9D5nXQnyWu6XR2IFWABqNpxI9DYLCPE8BlL+n\nGhPpzF+vRysAjcZTCQiAyRmelw1c+JwqTjhzs7sl0diJVgAajSfjabkAbdVw5l1Y/GUIDHa3NBo7\nsUoBCCE2CSHKhBDlQohHzexPE0LsFkIcE0J8KIRINtn3YyHESSFEiRDiF0KoYHYhRIgQ4lkhxGkh\nRKkQ4guO+1gajY8QlwGt51TSlSdQ9ILKR1n8gLsl0TgAiwpACBEIPANsBvKAe4QQeaMO+wnwopRy\nPvAE8JTh3JVAATAfmAtcA6w1nPM94LyUMtdw3Y/s/jQaja8Rl6nqQHU2uFsSVZr6yEuQvRFiU9wt\njcYBWLMCWAqUSynPSikHgJeB0R3C84APDO/3mOyXQBgQAoQCwUCTYd9XMCgKKeWIlPKCrR9Co/FZ\nPCkSqOwt6GrSzl8fwhoFMAOoMfm91rDNlKPA7Yb3twHRQoh4KeUBlEJoMPzsklKWCCFiDcf+QAhx\nWAjxihAiydzgQoiHhBCFQojC5uZmKz+WRuMjGBVAqwc4ggu3wqRkyNnobkk0DsJRTuDvAmuFEEdQ\nJp46YFgIkQ3MBpJRSmO9EGI1qgZRMrBfSrkYOIAyI12FlPJZKWW+lDI/MTHRQeJqNF5CTDIEBLt/\nBXCxAs5+qBK/AgLdK4vGYVijAOoAU4NfsmHbJaSU9VLK26WUi1C2faSUbajVwEEpZZeUsgt4G1gB\nXAR6gNcMl3gFWGzPB9FofJKAQFUF1t0KoOg5EIGw6EvulUPjUKxRAJ8BOUKIDCFECHA3sN30ACFE\nghDCeK3HgK2G99WolUGQECIYtTookVJKYAewznDcBuCUXZ9Eo/FV3B0KOtQPR7bBrBtg0jT3yaFx\nOBbLQUsph4QQDwO7gEBgq5TypBDiCaBQSrkd9SB/Sgghgb3A3xpOfxVYDxxHOYTfkVLuMOz7J+Al\nIcTPgWZAd5TQaMwRlwnl78MzbmoJOtQHvS3a+euDCDUZ9w7y8/NlYWGhu8XQaFxLw1H45Oeq+Jq7\nmJQM1/27yk7WeB1CiCIpZf7o7bohjEbj6UxbAF98zt1SaHwQrc41Go3GT9EKQKPRaPwUrQA0Go3G\nT9EKQKPRaPwUrQA0Go3GT9EKQKPRaPwUrQA0Go3GT9EKQKPRaPwUr8oEFkI0A1XulmMMEgBP7mmg\n5bMPLZ99aPnsw1750qSUV5VT9ioF4MkIIQrNpVp7Clo++9Dy2YeWzz6cJZ82AWk0Go2fohWARqPR\n+ClaATiOZ90tgAW0fPah5bMPLZ99OEU+7QPQaDQaP0WvADQajcZP0QpAo9Fo/BStACaAECJFCLFH\nCHFKCHFSCPEtM8esE0K0CyGKDT+Pu1jGSiHEccPYV7VPE4pfCCHKhRDHhBCLXSjbTJPvpVgI0SGE\n+PaoY1z6/QkhtgohzgshTphsixNCvCeEOGN4nTzGuQ8YjjkjhHjAhfI9LYQoNfz9XhdCxI5x7rj3\nghPl+1chRJ3J3/CGMc7dJIQoM9yLj7pQvj+ayFYphCge41xXfH9mnykuuwellPrHyh9gGrDY8D4a\nOA3kjTpmHbDTjTJWAgnj7L8BeBsQwHLgkJvkDAQaUQkqbvv+gDXAYuCEybYfA48a3j8K/MjMeXHA\nWcPrZMP7yS6S7zogyPD+R+bks+ZecKJ8/wp814q/fwWQCYQAR0f/LzlLvlH7/xN43I3fn9lniqvu\nQb0CmABSygYp5WHD+06gBJjhXqkmzK3Ai1JxEIgVQkxzgxwbgAoppVszu6WUe4GWUZtvBV4wvH8B\n+LyZU68H3pNStkgpW4H3gE2ukE9K+a6Ucsjw60Eg2dHjWssY3581LAXKpZRnpZQDwMuo792hjCef\nEEIAdwJ/cPS41jLOM8Ul96BWADYihEgHFgGHzOxeIYQ4KoR4Wwgxx6WCgQTeFUIUCSEeMrN/BlBj\n8nst7lFidzP2P547vz+AJCllg+F9I5Bk5hhP+R6/glrRmcPSveBMHjaYqLaOYb7whO9vNdAkpTwz\nxn6Xfn+jnikuuQe1ArABIUQU8Gfg21LKjlG7D6PMGguA/wbecLF4q6SUi4HNwN8KIda4eHyLCCFC\ngFuAV8zsdvf3dwVSrbU9MlZaCPE9YAjYNsYh7roX/gfIAhYCDSgziydyD+PP/l32/Y33THHmPagV\nwAQRQgSj/lDbpJSvjd4vpeyQUnYZ3r8FBAshElwln5SyzvB6HngdtdQ2pQ5IMfk92bDNlWwGDksp\nm0bvcPf3Z6DJaBYzvJ43c4xbv0chxIPATcB9hgfEVVhxLzgFKWWTlHJYSjkC/O8Y47r7+wsCbgf+\nONYxrvr+xnimuOQe1ApgAhhshr8FSqSUPx3jmKmG4xBCLEV9xxddJF+kECLa+B7lLDwx6rDtwJcN\n0UDLgXaTpaarGHPm5c7vz4TtgDGi4gHgL2aO2QVcJ/5/O3fIEkEQBXD8P9kgatKm4De4JEYRuSDY\nrGq5YLb4OQSDQfA7mLQLFj0RBM8m+A0shjXMO1jEPSw3B87/BxN2bpZ9DI957OxwKS3EFsd29E1d\nSmkHOAF2m6b57Bjzl1yYVnztb0p7Hc+9B9ZTSqvxRrhPnvdStoCXpmnef/ux1PxNWFPK5OA0v3D/\ntwZskl/FhsBDtD4wAAYx5hh4Jp9quAM2Csa3Fs99jBhOo78dXwLOyCcwnoBe4TmcIy/o862+mc0f\nuRB9AF/kPdQjYAm4BV6BG2AxxvaAi9a9h8Ao2kHB+Ebkvd9xDp7H2BXgelIuFIrvKnJrSF7Iln/G\nF9d98qmXt5LxRf/lOOdaY2cxf11rSpEc9K8gJKlSbgFJUqUsAJJUKQuAJFXKAiBJlbIASFKlLACS\nVCkLgCRV6htBUDO3bHduHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FqoY7lN9hEN",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 2 gen x 20 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf1-r-G7AFOs",
        "colab_type": "code",
        "outputId": "56f178fb-9ff9-4ce5-b883-f1ee6f93a0dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 16s 261us/step - loss: 0.3876 - acc: 0.8750\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0704 - acc: 0.9793\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0439 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0367 - acc: 0.9890\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0309 - acc: 0.9904\n",
            "10000/10000 [==============================] - 1s 100us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.2936 - acc: 0.9029\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0553 - acc: 0.9834\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0384 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0316 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0273 - acc: 0.9918\n",
            "10000/10000 [==============================] - 1s 103us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3522 - acc: 0.8898\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0625 - acc: 0.9810\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0442 - acc: 0.9866\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.0331 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0272 - acc: 0.9920\n",
            "10000/10000 [==============================] - 1s 77us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.4581 - acc: 0.8456\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0677 - acc: 0.9801\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0445 - acc: 0.9865\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0346 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0284 - acc: 0.9912\n",
            "10000/10000 [==============================] - 1s 106us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.4031 - acc: 0.8736\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0654 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0435 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0310 - acc: 0.9909\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0277 - acc: 0.9915\n",
            "10000/10000 [==============================] - 1s 96us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.3923 - acc: 0.8675\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0714 - acc: 0.9783\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0477 - acc: 0.9856\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0363 - acc: 0.9890\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0321 - acc: 0.9896\n",
            "10000/10000 [==============================] - 1s 106us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 0.4559 - acc: 0.8474\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0706 - acc: 0.9781\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0451 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0365 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0308 - acc: 0.9904\n",
            "10000/10000 [==============================] - 1s 109us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 134us/step - loss: 0.3718 - acc: 0.8817\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0609 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0418 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0331 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0282 - acc: 0.9916\n",
            "10000/10000 [==============================] - 1s 103us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.4742 - acc: 0.8425\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0851 - acc: 0.9752\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0570 - acc: 0.9835\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0424 - acc: 0.9871\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0384 - acc: 0.9885\n",
            "10000/10000 [==============================] - 1s 105us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.3501 - acc: 0.8833\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0636 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0440 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0346 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0276 - acc: 0.9916\n",
            "10000/10000 [==============================] - 1s 97us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.3202 - acc: 0.8999\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0594 - acc: 0.9827\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0428 - acc: 0.9870\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0339 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0269 - acc: 0.9917\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.3404 - acc: 0.8907\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0578 - acc: 0.9825\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0400 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0305 - acc: 0.9906\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0253 - acc: 0.9919\n",
            "10000/10000 [==============================] - 1s 87us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.3721 - acc: 0.8788\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0640 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0416 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0344 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0282 - acc: 0.9917\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.3126 - acc: 0.8980\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0547 - acc: 0.9826\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0394 - acc: 0.9882\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0313 - acc: 0.9906\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0284 - acc: 0.9913\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.3565 - acc: 0.8831\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0639 - acc: 0.9811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0403 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0310 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0252 - acc: 0.9923\n",
            "10000/10000 [==============================] - 1s 78us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.3306 - acc: 0.8901\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0615 - acc: 0.9815\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0438 - acc: 0.9868\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.0353 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0273 - acc: 0.9914\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.3080 - acc: 0.8993\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0614 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0397 - acc: 0.9879\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0331 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0263 - acc: 0.9919\n",
            "10000/10000 [==============================] - 1s 98us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.3643 - acc: 0.8817\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0624 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0437 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0392 - acc: 0.9884\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0302 - acc: 0.9909\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.3666 - acc: 0.8785\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0597 - acc: 0.9816\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0404 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0362 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0288 - acc: 0.9907\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.3566 - acc: 0.8841\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0685 - acc: 0.9790\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0430 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0334 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0288 - acc: 0.9909\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "this gen fitnesses: [0.99   0.9925 0.9867 0.9865 0.9896 0.9879 0.9891 0.991  0.9884 0.9932\n",
            " 0.9874 0.9878 0.9898 0.9936 0.9882 0.9911 0.9885 0.9919 0.9895 0.9922]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.1923 - acc: 0.9368\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0389 - acc: 0.9882\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0281 - acc: 0.9915\n",
            "10000/10000 [==============================] - 1s 101us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.2395 - acc: 0.9220\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0493 - acc: 0.9851\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0329 - acc: 0.9901\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0271 - acc: 0.9918\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.2715 - acc: 0.9121\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0540 - acc: 0.9836\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0352 - acc: 0.9888\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0304 - acc: 0.9906\n",
            "10000/10000 [==============================] - 1s 96us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.2459 - acc: 0.9203\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0490 - acc: 0.9851\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0363 - acc: 0.9885\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0295 - acc: 0.9910\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.2310 - acc: 0.9243\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0493 - acc: 0.9853\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0338 - acc: 0.9893\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0280 - acc: 0.9914\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.2646 - acc: 0.9159\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0542 - acc: 0.9841\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0446 - acc: 0.9865\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0357 - acc: 0.9895\n",
            "10000/10000 [==============================] - 1s 98us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 0.2801 - acc: 0.9076\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0530 - acc: 0.9842\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0374 - acc: 0.9887\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0301 - acc: 0.9912\n",
            "10000/10000 [==============================] - 1s 103us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.2529 - acc: 0.9167\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0487 - acc: 0.9853\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0385 - acc: 0.9882\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0300 - acc: 0.9910\n",
            "10000/10000 [==============================] - 1s 100us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.2117 - acc: 0.9337\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0399 - acc: 0.9880\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0295 - acc: 0.9912\n",
            "10000/10000 [==============================] - 1s 97us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.3344 - acc: 0.8839\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0550 - acc: 0.9842\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0429 - acc: 0.9875\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0309 - acc: 0.9911\n",
            "10000/10000 [==============================] - 1s 106us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3633 - acc: 0.8822\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0697 - acc: 0.9787\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0440 - acc: 0.9868\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0364 - acc: 0.9890\n",
            "10000/10000 [==============================] - 1s 80us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.2774 - acc: 0.9097\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0495 - acc: 0.9856\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 0.0361 - acc: 0.9890\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0297 - acc: 0.9909\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.1529 - acc: 0.9557\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0334 - acc: 0.9896\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0248 - acc: 0.9921\n",
            "10000/10000 [==============================] - 1s 99us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.9925 0.9929 0.989  0.99   0.9896 0.9917 0.9867 0.9911 0.9903 0.9888\n",
            " 0.9902 0.9876 0.9915 0.9918 0.9882 0.9911 0.9885 0.9919 0.9895 0.9922]\n",
            "The best individual [1 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0] had fitness (accuracy): 0.9929\n",
            "CPU times: user 13min 58s, sys: 2min 31s, total: 16min 30s\n",
            "Wall time: 18min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsYjksWrAGES",
        "colab_type": "code",
        "outputId": "01190080-2414-4a75-8ff1-a4a8629db11a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 2)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/H85gK2RVF0QKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4qWi23vA1Aj",
        "colab_type": "text"
      },
      "source": [
        "## Modification: 20 gen x 20 individuals, (MNIST/6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOWUaOvEM9QT",
        "colab_type": "code",
        "outputId": "1e82538a-8647-4139-ad49-baf72e4ad6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 563us/step - loss: 1.6660 - acc: 0.4189\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.4824 - acc: 0.8639\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.2324 - acc: 0.9409\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 401us/step - loss: 0.1377 - acc: 0.9625\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.1006 - acc: 0.9694\n",
            "1000/1000 [==============================] - 0s 441us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 609us/step - loss: 1.2173 - acc: 0.5886\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 443us/step - loss: 0.2416 - acc: 0.9298\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.1562 - acc: 0.9531\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.1475 - acc: 0.9587\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 442us/step - loss: 0.0727 - acc: 0.9773\n",
            "1000/1000 [==============================] - 0s 447us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 336us/step - loss: 1.1399 - acc: 0.6049\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 222us/step - loss: 0.2302 - acc: 0.9322\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 227us/step - loss: 0.1246 - acc: 0.9639\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 224us/step - loss: 0.1307 - acc: 0.9613\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 220us/step - loss: 0.0752 - acc: 0.9767\n",
            "1000/1000 [==============================] - 0s 275us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 551us/step - loss: 1.0914 - acc: 0.6362\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 415us/step - loss: 0.2317 - acc: 0.9285\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 417us/step - loss: 0.1584 - acc: 0.9529\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.0910 - acc: 0.9722\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 417us/step - loss: 0.0670 - acc: 0.9795\n",
            "1000/1000 [==============================] - 0s 428us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 540us/step - loss: 1.3536 - acc: 0.5247\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 389us/step - loss: 0.3479 - acc: 0.8985\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1682 - acc: 0.9487\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0967 - acc: 0.9714\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.0871 - acc: 0.9742\n",
            "1000/1000 [==============================] - 0s 370us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 568us/step - loss: 1.5183 - acc: 0.4689\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.4534 - acc: 0.8727\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.2219 - acc: 0.9372\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1933 - acc: 0.9433\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1140 - acc: 0.9671\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 529us/step - loss: 1.2703 - acc: 0.5771\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.2668 - acc: 0.9240\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.1393 - acc: 0.9598\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.1154 - acc: 0.9668\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.0770 - acc: 0.9757\n",
            "1000/1000 [==============================] - 0s 379us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 522us/step - loss: 1.5928 - acc: 0.4507\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.4055 - acc: 0.8821\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.2906 - acc: 0.9164\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 405us/step - loss: 0.1342 - acc: 0.9587\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.1001 - acc: 0.9692\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 512us/step - loss: 1.3681 - acc: 0.5198\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.3895 - acc: 0.8897\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1879 - acc: 0.9489\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1007 - acc: 0.9712\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.0701 - acc: 0.9793\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 1.3622 - acc: 0.5229\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.2965 - acc: 0.9118\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1714 - acc: 0.9492\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.1049 - acc: 0.9693\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 377us/step - loss: 0.0703 - acc: 0.9787\n",
            "1000/1000 [==============================] - 0s 390us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 604us/step - loss: 1.2234 - acc: 0.5844\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.2231 - acc: 0.9352\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.1260 - acc: 0.9607\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.1018 - acc: 0.9703\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.0859 - acc: 0.9728\n",
            "1000/1000 [==============================] - 0s 412us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 1.1605 - acc: 0.6178\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 248us/step - loss: 0.2311 - acc: 0.9344\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 250us/step - loss: 0.1541 - acc: 0.9554\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 3s 253us/step - loss: 0.1016 - acc: 0.9703\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 3s 254us/step - loss: 0.1129 - acc: 0.9653\n",
            "1000/1000 [==============================] - 0s 324us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 575us/step - loss: 1.2704 - acc: 0.5638\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2932 - acc: 0.9123\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.1526 - acc: 0.9537\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.0796 - acc: 0.9762\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0639 - acc: 0.9786\n",
            "1000/1000 [==============================] - 0s 385us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 506us/step - loss: 1.1530 - acc: 0.6048\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.2656 - acc: 0.9240\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1443 - acc: 0.9565\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1266 - acc: 0.9629\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0654 - acc: 0.9813\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 305us/step - loss: 1.2234 - acc: 0.5832\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 209us/step - loss: 0.2958 - acc: 0.9136\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 211us/step - loss: 0.1814 - acc: 0.9478\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 212us/step - loss: 0.1283 - acc: 0.9636\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 209us/step - loss: 0.1000 - acc: 0.9673\n",
            "1000/1000 [==============================] - 0s 269us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 1.1627 - acc: 0.5964\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.3208 - acc: 0.9080\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.1352 - acc: 0.9594\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 369us/step - loss: 0.1057 - acc: 0.9681\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0749 - acc: 0.9767\n",
            "1000/1000 [==============================] - 0s 338us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 482us/step - loss: 1.3871 - acc: 0.5223\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.3492 - acc: 0.9016\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.1750 - acc: 0.9486\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.1230 - acc: 0.9635\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 0.0813 - acc: 0.9751\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 503us/step - loss: 2.1667 - acc: 0.1889\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.6785 - acc: 0.7920\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.2162 - acc: 0.9369\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1514 - acc: 0.9553\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.0916 - acc: 0.9732\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 1.5228 - acc: 0.4723\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.4746 - acc: 0.8671\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.1954 - acc: 0.9448\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.1376 - acc: 0.9631\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.1112 - acc: 0.9668\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 551us/step - loss: 1.2704 - acc: 0.5748\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.2902 - acc: 0.9187\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1512 - acc: 0.9552\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1214 - acc: 0.9644\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0922 - acc: 0.9732\n",
            "1000/1000 [==============================] - 0s 414us/step\n",
            "this gen fitnesses: [0.953 0.963 0.971 0.97  0.962 0.965 0.978 0.96  0.945 0.969 0.975 0.969\n",
            " 0.969 0.958 0.971 0.957 0.958 0.965 0.962 0.962]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 541us/step - loss: 1.3016 - acc: 0.5956\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2095 - acc: 0.9394\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.1501 - acc: 0.9550\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0759 - acc: 0.9778\n",
            "1000/1000 [==============================] - 0s 396us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 2.3399 - acc: 0.1481\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.9962 - acc: 0.6880\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.2782 - acc: 0.9243\n",
            "1000/1000 [==============================] - 0s 406us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 1.0146 - acc: 0.6580\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.2145 - acc: 0.9368\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 342us/step - loss: 0.1664 - acc: 0.9529\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 344us/step - loss: 0.1095 - acc: 0.9687\n",
            "1000/1000 [==============================] - 0s 338us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 1.1754 - acc: 0.6019\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.2820 - acc: 0.9186\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1664 - acc: 0.9499\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1028 - acc: 0.9693\n",
            "1000/1000 [==============================] - 0s 398us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 309us/step - loss: 1.3912 - acc: 0.5370\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.2979 - acc: 0.9094\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 229us/step - loss: 0.1510 - acc: 0.9528\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.0876 - acc: 0.9728\n",
            "1000/1000 [==============================] - 0s 289us/step\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 535us/step - loss: 1.4410 - acc: 0.5081\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.2944 - acc: 0.9164\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.1476 - acc: 0.9561\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.1081 - acc: 0.9680\n",
            "1000/1000 [==============================] - 0s 385us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 489us/step - loss: 1.2471 - acc: 0.5966\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.2144 - acc: 0.9401\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1427 - acc: 0.9579\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 492us/step - loss: 0.9091 - acc: 0.7095\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1434 - acc: 0.9596\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0873 - acc: 0.9747\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 492us/step - loss: 0.9396 - acc: 0.7127\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1548 - acc: 0.9557\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0912 - acc: 0.9735\n",
            "1000/1000 [==============================] - 0s 378us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.2574 - acc: 0.5890\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.2237 - acc: 0.9337\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1285 - acc: 0.9616\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1047 - acc: 0.9698\n",
            "1000/1000 [==============================] - 0s 368us/step\n",
            "this gen fitnesses: [0.975 0.909 0.961 0.971 0.962 0.965 0.978 0.96  0.945 0.965 0.975 0.969\n",
            " 0.952 0.958 0.971 0.957 0.942 0.959 0.97  0.961]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.7745 - acc: 0.7408\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.1914 - acc: 0.9416\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 0.0897 - acc: 0.9736\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.0685 - acc: 0.9782\n",
            "1000/1000 [==============================] - 0s 354us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 555us/step - loss: 1.5084 - acc: 0.4928\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.3587 - acc: 0.8969\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.2054 - acc: 0.9456\n",
            "1000/1000 [==============================] - 0s 388us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.5155 - acc: 0.5327\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 416us/step - loss: 0.3211 - acc: 0.9048\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 416us/step - loss: 0.1646 - acc: 0.9482\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 415us/step - loss: 0.0853 - acc: 0.9727\n",
            "1000/1000 [==============================] - 0s 376us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 324us/step - loss: 1.0635 - acc: 0.6693\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 232us/step - loss: 0.2180 - acc: 0.9392\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 233us/step - loss: 0.1200 - acc: 0.9658\n",
            "1000/1000 [==============================] - 0s 296us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 543us/step - loss: 0.9416 - acc: 0.6850\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.1775 - acc: 0.9452\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0918 - acc: 0.9736\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.0651 - acc: 0.9806\n",
            "1000/1000 [==============================] - 0s 395us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 550us/step - loss: 0.9617 - acc: 0.6779\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1985 - acc: 0.9412\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1383 - acc: 0.9582\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0943 - acc: 0.9722\n",
            "1000/1000 [==============================] - 0s 394us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 310us/step - loss: 0.9580 - acc: 0.6906\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.1632 - acc: 0.9503\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 229us/step - loss: 0.1146 - acc: 0.9675\n",
            "1000/1000 [==============================] - 0s 287us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 474us/step - loss: 1.4353 - acc: 0.5341\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.2191 - acc: 0.9340\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.1104 - acc: 0.9665\n",
            "1000/1000 [==============================] - 0s 370us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 1.4935 - acc: 0.4923\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.4803 - acc: 0.8394\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1972 - acc: 0.9416\n",
            "1000/1000 [==============================] - 0s 367us/step\n",
            "this gen fitnesses: [0.975 0.909 0.961 0.971 0.979 0.945 0.978 0.96  0.954 0.941 0.965 0.969\n",
            " 0.948 0.958 0.964 0.948 0.942 0.959 0.97  0.944]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 2.2903 - acc: 0.1438\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 1.3174 - acc: 0.5681\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.4004 - acc: 0.8822\n",
            "1000/1000 [==============================] - 0s 394us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 499us/step - loss: 1.3784 - acc: 0.5263\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 403us/step - loss: 0.2715 - acc: 0.9229\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1496 - acc: 0.9595\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.0923 - acc: 0.9720\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 0.9960 - acc: 0.6976\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1882 - acc: 0.9453\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1030 - acc: 0.9695\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1620 - acc: 0.9544\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 509us/step - loss: 1.3145 - acc: 0.5560\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.2387 - acc: 0.9266\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 405us/step - loss: 0.1386 - acc: 0.9599\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.1788 - acc: 0.9432\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 536us/step - loss: 1.1034 - acc: 0.6180\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2040 - acc: 0.9395\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1315 - acc: 0.9628\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0990 - acc: 0.9712\n",
            "1000/1000 [==============================] - 0s 420us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 529us/step - loss: 0.9573 - acc: 0.6781\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.1745 - acc: 0.9488\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.1089 - acc: 0.9664\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.0609 - acc: 0.9816\n",
            "1000/1000 [==============================] - 0s 445us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 307us/step - loss: 1.1201 - acc: 0.6314\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.2595 - acc: 0.9328\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.1180 - acc: 0.9674\n",
            "1000/1000 [==============================] - 0s 305us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 555us/step - loss: 1.1184 - acc: 0.6174\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.2393 - acc: 0.9308\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.1168 - acc: 0.9671\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.0787 - acc: 0.9774\n",
            "1000/1000 [==============================] - 0s 419us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 0.9039 - acc: 0.7052\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 376us/step - loss: 0.1804 - acc: 0.9486\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.0959 - acc: 0.9729\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.0826 - acc: 0.9760\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 538us/step - loss: 0.9665 - acc: 0.6666\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1908 - acc: 0.9438\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.1038 - acc: 0.9697\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0699 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 419us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 283us/step - loss: 1.1804 - acc: 0.6047\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 207us/step - loss: 0.2847 - acc: 0.9161\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 210us/step - loss: 0.1437 - acc: 0.9597\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 206us/step - loss: 0.0824 - acc: 0.9756\n",
            "1000/1000 [==============================] - 0s 265us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 1.0071 - acc: 0.6555\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1664 - acc: 0.9549\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.1147 - acc: 0.9653\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.0744 - acc: 0.9785\n",
            "1000/1000 [==============================] - 0s 341us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 1.3179 - acc: 0.5481\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.2560 - acc: 0.9276\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1439 - acc: 0.9595\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1015 - acc: 0.9707\n",
            "1000/1000 [==============================] - 0s 344us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 1.0542 - acc: 0.6491\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.1885 - acc: 0.9452\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 438us/step - loss: 0.1027 - acc: 0.9702\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 443us/step - loss: 0.0816 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 442us/step\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 0.5816 - acc: 0.8192\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0995 - acc: 0.9695\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0782 - acc: 0.9780\n",
            "1000/1000 [==============================] - 0s 408us/step\n",
            "this gen fitnesses: [0.938 0.909 0.965 0.955 0.951 0.947 0.978 0.96  0.959 0.967 0.969 0.97\n",
            " 0.965 0.958 0.946 0.962 0.964 0.953 0.97  0.96 ]\n",
            "\t\t\tStarting generation 5...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 584us/step - loss: 0.7857 - acc: 0.7409\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.1369 - acc: 0.9603\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.0947 - acc: 0.9713\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.0688 - acc: 0.9790\n",
            "1000/1000 [==============================] - 0s 449us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 546us/step - loss: 0.8820 - acc: 0.6976\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1758 - acc: 0.9486\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.0945 - acc: 0.9721\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0775 - acc: 0.9770\n",
            "1000/1000 [==============================] - 0s 411us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 1.4044 - acc: 0.5226\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 256us/step - loss: 0.2432 - acc: 0.9276\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 257us/step - loss: 0.1553 - acc: 0.9541\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 259us/step - loss: 0.1076 - acc: 0.9666\n",
            "1000/1000 [==============================] - 0s 349us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 519us/step - loss: 0.6625 - acc: 0.7874\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.1192 - acc: 0.9643\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.0811 - acc: 0.9755\n",
            "1000/1000 [==============================] - 0s 361us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 498us/step - loss: 0.8904 - acc: 0.6966\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1585 - acc: 0.9523\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1485 - acc: 0.9573\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0760 - acc: 0.9781\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 0.9327 - acc: 0.7200\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1851 - acc: 0.9472\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0991 - acc: 0.9686\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0945 - acc: 0.9707\n",
            "1000/1000 [==============================] - 0s 374us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.967 0.94  0.965 0.953 0.972 0.947 0.978 0.96  0.959 0.967 0.969 0.97\n",
            " 0.965 0.958 0.946 0.962 0.969 0.953 0.953 0.96 ]\n",
            "\t\t\tStarting generation 6...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 523us/step - loss: 0.8826 - acc: 0.7016\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.1711 - acc: 0.9505\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1013 - acc: 0.9693\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.0724 - acc: 0.9777\n",
            "1000/1000 [==============================] - 0s 426us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 1.4484 - acc: 0.5152\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.2690 - acc: 0.9246\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1414 - acc: 0.9602\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.0972 - acc: 0.9722\n",
            "1000/1000 [==============================] - 0s 371us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 325us/step - loss: 1.3349 - acc: 0.5406\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 241us/step - loss: 0.2809 - acc: 0.9126\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 239us/step - loss: 0.1831 - acc: 0.9468\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 235us/step - loss: 0.1132 - acc: 0.9645\n",
            "1000/1000 [==============================] - 0s 308us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 533us/step - loss: 1.3197 - acc: 0.5890\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 419us/step - loss: 0.1922 - acc: 0.9455\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.1070 - acc: 0.9679\n",
            "1000/1000 [==============================] - 0s 443us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 552us/step - loss: 0.7135 - acc: 0.7762\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1978 - acc: 0.9462\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 413us/step - loss: 0.0897 - acc: 0.9753\n",
            "1000/1000 [==============================] - 0s 415us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.8273 - acc: 0.7562\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 202us/step - loss: 0.1695 - acc: 0.9501\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 197us/step - loss: 0.1051 - acc: 0.9685\n",
            "1000/1000 [==============================] - 0s 281us/step\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 487us/step - loss: 1.0769 - acc: 0.6654\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 374us/step - loss: 0.1511 - acc: 0.9551\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.1092 - acc: 0.9677\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.9539 - acc: 0.6800\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 344us/step - loss: 0.2063 - acc: 0.9398\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1165 - acc: 0.9645\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 343us/step - loss: 0.1284 - acc: 0.9632\n",
            "1000/1000 [==============================] - 0s 325us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 306us/step - loss: 1.0056 - acc: 0.6759\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1861 - acc: 0.9470\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 227us/step - loss: 0.0973 - acc: 0.9716\n",
            "1000/1000 [==============================] - 0s 333us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 579us/step - loss: 1.0642 - acc: 0.6546\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.1779 - acc: 0.9463\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 437us/step - loss: 0.0908 - acc: 0.9726\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1051 - acc: 0.9694\n",
            "1000/1000 [==============================] - 0s 433us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 468us/step - loss: 0.8855 - acc: 0.7058\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.1656 - acc: 0.9542\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 356us/step - loss: 0.1173 - acc: 0.9651\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 354us/step - loss: 0.1030 - acc: 0.9712\n",
            "1000/1000 [==============================] - 0s 344us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 502us/step - loss: 1.1888 - acc: 0.6292\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1691 - acc: 0.9528\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0787 - acc: 0.9772\n",
            "1000/1000 [==============================] - 0s 380us/step\n",
            "this gen fitnesses: [0.967 0.952 0.929 0.956 0.972 0.947 0.97  0.969 0.959 0.962 0.969 0.97\n",
            " 0.965 0.958 0.961 0.956 0.969 0.973 0.958 0.956]\n",
            "\t\t\tStarting generation 7...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 1.7073 - acc: 0.4471\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 433us/step - loss: 0.2852 - acc: 0.9180\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.1432 - acc: 0.9569\n",
            "1000/1000 [==============================] - 0s 440us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 512us/step - loss: 0.8972 - acc: 0.6950\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.1786 - acc: 0.9486\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.1114 - acc: 0.9670\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.0897 - acc: 0.9756\n",
            "1000/1000 [==============================] - 0s 388us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 502us/step - loss: 1.2295 - acc: 0.6282\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.2011 - acc: 0.9421\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1368 - acc: 0.9598\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0798 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 480us/step - loss: 1.1172 - acc: 0.6359\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.1975 - acc: 0.9482\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 377us/step - loss: 0.1065 - acc: 0.9685\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 378us/step - loss: 0.0764 - acc: 0.9783\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 318us/step - loss: 1.2108 - acc: 0.5865\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 225us/step - loss: 0.3488 - acc: 0.8967\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.2064 - acc: 0.9387\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 224us/step - loss: 0.1111 - acc: 0.9675\n",
            "1000/1000 [==============================] - 0s 291us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 1.1441 - acc: 0.6043\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.2068 - acc: 0.9425\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 348us/step - loss: 0.1113 - acc: 0.9695\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.0729 - acc: 0.9783\n",
            "1000/1000 [==============================] - 0s 362us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 544us/step - loss: 1.1818 - acc: 0.5906\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1800 - acc: 0.9508\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1534 - acc: 0.9581\n",
            "1000/1000 [==============================] - 0s 397us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 447us/step - loss: 0.8754 - acc: 0.6989\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.1780 - acc: 0.9496\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 357us/step - loss: 0.0963 - acc: 0.9694\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 358us/step - loss: 0.0811 - acc: 0.9748\n",
            "1000/1000 [==============================] - 0s 333us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 499us/step - loss: 1.0819 - acc: 0.6296\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1936 - acc: 0.9437\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.1248 - acc: 0.9658\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0753 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 373us/step\n",
            "this gen fitnesses: [0.948 0.952 0.929 0.956 0.972 0.947 0.97  0.973 0.959 0.962 0.97  0.951\n",
            " 0.965 0.958 0.961 0.924 0.953 0.962 0.966 0.967]\n",
            "\t\t\tStarting generation 8...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 529us/step - loss: 1.1552 - acc: 0.6000\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2247 - acc: 0.9364\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.1506 - acc: 0.9581\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 431us/step - loss: 0.0838 - acc: 0.9768\n",
            "1000/1000 [==============================] - 0s 424us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 1.2012 - acc: 0.6362\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1650 - acc: 0.9513\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1003 - acc: 0.9709\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.0664 - acc: 0.9798\n",
            "1000/1000 [==============================] - 0s 425us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 528us/step - loss: 1.0970 - acc: 0.6368\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 413us/step - loss: 0.2126 - acc: 0.9397\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.1208 - acc: 0.9625\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.0799 - acc: 0.9757\n",
            "1000/1000 [==============================] - 0s 390us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 498us/step - loss: 1.3545 - acc: 0.5447\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.2648 - acc: 0.9243\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1426 - acc: 0.9593\n",
            "1000/1000 [==============================] - 0s 380us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 470us/step - loss: 1.4278 - acc: 0.5418\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.2222 - acc: 0.9366\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 369us/step - loss: 0.1122 - acc: 0.9670\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.0729 - acc: 0.9782\n",
            "1000/1000 [==============================] - 0s 381us/step\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.948 0.952 0.929 0.956 0.97  0.947 0.97  0.973 0.959 0.962 0.964 0.951\n",
            " 0.969 0.961 0.961 0.924 0.952 0.962 0.966 0.967]\n",
            "\t\t\tStarting generation 9...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 579us/step - loss: 2.0633 - acc: 0.2697\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.6709 - acc: 0.7743\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.2602 - acc: 0.9365\n",
            "1000/1000 [==============================] - 0s 418us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 459us/step - loss: 1.1847 - acc: 0.5875\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.2694 - acc: 0.9292\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1531 - acc: 0.9547\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.0913 - acc: 0.9752\n",
            "1000/1000 [==============================] - 0s 359us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 481us/step - loss: 0.9495 - acc: 0.6693\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 373us/step - loss: 0.1421 - acc: 0.9532\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.1123 - acc: 0.9655\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0799 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 351us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 463us/step - loss: 0.8825 - acc: 0.6969\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.1593 - acc: 0.9517\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0913 - acc: 0.9708\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.0734 - acc: 0.9766\n",
            "1000/1000 [==============================] - 0s 359us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.2127 - acc: 0.6003\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.2423 - acc: 0.9336\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 419us/step - loss: 0.1457 - acc: 0.9599\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 417us/step - loss: 0.0940 - acc: 0.9720\n",
            "1000/1000 [==============================] - 0s 401us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 1.0312 - acc: 0.6428\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.1826 - acc: 0.9492\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1357 - acc: 0.9603\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0837 - acc: 0.9754\n",
            "1000/1000 [==============================] - 0s 377us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 556us/step - loss: 0.8557 - acc: 0.7148\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 0.1596 - acc: 0.9537\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 436us/step - loss: 0.1027 - acc: 0.9715\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1115 - acc: 0.9655\n",
            "1000/1000 [==============================] - 0s 383us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 319us/step - loss: 1.0096 - acc: 0.6755\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 223us/step - loss: 0.1801 - acc: 0.9466\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.1520 - acc: 0.9553\n",
            "1000/1000 [==============================] - 0s 282us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 496us/step - loss: 0.8260 - acc: 0.7262\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1509 - acc: 0.9548\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.0908 - acc: 0.9729\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0728 - acc: 0.9785\n",
            "1000/1000 [==============================] - 0s 376us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 1.1201 - acc: 0.6265\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.2313 - acc: 0.9371\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1263 - acc: 0.9661\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1579 - acc: 0.9564\n",
            "1000/1000 [==============================] - 0s 367us/step\n",
            "this gen fitnesses: [0.948 0.944 0.974 0.912 0.97  0.947 0.97  0.968 0.959 0.962 0.964 0.973\n",
            " 0.973 0.963 0.961 0.948 0.952 0.962 0.974 0.969]\n",
            "\t\t\tStarting generation 10...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 1.1676 - acc: 0.5787\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.2067 - acc: 0.9419\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1004 - acc: 0.9706\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0786 - acc: 0.9779\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 1.5247 - acc: 0.4942\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.3387 - acc: 0.9076\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 351us/step - loss: 0.1577 - acc: 0.9555\n",
            "1000/1000 [==============================] - 0s 375us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.1761 - acc: 0.6693\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1498 - acc: 0.9580\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.1173 - acc: 0.9652\n",
            "1000/1000 [==============================] - 0s 401us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 6s 560us/step - loss: 0.7499 - acc: 0.7551\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1320 - acc: 0.9625\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1029 - acc: 0.9709\n",
            "1000/1000 [==============================] - 0s 399us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 511us/step - loss: 0.9984 - acc: 0.6636\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1725 - acc: 0.9507\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0764 - acc: 0.9782\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1212 - acc: 0.9649\n",
            "1000/1000 [==============================] - 0s 398us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 569us/step - loss: 0.9079 - acc: 0.7020\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.1870 - acc: 0.9429\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.0925 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0573 - acc: 0.9837\n",
            "1000/1000 [==============================] - 0s 407us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.9918 - acc: 0.6845\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1612 - acc: 0.9533\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0883 - acc: 0.9745\n",
            "1000/1000 [==============================] - 0s 328us/step\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.4961 - acc: 0.5574\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 415us/step - loss: 0.2729 - acc: 0.9105\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1535 - acc: 0.9545\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.968 0.944 0.951 0.959 0.97  0.964 0.97  0.968 0.959 0.962 0.965 0.973\n",
            " 0.973 0.972 0.962 0.948 0.952 0.962 0.934 0.969]\n",
            "\t\t\tStarting generation 11...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 505us/step - loss: 1.4597 - acc: 0.4835\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 0.2850 - acc: 0.9265\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1635 - acc: 0.9599\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0910 - acc: 0.9764\n",
            "1000/1000 [==============================] - 0s 398us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 535us/step - loss: 0.9535 - acc: 0.6833\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1701 - acc: 0.9502\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0865 - acc: 0.9733\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0846 - acc: 0.9738\n",
            "1000/1000 [==============================] - 0s 406us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.7617 - acc: 0.7319\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.1452 - acc: 0.9567\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0936 - acc: 0.9721\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.0577 - acc: 0.9813\n",
            "1000/1000 [==============================] - 0s 350us/step\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 509us/step - loss: 0.9242 - acc: 0.6904\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 401us/step - loss: 0.1523 - acc: 0.9545\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0851 - acc: 0.9753\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0724 - acc: 0.9790\n",
            "1000/1000 [==============================] - 0s 378us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 518us/step - loss: 0.8795 - acc: 0.7198\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1420 - acc: 0.9573\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.2007 - acc: 0.9411\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.0664 - acc: 0.9806\n",
            "1000/1000 [==============================] - 0s 377us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 292us/step - loss: 1.2151 - acc: 0.5831\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 214us/step - loss: 0.2329 - acc: 0.9325\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 214us/step - loss: 0.1463 - acc: 0.9575\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 217us/step - loss: 0.0966 - acc: 0.9721\n",
            "1000/1000 [==============================] - 0s 267us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 511us/step - loss: 1.2017 - acc: 0.5840\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.2136 - acc: 0.9396\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1073 - acc: 0.9698\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1087 - acc: 0.9683\n",
            "1000/1000 [==============================] - 0s 387us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 1.1481 - acc: 0.6202\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.1686 - acc: 0.9517\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1042 - acc: 0.9682\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.0876 - acc: 0.9737\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 503us/step - loss: 2.2209 - acc: 0.1898\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.7681 - acc: 0.7546\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.2070 - acc: 0.9408\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 483us/step - loss: 1.0622 - acc: 0.6461\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1570 - acc: 0.9550\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1065 - acc: 0.9684\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0833 - acc: 0.9749\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 537us/step - loss: 0.9903 - acc: 0.6680\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 430us/step - loss: 0.1691 - acc: 0.9524\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1163 - acc: 0.9670\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0946 - acc: 0.9738\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "this gen fitnesses: [0.968 0.962 0.985 0.959 0.97  0.972 0.97  0.968 0.974 0.954 0.968 0.953\n",
            " 0.92  0.972 0.962 0.948 0.967 0.962 0.934 0.972]\n",
            "\t\t\tStarting generation 12...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 558us/step - loss: 1.2365 - acc: 0.5931\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.3244 - acc: 0.9121\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1414 - acc: 0.9584\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1061 - acc: 0.9684\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.0868 - acc: 0.9741\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 464us/step - loss: 0.9942 - acc: 0.6888\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1419 - acc: 0.9601\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0765 - acc: 0.9779\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 0.9884 - acc: 0.6707\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1612 - acc: 0.9568\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1188 - acc: 0.9692\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.2310 - acc: 0.5776\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.2016 - acc: 0.9410\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1032 - acc: 0.9718\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0959 - acc: 0.9715\n",
            "1000/1000 [==============================] - 0s 385us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 515us/step - loss: 1.0448 - acc: 0.6572\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.1392 - acc: 0.9586\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1360 - acc: 0.9571\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 413us/step - loss: 0.0698 - acc: 0.9788\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 534us/step - loss: 1.3993 - acc: 0.5516\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1968 - acc: 0.9421\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1521 - acc: 0.9537\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0709 - acc: 0.9784\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 517us/step - loss: 1.5430 - acc: 0.4833\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1912 - acc: 0.9447\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 411us/step - loss: 0.0902 - acc: 0.9719\n",
            "1000/1000 [==============================] - 0s 395us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 1.5581 - acc: 0.5160\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1956 - acc: 0.9459\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.1645 - acc: 0.9559\n",
            "1000/1000 [==============================] - 0s 333us/step\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 6s 567us/step - loss: 1.3085 - acc: 0.5665\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.2687 - acc: 0.9214\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1877 - acc: 0.9437\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1064 - acc: 0.9700\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.0657 - acc: 0.9811\n",
            "1000/1000 [==============================] - 0s 405us/step\n",
            "this gen fitnesses: [0.968 0.961 0.985 0.97  0.97  0.972 0.967 0.959 0.975 0.954 0.98  0.965\n",
            " 0.92  0.972 0.969 0.948 0.967 0.962 0.934 0.971]\n",
            "\t\t\tStarting generation 13...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 2.2765 - acc: 0.2031\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.5576 - acc: 0.8292\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 429us/step - loss: 0.1983 - acc: 0.9396\n",
            "1000/1000 [==============================] - 0s 413us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 444us/step - loss: 0.9740 - acc: 0.6734\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 344us/step - loss: 0.1579 - acc: 0.9508\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 342us/step - loss: 0.0804 - acc: 0.9758\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 343us/step - loss: 0.0536 - acc: 0.9842\n",
            "1000/1000 [==============================] - 0s 335us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 467us/step - loss: 1.1945 - acc: 0.6430\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.1065 - acc: 0.9698\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.0622 - acc: 0.9802\n",
            "1000/1000 [==============================] - 0s 365us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 489us/step - loss: 1.2135 - acc: 0.5763\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1807 - acc: 0.9510\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0985 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0672 - acc: 0.9800\n",
            "1000/1000 [==============================] - 0s 372us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 545us/step - loss: 1.2222 - acc: 0.5711\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.3573 - acc: 0.8994\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1262 - acc: 0.9648\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.0919 - acc: 0.9712\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 313us/step - loss: 1.3471 - acc: 0.5652\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 233us/step - loss: 0.3310 - acc: 0.9057\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 230us/step - loss: 0.1709 - acc: 0.9468\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.1164 - acc: 0.9643\n",
            "1000/1000 [==============================] - 0s 287us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 532us/step - loss: 1.2733 - acc: 0.5647\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 405us/step - loss: 0.2148 - acc: 0.9363\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 408us/step - loss: 0.1222 - acc: 0.9628\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.0968 - acc: 0.9702\n",
            "1000/1000 [==============================] - 0s 402us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 2.0434 - acc: 0.2971\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.4022 - acc: 0.8819\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 412us/step - loss: 0.1643 - acc: 0.9521\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 434us/step - loss: 0.8196 - acc: 0.7282\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1520 - acc: 0.9579\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0809 - acc: 0.9752\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 338us/step - loss: 0.0666 - acc: 0.9816\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 312us/step - loss: 1.0118 - acc: 0.6605\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.1820 - acc: 0.9454\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 228us/step - loss: 0.0981 - acc: 0.9698\n",
            "1000/1000 [==============================] - 0s 292us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 549us/step - loss: 1.2380 - acc: 0.5847\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.2001 - acc: 0.9427\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.1124 - acc: 0.9671\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0802 - acc: 0.9765\n",
            "1000/1000 [==============================] - 0s 401us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.968 0.95  0.955 0.975 0.753 0.972 0.948 0.959 0.975 0.963 0.953 0.952\n",
            " 0.92  0.972 0.952 0.961 0.967 0.962 0.972 0.971]\n",
            "\t\t\tStarting generation 14...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.0847 - acc: 0.6259\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.2118 - acc: 0.9383\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1412 - acc: 0.9602\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1021 - acc: 0.9710\n",
            "1000/1000 [==============================] - 0s 397us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 1.0488 - acc: 0.6545\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 277us/step - loss: 0.1614 - acc: 0.9542\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 277us/step - loss: 0.0980 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 277us/step - loss: 0.0802 - acc: 0.9763\n",
            "1000/1000 [==============================] - 0s 287us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 480us/step - loss: 0.8791 - acc: 0.6848\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1008 - acc: 0.9726\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0706 - acc: 0.9788\n",
            "1000/1000 [==============================] - 0s 367us/step\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 1.1032 - acc: 0.6273\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 420us/step - loss: 0.1654 - acc: 0.9534\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0806 - acc: 0.9746\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.0773 - acc: 0.9759\n",
            "1000/1000 [==============================] - 0s 394us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 342us/step - loss: 1.2847 - acc: 0.5745\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 245us/step - loss: 0.3646 - acc: 0.8920\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 249us/step - loss: 0.1632 - acc: 0.9505\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 249us/step - loss: 0.1111 - acc: 0.9655\n",
            "1000/1000 [==============================] - 0s 311us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 492us/step - loss: 1.0044 - acc: 0.6475\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.1768 - acc: 0.9484\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 380us/step - loss: 0.1026 - acc: 0.9696\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0707 - acc: 0.9788\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 291us/step - loss: 1.1096 - acc: 0.6189\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 216us/step - loss: 0.2711 - acc: 0.9211\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1652 - acc: 0.9506\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1032 - acc: 0.9695\n",
            "1000/1000 [==============================] - 0s 274us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 484us/step - loss: 1.0538 - acc: 0.6454\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1881 - acc: 0.9470\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0873 - acc: 0.9765\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.0608 - acc: 0.9811\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 510us/step - loss: 0.9058 - acc: 0.7149\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1466 - acc: 0.9566\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.1075 - acc: 0.9672\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.0816 - acc: 0.9747\n",
            "1000/1000 [==============================] - 0s 370us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 1.1231 - acc: 0.6466\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.1610 - acc: 0.9514\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 365us/step - loss: 0.1126 - acc: 0.9677\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0622 - acc: 0.9801\n",
            "1000/1000 [==============================] - 0s 349us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 539us/step - loss: 0.7711 - acc: 0.7532\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.1466 - acc: 0.9612\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 428us/step - loss: 0.1079 - acc: 0.9699\n",
            "1000/1000 [==============================] - 0s 415us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 2s 224us/step - loss: 1.0559 - acc: 0.6547\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.2419 - acc: 0.9284\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.1223 - acc: 0.9631\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.0865 - acc: 0.9758\n",
            "1000/1000 [==============================] - 0s 245us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 3s 328us/step - loss: 0.6663 - acc: 0.7898\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 229us/step - loss: 0.1120 - acc: 0.9678\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 227us/step - loss: 0.0808 - acc: 0.9743\n",
            "1000/1000 [==============================] - 0s 285us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.0477 - acc: 0.6508\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1610 - acc: 0.9535\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1016 - acc: 0.9699\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0767 - acc: 0.9768\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 514us/step - loss: 0.9374 - acc: 0.6876\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1494 - acc: 0.9542\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 408us/step - loss: 0.0869 - acc: 0.9716\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.0723 - acc: 0.9774\n",
            "1000/1000 [==============================] - 0s 386us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 541us/step - loss: 2.2074 - acc: 0.1671\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.6606 - acc: 0.8013\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.1710 - acc: 0.9520\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.968 0.962 0.923 0.968 0.753 0.972 0.949 0.958 0.975 0.955 0.946 0.942\n",
            " 0.965 0.948 0.967 0.944 0.956 0.952 0.948 0.971]\n",
            "\t\t\tStarting generation 15...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 0.9905 - acc: 0.6689\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.1725 - acc: 0.9503\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0835 - acc: 0.9760\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0838 - acc: 0.9738\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 296us/step - loss: 1.0721 - acc: 0.6286\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 221us/step - loss: 0.2233 - acc: 0.9362\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 218us/step - loss: 0.1603 - acc: 0.9514\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 219us/step - loss: 0.1200 - acc: 0.9629\n",
            "1000/1000 [==============================] - 0s 278us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 455us/step - loss: 0.8150 - acc: 0.7314\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 363us/step - loss: 0.1303 - acc: 0.9627\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.0845 - acc: 0.9756\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.0867 - acc: 0.9757\n",
            "1000/1000 [==============================] - 0s 350us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 513us/step - loss: 1.0537 - acc: 0.6584\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1432 - acc: 0.9575\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 406us/step - loss: 0.1023 - acc: 0.9711\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 407us/step - loss: 0.0663 - acc: 0.9801\n",
            "1000/1000 [==============================] - 0s 368us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 491us/step - loss: 1.5992 - acc: 0.4457\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.5759 - acc: 0.8194\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.2550 - acc: 0.9230\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.1368 - acc: 0.9621\n",
            "1000/1000 [==============================] - 0s 393us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 505us/step - loss: 1.3305 - acc: 0.5742\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1604 - acc: 0.9523\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0899 - acc: 0.9717\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.0590 - acc: 0.9813\n",
            "1000/1000 [==============================] - 0s 366us/step\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 497us/step - loss: 1.0935 - acc: 0.6306\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.2150 - acc: 0.9398\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1509 - acc: 0.9567\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.0800 - acc: 0.9761\n",
            "1000/1000 [==============================] - 0s 371us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 2s 222us/step - loss: 0.8903 - acc: 0.7170\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 2s 158us/step - loss: 0.1731 - acc: 0.9495\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 2s 157us/step - loss: 0.0951 - acc: 0.9724\n",
            "1000/1000 [==============================] - 0s 261us/step\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 435us/step - loss: 1.3464 - acc: 0.5283\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.3273 - acc: 0.9127\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1202 - acc: 0.9649\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0896 - acc: 0.9715\n",
            "1000/1000 [==============================] - 0s 327us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 494us/step - loss: 1.2062 - acc: 0.6449\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.1814 - acc: 0.9505\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1035 - acc: 0.9697\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 531us/step - loss: 2.0327 - acc: 0.3189\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.5969 - acc: 0.8240\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1584 - acc: 0.9549\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 547us/step - loss: 1.0940 - acc: 0.6861\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.2172 - acc: 0.9377\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1188 - acc: 0.9667\n",
            "1000/1000 [==============================] - 0s 418us/step\n",
            "this gen fitnesses: [0.944 0.962 0.923 0.966 0.973 0.945 0.949 0.954 0.978 0.955 0.946 0.971\n",
            " 0.965 0.948 0.92  0.944 0.976 0.97  0.959 0.956]\n",
            "\t\t\tStarting generation 16...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 1.2102 - acc: 0.5991\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.1964 - acc: 0.9439\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.0924 - acc: 0.9746\n",
            "1000/1000 [==============================] - 0s 294us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 1.0549 - acc: 0.6634\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1578 - acc: 0.9548\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1065 - acc: 0.9715\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.0692 - acc: 0.9796\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 514us/step - loss: 1.1140 - acc: 0.6025\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.1772 - acc: 0.9470\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 400us/step - loss: 0.0849 - acc: 0.9758\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 402us/step - loss: 0.0624 - acc: 0.9807\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 559us/step - loss: 1.1048 - acc: 0.6355\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1409 - acc: 0.9610\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1116 - acc: 0.9675\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 421us/step - loss: 0.0663 - acc: 0.9798\n",
            "1000/1000 [==============================] - 0s 404us/step\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 418us/step - loss: 0.9416 - acc: 0.6913\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 334us/step - loss: 0.1733 - acc: 0.9488\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 334us/step - loss: 0.0906 - acc: 0.9744\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 336us/step - loss: 0.0942 - acc: 0.9726\n",
            "1000/1000 [==============================] - 0s 320us/step\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.9493 - acc: 0.7291\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.1358 - acc: 0.9580\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 278us/step - loss: 0.0891 - acc: 0.9715\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 279us/step - loss: 0.0514 - acc: 0.9832\n",
            "1000/1000 [==============================] - 0s 296us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 460us/step - loss: 1.0799 - acc: 0.6253\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 0.1590 - acc: 0.9545\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.0856 - acc: 0.9753\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.0670 - acc: 0.9801\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 501us/step - loss: 0.7873 - acc: 0.7239\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1620 - acc: 0.9521\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 404us/step - loss: 0.0962 - acc: 0.9710\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 401us/step - loss: 0.0989 - acc: 0.9698\n",
            "1000/1000 [==============================] - 0s 368us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 525us/step - loss: 0.8314 - acc: 0.7173\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1348 - acc: 0.9608\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.1112 - acc: 0.9695\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.0977 - acc: 0.9721\n",
            "1000/1000 [==============================] - 0s 377us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 487us/step - loss: 1.0426 - acc: 0.6669\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.2435 - acc: 0.9309\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.0971 - acc: 0.9712\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0716 - acc: 0.9785\n",
            "1000/1000 [==============================] - 0s 371us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 538us/step - loss: 0.9572 - acc: 0.6886\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.1547 - acc: 0.9519\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.0958 - acc: 0.9718\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0814 - acc: 0.9754\n",
            "1000/1000 [==============================] - 0s 389us/step\n",
            "this gen fitnesses: [0.944 0.962 0.947 0.979 0.964 0.975 0.949 0.954 0.978 0.973 0.946 0.971\n",
            " 0.965 0.948 0.959 0.951 0.97  0.961 0.972 0.969]\n",
            "\t\t\tStarting generation 17...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 6s 553us/step - loss: 0.8288 - acc: 0.7446\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 424us/step - loss: 0.1261 - acc: 0.9606\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0826 - acc: 0.9748\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0781 - acc: 0.9777\n",
            "1000/1000 [==============================] - 0s 418us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 0.8990 - acc: 0.7144\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.2085 - acc: 0.9438\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.0891 - acc: 0.9745\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.0828 - acc: 0.9756\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 489us/step - loss: 2.4978 - acc: 0.2492\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.5596 - acc: 0.8293\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.2062 - acc: 0.9365\n",
            "1000/1000 [==============================] - 0s 365us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 454us/step - loss: 0.8550 - acc: 0.7029\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.1475 - acc: 0.9556\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 347us/step - loss: 0.0753 - acc: 0.9768\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 349us/step - loss: 0.0831 - acc: 0.9735\n",
            "1000/1000 [==============================] - 0s 344us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 461us/step - loss: 0.9369 - acc: 0.6859\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.1698 - acc: 0.9526\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 368us/step - loss: 0.0966 - acc: 0.9727\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 367us/step - loss: 0.0596 - acc: 0.9834\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 477us/step - loss: 0.8176 - acc: 0.7331\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 381us/step - loss: 0.1483 - acc: 0.9564\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 377us/step - loss: 0.1161 - acc: 0.9656\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 378us/step - loss: 0.0648 - acc: 0.9809\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 441us/step - loss: 1.2921 - acc: 0.5482\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1561 - acc: 0.9543\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0894 - acc: 0.9730\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0692 - acc: 0.9786\n",
            "1000/1000 [==============================] - 0s 335us/step\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 500us/step - loss: 0.8209 - acc: 0.7166\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.1611 - acc: 0.9503\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.0987 - acc: 0.9712\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.0675 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 378us/step\n",
            "this gen fitnesses: [0.944 0.959 0.947 0.979 0.964 0.975 0.969 0.953 0.978 0.973 0.972 0.967\n",
            " 0.965 0.948 0.971 0.966 0.97  0.961 0.972 0.96 ]\n",
            "\t\t\tStarting generation 18...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 488us/step - loss: 0.8468 - acc: 0.7235\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1279 - acc: 0.9631\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0838 - acc: 0.9743\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.0740 - acc: 0.9775\n",
            "1000/1000 [==============================] - 0s 369us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 0.9803 - acc: 0.6785\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1791 - acc: 0.9489\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 341us/step - loss: 0.1048 - acc: 0.9694\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0711 - acc: 0.9792\n",
            "1000/1000 [==============================] - 0s 337us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 471us/step - loss: 0.9599 - acc: 0.6792\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 370us/step - loss: 0.1666 - acc: 0.9527\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.1019 - acc: 0.9697\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 371us/step - loss: 0.0576 - acc: 0.9829\n",
            "1000/1000 [==============================] - 0s 359us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 532us/step - loss: 1.3326 - acc: 0.5375\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2576 - acc: 0.9293\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.1378 - acc: 0.9622\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.0730 - acc: 0.9795\n",
            "1000/1000 [==============================] - 0s 396us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #7\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 497us/step - loss: 1.2779 - acc: 0.5967\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1705 - acc: 0.9516\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1206 - acc: 0.9635\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.0616 - acc: 0.9816\n",
            "1000/1000 [==============================] - 0s 364us/step\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 473us/step - loss: 0.7778 - acc: 0.7538\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 374us/step - loss: 0.1153 - acc: 0.9636\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 376us/step - loss: 0.0669 - acc: 0.9798\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 372us/step - loss: 0.0580 - acc: 0.9821\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.944 0.97  0.969 0.962 0.971 0.975 0.969 0.953 0.978 0.973 0.972 0.963\n",
            " 0.965 0.948 0.971 0.966 0.97  0.977 0.972 0.96 ]\n",
            "\t\t\tStarting generation 19...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 480us/step - loss: 0.8959 - acc: 0.7257\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 366us/step - loss: 0.1245 - acc: 0.9623\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 364us/step - loss: 0.0671 - acc: 0.9791\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 465us/step - loss: 1.2228 - acc: 0.5561\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 361us/step - loss: 0.2566 - acc: 0.9263\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 0.1480 - acc: 0.9556\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 359us/step - loss: 0.1105 - acc: 0.9695\n",
            "1000/1000 [==============================] - 0s 349us/step\n",
            "Creating and evaluating indiv #2\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #3\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #4\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 542us/step - loss: 1.1285 - acc: 0.5921\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.2072 - acc: 0.9413\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 423us/step - loss: 0.1151 - acc: 0.9663\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 422us/step - loss: 0.0763 - acc: 0.9761\n",
            "1000/1000 [==============================] - 0s 408us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 343us/step - loss: 1.4014 - acc: 0.5420\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 231us/step - loss: 0.3179 - acc: 0.9003\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 232us/step - loss: 0.1924 - acc: 0.9427\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 234us/step - loss: 0.1199 - acc: 0.9644\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 235us/step - loss: 0.0814 - acc: 0.9739\n",
            "1000/1000 [==============================] - 0s 291us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.9228 - acc: 0.3042\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.7125 - acc: 0.7811\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.2054 - acc: 0.9436\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1078 - acc: 0.9711\n",
            "1000/1000 [==============================] - 0s 381us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 479us/step - loss: 1.6765 - acc: 0.4851\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.2780 - acc: 0.9205\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.1421 - acc: 0.9630\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #13\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #16\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 3s 293us/step - loss: 1.1699 - acc: 0.5972\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2s 192us/step - loss: 0.2283 - acc: 0.9333\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2s 191us/step - loss: 0.1533 - acc: 0.9541\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 2s 191us/step - loss: 0.0955 - acc: 0.9714\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 2s 191us/step - loss: 0.0835 - acc: 0.9741\n",
            "1000/1000 [==============================] - 0s 260us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 483us/step - loss: 1.4258 - acc: 0.4868\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.3449 - acc: 0.8971\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1445 - acc: 0.9556\n",
            "1000/1000 [==============================] - 0s 357us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 5s 514us/step - loss: 1.0649 - acc: 0.6684\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 4s 410us/step - loss: 0.1279 - acc: 0.9634\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 4s 414us/step - loss: 0.1199 - acc: 0.9654\n",
            "1000/1000 [==============================] - 0s 390us/step\n",
            "this gen fitnesses: [0.973 0.96  0.969 0.962 0.971 0.965 0.947 0.941 0.95  0.973 0.972 0.963\n",
            " 0.965 0.948 0.971 0.966 0.97  0.967 0.955 0.968]\n",
            "\t\t\tStarting generation 20...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #1\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 472us/step - loss: 0.9644 - acc: 0.7122\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 338us/step - loss: 0.1436 - acc: 0.9598\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0842 - acc: 0.9754\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.0947 - acc: 0.9742\n",
            "1000/1000 [==============================] - 0s 343us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 512us/step - loss: 1.7752 - acc: 0.3718\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 408us/step - loss: 0.4119 - acc: 0.8627\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.1793 - acc: 0.9535\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.0949 - acc: 0.9734\n",
            "1000/1000 [==============================] - 0s 384us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 494us/step - loss: 1.0829 - acc: 0.6152\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.1624 - acc: 0.9563\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.0860 - acc: 0.9754\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 0.0688 - acc: 0.9812\n",
            "1000/1000 [==============================] - 0s 391us/step\n",
            "Creating and evaluating indiv #5\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 3s 306us/step - loss: 1.2082 - acc: 0.5818\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 2s 216us/step - loss: 0.2548 - acc: 0.9251\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1641 - acc: 0.9521\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 2s 215us/step - loss: 0.1044 - acc: 0.9674\n",
            "1000/1000 [==============================] - 0s 274us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 484us/step - loss: 1.0297 - acc: 0.6623\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.2159 - acc: 0.9397\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.0906 - acc: 0.9744\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 383us/step - loss: 0.0589 - acc: 0.9826\n",
            "1000/1000 [==============================] - 0s 375us/step\n",
            "Creating and evaluating indiv #8\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #9\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 439us/step - loss: 1.1868 - acc: 0.5991\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.3385 - acc: 0.8937\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 346us/step - loss: 0.1330 - acc: 0.9635\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 345us/step - loss: 0.1492 - acc: 0.9598\n",
            "1000/1000 [==============================] - 0s 360us/step\n",
            "Creating and evaluating indiv #11\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 486us/step - loss: 1.0226 - acc: 0.6785\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.1794 - acc: 0.9479\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 382us/step - loss: 0.1004 - acc: 0.9701\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 384us/step - loss: 0.0933 - acc: 0.9703\n",
            "1000/1000 [==============================] - 0s 363us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 537us/step - loss: 0.9836 - acc: 0.6807\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 425us/step - loss: 0.1286 - acc: 0.9609\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 426us/step - loss: 0.0793 - acc: 0.9761\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 427us/step - loss: 0.0571 - acc: 0.9818\n",
            "1000/1000 [==============================] - 0s 435us/step\n",
            "Creating and evaluating indiv #14\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 4s 440us/step - loss: 1.2422 - acc: 0.6321\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 3s 339us/step - loss: 0.1648 - acc: 0.9544\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.1043 - acc: 0.9687\n",
            "1000/1000 [==============================] - 0s 353us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 5s 452us/step - loss: 1.3259 - acc: 0.5665\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 4s 360us/step - loss: 0.2618 - acc: 0.9364\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 4s 362us/step - loss: 0.1448 - acc: 0.9615\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 4s 358us/step - loss: 0.1171 - acc: 0.9691\n",
            "1000/1000 [==============================] - 0s 346us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 4s 432us/step - loss: 0.9969 - acc: 0.6774\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 3s 337us/step - loss: 0.2154 - acc: 0.9407\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 3s 337us/step - loss: 0.1105 - acc: 0.9700\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 3s 340us/step - loss: 0.0831 - acc: 0.9759\n",
            "1000/1000 [==============================] - 0s 339us/step\n",
            "Creating and evaluating indiv #18\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "Creating and evaluating indiv #19\n",
            "\t\t\t\\Skipping training because model is the same as last gen\n",
            "this gen fitnesses: [0.973 0.96  0.964 0.958 0.963 0.965 0.952 0.973 0.95  0.973 0.957 0.963\n",
            " 0.916 0.968 0.971 0.954 0.959 0.95  0.955 0.968]\n",
            "The best individual [0 0 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0] had fitness (accuracy): 0.973\n",
            "CPU times: user 47min 9s, sys: 10min 3s, total: 57min 12s\n",
            "Wall time: 1h 6min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHqh5JrxgTDq",
        "colab_type": "text"
      },
      "source": [
        "## Baseline 20 gen x 20 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOPhKQ-JgR3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = False\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CrCDRDMA5fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 5)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vstiUgUrivpq",
        "colab_type": "text"
      },
      "source": [
        "## Baseline: 20 gen x 2 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8KjjexlizkL",
        "colab_type": "code",
        "outputId": "ec6714c7-4c47-4bb8-8b6e-6dffa99234d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = False\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.3734 - acc: 0.8781\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0658 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0435 - acc: 0.9866\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0355 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0276 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 232us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 448us/step - loss: 0.3392 - acc: 0.8876\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 425us/step - loss: 0.0572 - acc: 0.9830\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 432us/step - loss: 0.0407 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0323 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0282 - acc: 0.9912\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "this gen fitnesses: [0.9904 0.9913]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 408us/step - loss: 0.3862 - acc: 0.8701\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0615 - acc: 0.9819\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.0404 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0327 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0280 - acc: 0.9915\n",
            "10000/10000 [==============================] - 2s 238us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 416us/step - loss: 0.4032 - acc: 0.8684\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0601 - acc: 0.9821\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 393us/step - loss: 0.0458 - acc: 0.9862\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0348 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.0290 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "this gen fitnesses: [0.9924 0.9882]\n",
            "\t\t\tStarting generation 3...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.3113 - acc: 0.8981\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0597 - acc: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0425 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0323 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0265 - acc: 0.9923\n",
            "10000/10000 [==============================] - 2s 227us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 413us/step - loss: 0.3871 - acc: 0.8685\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0668 - acc: 0.9798\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0484 - acc: 0.9858\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 392us/step - loss: 0.0375 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 392us/step - loss: 0.0281 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 230us/step\n",
            "this gen fitnesses: [0.9918 0.9881]\n",
            "\t\t\tStarting generation 4...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.3345 - acc: 0.8899\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0561 - acc: 0.9833\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0375 - acc: 0.9886\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0337 - acc: 0.9895\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0263 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.4486 - acc: 0.8443\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0567 - acc: 0.9831\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0415 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0322 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0275 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 219us/step\n",
            "this gen fitnesses: [0.9924 0.9889]\n",
            "\t\t\tStarting generation 5...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.3059 - acc: 0.8982\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0599 - acc: 0.9819\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0402 - acc: 0.9883\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0320 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0259 - acc: 0.9923\n",
            "10000/10000 [==============================] - 2s 217us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 389us/step - loss: 0.3988 - acc: 0.8704\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0622 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 372us/step - loss: 0.0391 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0324 - acc: 0.9904\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0282 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 220us/step\n",
            "this gen fitnesses: [0.9874 0.9925]\n",
            "\t\t\tStarting generation 6...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3732 - acc: 0.8760\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0584 - acc: 0.9827\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0442 - acc: 0.9866\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0330 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0291 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 229us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.3156 - acc: 0.8973\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 21s 356us/step - loss: 0.0557 - acc: 0.9833\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 356us/step - loss: 0.0395 - acc: 0.9881\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 356us/step - loss: 0.0314 - acc: 0.9904\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 21s 356us/step - loss: 0.0283 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 218us/step\n",
            "this gen fitnesses: [0.9896 0.9882]\n",
            "\t\t\tStarting generation 7...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3799 - acc: 0.8733\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0603 - acc: 0.9823\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0471 - acc: 0.9867\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0336 - acc: 0.9903\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0277 - acc: 0.9916\n",
            "10000/10000 [==============================] - 2s 230us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 418us/step - loss: 0.3609 - acc: 0.8798\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0728 - acc: 0.9781\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0491 - acc: 0.9850\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0399 - acc: 0.9880\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0302 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "this gen fitnesses: [0.9864 0.9896]\n",
            "\t\t\tStarting generation 8...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 452us/step - loss: 0.3046 - acc: 0.9010\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 425us/step - loss: 0.0609 - acc: 0.9814\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.0418 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0322 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0276 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 249us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 416us/step - loss: 0.2814 - acc: 0.9081\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0539 - acc: 0.9834\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0397 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0319 - acc: 0.9903\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0264 - acc: 0.9919\n",
            "10000/10000 [==============================] - 2s 233us/step\n",
            "this gen fitnesses: [0.9907 0.992 ]\n",
            "\t\t\tStarting generation 9...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 443us/step - loss: 0.3278 - acc: 0.8923\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0582 - acc: 0.9825\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0394 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0320 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0253 - acc: 0.9924\n",
            "10000/10000 [==============================] - 2s 246us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 418us/step - loss: 0.3060 - acc: 0.9007\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0578 - acc: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0452 - acc: 0.9861\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0338 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0280 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "this gen fitnesses: [0.9905 0.9908]\n",
            "\t\t\tStarting generation 10...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.3314 - acc: 0.8855\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 425us/step - loss: 0.0586 - acc: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0424 - acc: 0.9870\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0314 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0278 - acc: 0.9914\n",
            "10000/10000 [==============================] - 3s 254us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 20s 339us/step - loss: 0.3932 - acc: 0.8694\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.0642 - acc: 0.9797\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.0432 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 19s 318us/step - loss: 0.0354 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 19s 319us/step - loss: 0.0275 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 197us/step\n",
            "this gen fitnesses: [0.9924 0.9914]\n",
            "\t\t\tStarting generation 11...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.3572 - acc: 0.8812\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.0615 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0406 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0318 - acc: 0.9909\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0251 - acc: 0.9923\n",
            "10000/10000 [==============================] - 2s 245us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.3781 - acc: 0.8775\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0684 - acc: 0.9795\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0459 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0345 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 21s 346us/step - loss: 0.0300 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 210us/step\n",
            "this gen fitnesses: [0.9919 0.9906]\n",
            "\t\t\tStarting generation 12...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.4608 - acc: 0.8415\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0613 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0434 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0336 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.0292 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 241us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.4814 - acc: 0.8340\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0717 - acc: 0.9799\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0467 - acc: 0.9862\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0362 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0283 - acc: 0.9913\n",
            "10000/10000 [==============================] - 2s 223us/step\n",
            "this gen fitnesses: [0.9912 0.9899]\n",
            "\t\t\tStarting generation 13...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 416us/step - loss: 0.4517 - acc: 0.8511\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0687 - acc: 0.9792\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0495 - acc: 0.9849\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0364 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0309 - acc: 0.9905\n",
            "10000/10000 [==============================] - 2s 233us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.3479 - acc: 0.8821\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0587 - acc: 0.9825\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0414 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0308 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0260 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "this gen fitnesses: [0.9904 0.9892]\n",
            "\t\t\tStarting generation 14...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.3399 - acc: 0.8909\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.0616 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.0426 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0362 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 397us/step - loss: 0.0288 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 234us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.2861 - acc: 0.9041\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0540 - acc: 0.9833\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0370 - acc: 0.9884\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0296 - acc: 0.9910\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0228 - acc: 0.9927\n",
            "10000/10000 [==============================] - 2s 238us/step\n",
            "this gen fitnesses: [0.9909 0.9934]\n",
            "\t\t\tStarting generation 15...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.3241 - acc: 0.8907\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0604 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0383 - acc: 0.9882\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0292 - acc: 0.9912\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0249 - acc: 0.9924\n",
            "10000/10000 [==============================] - 2s 246us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.3713 - acc: 0.8747\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 20s 341us/step - loss: 0.0601 - acc: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 342us/step - loss: 0.0435 - acc: 0.9868\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 343us/step - loss: 0.0346 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 21s 343us/step - loss: 0.0279 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 205us/step\n",
            "this gen fitnesses: [0.9913 0.9914]\n",
            "\t\t\tStarting generation 16...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.3097 - acc: 0.8944\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 405us/step - loss: 0.0534 - acc: 0.9841\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0349 - acc: 0.9893\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0312 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0222 - acc: 0.9931\n",
            "10000/10000 [==============================] - 2s 246us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.3206 - acc: 0.8921\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0588 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0404 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.0320 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0251 - acc: 0.9923\n",
            "10000/10000 [==============================] - 2s 229us/step\n",
            "this gen fitnesses: [0.9878 0.9907]\n",
            "\t\t\tStarting generation 17...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 457us/step - loss: 0.3169 - acc: 0.8979\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0560 - acc: 0.9828\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0375 - acc: 0.9886\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0340 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.0244 - acc: 0.9926\n",
            "10000/10000 [==============================] - 3s 252us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.3824 - acc: 0.8707\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0623 - acc: 0.9815\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0451 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0319 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0291 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 238us/step\n",
            "this gen fitnesses: [0.9909 0.9897]\n",
            "\t\t\tStarting generation 18...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.3490 - acc: 0.8865\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0599 - acc: 0.9823\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0431 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0333 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0242 - acc: 0.9927\n",
            "10000/10000 [==============================] - 2s 249us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.4193 - acc: 0.8603\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.0658 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.0446 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0350 - acc: 0.9893\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.0288 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 241us/step\n",
            "this gen fitnesses: [0.9898 0.992 ]\n",
            "\t\t\tStarting generation 19...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.2934 - acc: 0.9059\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0596 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0416 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0317 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 425us/step - loss: 0.0241 - acc: 0.9923\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 419us/step - loss: 0.2841 - acc: 0.9063\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.0586 - acc: 0.9823\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.0393 - acc: 0.9882\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.0323 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0251 - acc: 0.9921\n",
            "10000/10000 [==============================] - 2s 238us/step\n",
            "this gen fitnesses: [0.9886 0.9903]\n",
            "\t\t\tStarting generation 20...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 451us/step - loss: 0.2750 - acc: 0.9083\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0560 - acc: 0.9831\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0422 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0325 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0259 - acc: 0.9922\n",
            "10000/10000 [==============================] - 3s 251us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 420us/step - loss: 0.2940 - acc: 0.9028\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.0605 - acc: 0.9809\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.0411 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0322 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 400us/step - loss: 0.0260 - acc: 0.9922\n",
            "10000/10000 [==============================] - 2s 242us/step\n",
            "this gen fitnesses: [0.9898 0.9906]\n",
            "The best individual [0 1 1 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0 0] had fitness (accuracy): 0.9906\n",
            "CPU times: user 51min 39s, sys: 15min 48s, total: 1h 7min 27s\n",
            "Wall time: 1h 22min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Ry72Ayizbv",
        "colab_type": "code",
        "outputId": "39d53602-c4a2-4394-abd7-d928f51e063c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 2)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzNqUE4CZWZtyAjAza1NOAGZmber/4FA8r9vYh9QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xJLUTkD3Vd0",
        "colab_type": "text"
      },
      "source": [
        "## Baseline: 2 gen x 20 individuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvf9mjis3a8S",
        "colab_type": "code",
        "outputId": "d2a97031-5531-4186-fd3d-07899710a648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = False\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tStarting generation 1...\n",
            "Creating models from individuals...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3982 - acc: 0.8701\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0670 - acc: 0.9796\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0440 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0362 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0298 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 234us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.3316 - acc: 0.8920\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0552 - acc: 0.9834\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0404 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0311 - acc: 0.9902\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0261 - acc: 0.9921\n",
            "10000/10000 [==============================] - 3s 254us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.3431 - acc: 0.8923\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0657 - acc: 0.9799\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0424 - acc: 0.9868\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0344 - acc: 0.9893\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0267 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 160us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 425us/step - loss: 0.4575 - acc: 0.8494\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0635 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0429 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 402us/step - loss: 0.0357 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.0299 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 246us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.3810 - acc: 0.8758\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 379us/step - loss: 0.0585 - acc: 0.9824\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 379us/step - loss: 0.0409 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0326 - acc: 0.9897\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 378us/step - loss: 0.0256 - acc: 0.9921\n",
            "10000/10000 [==============================] - 2s 222us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 447us/step - loss: 0.4170 - acc: 0.8626\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0744 - acc: 0.9786\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0500 - acc: 0.9854\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0402 - acc: 0.9880\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0337 - acc: 0.9896\n",
            "10000/10000 [==============================] - 3s 252us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 434us/step - loss: 0.4666 - acc: 0.8468\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0903 - acc: 0.9725\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 25s 411us/step - loss: 0.0490 - acc: 0.9849\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 25s 411us/step - loss: 0.0441 - acc: 0.9870\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 25s 409us/step - loss: 0.0336 - acc: 0.9892\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 432us/step - loss: 0.3582 - acc: 0.8844\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0604 - acc: 0.9820\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0412 - acc: 0.9879\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0345 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 407us/step - loss: 0.0286 - acc: 0.9911\n",
            "10000/10000 [==============================] - 2s 238us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 416us/step - loss: 0.4606 - acc: 0.8485\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 398us/step - loss: 0.0860 - acc: 0.9749\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 396us/step - loss: 0.0583 - acc: 0.9825\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0413 - acc: 0.9873\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 395us/step - loss: 0.0359 - acc: 0.9895\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.3464 - acc: 0.8833\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0602 - acc: 0.9812\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0405 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0364 - acc: 0.9893\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0272 - acc: 0.9920\n",
            "10000/10000 [==============================] - 2s 219us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 453us/step - loss: 0.3170 - acc: 0.8995\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0604 - acc: 0.9815\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 430us/step - loss: 0.0402 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0341 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0296 - acc: 0.9911\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 16s 263us/step - loss: 0.3296 - acc: 0.8945\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 0.0572 - acc: 0.9832\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 15s 244us/step - loss: 0.0405 - acc: 0.9881\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 14s 242us/step - loss: 0.0303 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 0.0251 - acc: 0.9919\n",
            "10000/10000 [==============================] - 2s 184us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.3398 - acc: 0.8866\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 425us/step - loss: 0.0615 - acc: 0.9816\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 425us/step - loss: 0.0419 - acc: 0.9878\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0332 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.0321 - acc: 0.9901\n",
            "10000/10000 [==============================] - 3s 252us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 408us/step - loss: 0.3130 - acc: 0.8963\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0552 - acc: 0.9830\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0404 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0322 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0247 - acc: 0.9926\n",
            "10000/10000 [==============================] - 2s 235us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 229us/step - loss: 0.3485 - acc: 0.8825\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0625 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0412 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 210us/step - loss: 0.0295 - acc: 0.9908\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0245 - acc: 0.9922\n",
            "10000/10000 [==============================] - 2s 161us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 387us/step - loss: 0.3289 - acc: 0.8892\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0607 - acc: 0.9816\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0424 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0340 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0270 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 220us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.3301 - acc: 0.8934\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0641 - acc: 0.9804\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 363us/step - loss: 0.0434 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0327 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0260 - acc: 0.9921\n",
            "10000/10000 [==============================] - 2s 221us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.3520 - acc: 0.8833\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0657 - acc: 0.9803\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0441 - acc: 0.9864\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.0352 - acc: 0.9889\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0316 - acc: 0.9905\n",
            "10000/10000 [==============================] - 2s 236us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.3645 - acc: 0.8807\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0621 - acc: 0.9816\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0425 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0335 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0275 - acc: 0.9917\n",
            "10000/10000 [==============================] - 2s 219us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 449us/step - loss: 0.3455 - acc: 0.8881\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 425us/step - loss: 0.0605 - acc: 0.9818\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0400 - acc: 0.9877\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 426us/step - loss: 0.0316 - acc: 0.9905\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 427us/step - loss: 0.0275 - acc: 0.9916\n",
            "10000/10000 [==============================] - 3s 251us/step\n",
            "this gen fitnesses: [0.9884 0.9924 0.9901 0.99   0.9917 0.9877 0.9858 0.9909 0.9869 0.9878\n",
            " 0.9907 0.9866 0.993  0.9891 0.9926 0.9921 0.987  0.9905 0.9938 0.9915]\n",
            "\t\t\tStarting generation 2...\n",
            "Creating models from individuals...\n",
            "findIndividualsWithSameRoots...\n",
            "Creating and evaluating indiv #0\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 401us/step - loss: 0.4088 - acc: 0.8645\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.0647 - acc: 0.9806\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.0426 - acc: 0.9871\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.0322 - acc: 0.9907\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0268 - acc: 0.9916\n",
            "10000/10000 [==============================] - 2s 230us/step\n",
            "Creating and evaluating indiv #1\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.4176 - acc: 0.8544\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0680 - acc: 0.9805\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0463 - acc: 0.9866\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0344 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0271 - acc: 0.9919\n",
            "10000/10000 [==============================] - 2s 238us/step\n",
            "Creating and evaluating indiv #2\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 380us/step - loss: 0.4096 - acc: 0.8620\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0627 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0435 - acc: 0.9872\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0346 - acc: 0.9888\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0291 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 223us/step\n",
            "Creating and evaluating indiv #3\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 383us/step - loss: 0.3804 - acc: 0.8755\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0600 - acc: 0.9822\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0425 - acc: 0.9869\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0349 - acc: 0.9894\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0286 - acc: 0.9912\n",
            "10000/10000 [==============================] - 2s 226us/step\n",
            "Creating and evaluating indiv #4\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.4374 - acc: 0.8579\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0625 - acc: 0.9807\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0425 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0338 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0280 - acc: 0.9913\n",
            "10000/10000 [==============================] - 2s 226us/step\n",
            "Creating and evaluating indiv #5\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 445us/step - loss: 0.3929 - acc: 0.8718\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0673 - acc: 0.9799\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0445 - acc: 0.9868\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 25s 422us/step - loss: 0.0360 - acc: 0.9890\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 25s 423us/step - loss: 0.0276 - acc: 0.9914\n",
            "10000/10000 [==============================] - 2s 250us/step\n",
            "Creating and evaluating indiv #6\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 0.3216 - acc: 0.8953\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0583 - acc: 0.9829\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0373 - acc: 0.9880\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0317 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0260 - acc: 0.9923\n",
            "10000/10000 [==============================] - 2s 225us/step\n",
            "Creating and evaluating indiv #7\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 25s 424us/step - loss: 0.3651 - acc: 0.8785\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0614 - acc: 0.9821\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0400 - acc: 0.9881\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 404us/step - loss: 0.0339 - acc: 0.9896\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.0250 - acc: 0.9923\n",
            "10000/10000 [==============================] - 2s 242us/step\n",
            "Creating and evaluating indiv #8\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 399us/step - loss: 0.2925 - acc: 0.9039\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0608 - acc: 0.9825\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0392 - acc: 0.9884\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0341 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.0267 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 225us/step\n",
            "Creating and evaluating indiv #9\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.4298 - acc: 0.8594\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0723 - acc: 0.9789\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0478 - acc: 0.9856\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0381 - acc: 0.9881\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.0301 - acc: 0.9910\n",
            "10000/10000 [==============================] - 2s 213us/step\n",
            "Creating and evaluating indiv #10\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.3247 - acc: 0.8964\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0639 - acc: 0.9808\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 429us/step - loss: 0.0423 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0339 - acc: 0.9901\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0279 - acc: 0.9918\n",
            "10000/10000 [==============================] - 3s 251us/step\n",
            "Creating and evaluating indiv #11\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 225us/step - loss: 0.3143 - acc: 0.8973\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0584 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0379 - acc: 0.9886\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0279 - acc: 0.9913\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 211us/step - loss: 0.0251 - acc: 0.9922\n",
            "10000/10000 [==============================] - 2s 160us/step\n",
            "Creating and evaluating indiv #12\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 390us/step - loss: 0.3465 - acc: 0.8862\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0629 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0422 - acc: 0.9874\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0351 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 371us/step - loss: 0.0296 - acc: 0.9909\n",
            "10000/10000 [==============================] - 2s 222us/step\n",
            "Creating and evaluating indiv #13\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 391us/step - loss: 0.3884 - acc: 0.8734\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0615 - acc: 0.9817\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 369us/step - loss: 0.0427 - acc: 0.9875\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0338 - acc: 0.9900\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 370us/step - loss: 0.0283 - acc: 0.9918\n",
            "10000/10000 [==============================] - 2s 230us/step\n",
            "Creating and evaluating indiv #14\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 14s 231us/step - loss: 0.3473 - acc: 0.8893\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 13s 214us/step - loss: 0.0627 - acc: 0.9813\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 13s 213us/step - loss: 0.0424 - acc: 0.9873\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0312 - acc: 0.9906\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 13s 212us/step - loss: 0.0257 - acc: 0.9919\n",
            "10000/10000 [==============================] - 2s 163us/step\n",
            "Creating and evaluating indiv #15\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 386us/step - loss: 0.3372 - acc: 0.8879\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 367us/step - loss: 0.0596 - acc: 0.9824\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 366us/step - loss: 0.0413 - acc: 0.9876\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 365us/step - loss: 0.0327 - acc: 0.9898\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 366us/step - loss: 0.0271 - acc: 0.9919\n",
            "10000/10000 [==============================] - 2s 225us/step\n",
            "Creating and evaluating indiv #16\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 381us/step - loss: 0.4440 - acc: 0.8522\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 22s 359us/step - loss: 0.0698 - acc: 0.9794\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0463 - acc: 0.9862\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 359us/step - loss: 0.0353 - acc: 0.9893\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 361us/step - loss: 0.0301 - acc: 0.9907\n",
            "10000/10000 [==============================] - 2s 218us/step\n",
            "Creating and evaluating indiv #17\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 24s 406us/step - loss: 0.4080 - acc: 0.8660\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0652 - acc: 0.9814\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 23s 382us/step - loss: 0.0450 - acc: 0.9866\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 24s 403us/step - loss: 0.0366 - acc: 0.9892\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 23s 384us/step - loss: 0.0316 - acc: 0.9902\n",
            "10000/10000 [==============================] - 2s 237us/step\n",
            "Creating and evaluating indiv #18\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.3633 - acc: 0.8788\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 23s 385us/step - loss: 0.0748 - acc: 0.9778\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0503 - acc: 0.9849\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 22s 362us/step - loss: 0.0391 - acc: 0.9876\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0330 - acc: 0.9898\n",
            "10000/10000 [==============================] - 2s 219us/step\n",
            "Creating and evaluating indiv #19\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 27s 450us/step - loss: 0.3217 - acc: 0.8952\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0606 - acc: 0.9821\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0442 - acc: 0.9866\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0334 - acc: 0.9899\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 26s 428us/step - loss: 0.0293 - acc: 0.9913\n",
            "10000/10000 [==============================] - 3s 255us/step\n",
            "this gen fitnesses: [0.9896 0.9897 0.99   0.9894 0.9929 0.9892 0.992  0.9916 0.9889 0.9884\n",
            " 0.9915 0.9899 0.9902 0.9928 0.9864 0.9907 0.9901 0.9912 0.9914 0.9917]\n",
            "The best individual [1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0] had fitness (accuracy): 0.9929\n",
            "CPU times: user 48min 55s, sys: 14min 42s, total: 1h 3min 38s\n",
            "Wall time: 1h 17min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC6-6PJ13azj",
        "colab_type": "code",
        "outputId": "539352d7-cada-4b92-8446-6d67912d224e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 5)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29eXydZZ33//6ePSd7cpK0TZqlSUqX\ntBQoIC2jLIMiOPKoDO7P4Cw4PuIzg6IOzkt09FcRHXxGh3EcREQcHdwQcEE6gyA7FLCQbiTpnrY0\nW5M0y0nOcv3+uO9zn3NykiZt9uT7fr3yyjn3dZ1zXxcp53Ou7yrGGBRFURQlFddsL0BRFEWZe6g4\nKIqiKBmoOCiKoigZqDgoiqIoGag4KIqiKBl4ZnsBU0EoFDLV1dWzvQxFUZR5xcsvv9xhjCkZbWxB\niEN1dTUvvfTSbC9DURRlXiEiB8caU7OSoiiKkoGKg6IoipKBioOiKIqSwYLwOSiKokwHkUiE1tZW\nwuHwbC9lUgQCASoqKvB6vRN+jYqDoijKGLS2tpKbm0t1dTUiMtvLOSOMMXR2dtLa2kpNTc2EX6dm\nJUVRlDEIh8MUFxfPW2EAEBGKi4tP+/Sj4qAoinIK5rMwJDiTPSxqcTjY2c8dW1/n+X2dDEVjs70c\nRVGUOcOiFodXW3v4t8dbeN9dz7Phn/6bv7jnRb775D52He0lHtc+F4qizC1uueUWHn/8cR588EFu\nu+02AH72s5+xdu1aXC7XlCYDL2qH9DvPXsYlZ5Xw/N5Onmnp4OmWDrb8djcAoRwfm2pDXFwXYlNd\nMRWFwVleraIoi50XXniBW2+9lc997nNce+21ADQ0NPDAAw/w0Y9+dErvtajFASAv4OWta5fw1rVL\nADjWM8gzLUmxePjVowBUFwfZXGeJxUW1xRQEfbO5bEVRFhGf/vSnefTRR9m/fz8XXXQRe/fu5bHH\nHuPaa6/l1ltvnZZ7LnpxGMnS/CyuPa+Ca8+rwBhDc1sfTzd38ExLBw/+8Qg/euEQIrCuPJ/NdSH+\npC7EuVWFBLzu2V66oijTyD/9aie7jvZO6XuuWZbHF/5s7bjzvv71r3Pddddx33338Y1vfINLLrmE\nZ555ZkrXMhIVh1MgIqwsy2VlWS5/eXENkVicVw9383SLJRbffXIf//7EXvweFxfUFDknizVL83C5\n5n+Eg6Ioc4dXXnmFs88+mz179rB69eppv5+Kw2ngdbvYWF3Exuoi/v5PV9I3FOXF/Z083WyZob76\nyB4ACoJeNteGHLGoLFZ/haLMdybyDX862L59O9dffz2tra2EQiEGBgYwxrBhwwaee+45srKypuW+\nKg6TIMfv4bJVZVy2qgyAtt4wz+7t5OmWDp5u7uA3jccAWF6UxcV1llhsqg1RlK3+CkVRJsaGDRvY\nvn07mzZt4umnn+Yv//Iv+cxnPsOaNWum9b4qDlNIaV6A/3VOOf/rnHKMMezr6Lcc280d/Pq1Y/zX\ni4cBWLsszxGL86uLyPKpv0JRlLFpb2+nsLAQl8vFnj170oThl7/8JZ/4xCdob2/n6quvZsOGDTz6\n6KOTvqcYM//j+Tdu3GjmerOfaCxO45EeJwrq5YMniMQMPreL86oKubjeEot15fm41V+hKHOC3bt3\nz4h9fyYYbS8i8rIxZuNo8/XkMEN43C7OqSzknMpCbrysnoHhKNsOnHBOFl9/9HW+/ujr5AU8XFRb\n7JwsakLZCyJ9X1GU+YWKwywR9Hl4y8oS3rLSat/a2TfEs3Yy3lPNHTy68zgAy/IDlmO73vJXlOT6\nZ3PZiqIsElQc5gjFOX7+7Oxl/NnZyzDGcKhrwAmZ3brrOD97uRWAVUtynSioC2qKyPbrn1BRlKlH\nP1nmICJCVXE2VcXZfPDCKmJxw66jvY5Y/PD5g3zv6f14XMK5lYX2yaKY9RUFeN2LulyWoihThIrD\nPMDtEtZV5LOuIp+PXVJLOBLj5YMnHLH4l8ea+H//Y4XWvmlFMhmvrjRH/RWKopwRKg7zkIDXzWbb\nYQ3QPTDMc3Z+xTMtHfzP7jYASnP9jmN7c12IJfmB2Vy2oijzCBWHBUBB0Mfb1y3l7euWAnC4a4Bn\n91qO7Sea2nngj0cAqCvNccTiwhVF5AUm3k9WUZTZ55ZbbuGtb30rPT097N69m1tuuYVPf/rT/OpX\nv8Ln81FbW8v3v/99CgoKJn0vzXNY4MTjht1v9Nr5FZ28uL+TcCSO2yWcXZHviMU5lYX4POqvUJRU\n5lqew2WXXcZvfvMbp2T35s2b2bp1K5dddhkej4fPfvazANx+++0Zr9U8ByUNl0tYuyyftcvyueHN\ntQxFY7xysNtJxrvz8Ra+9fsWgj43F9QUOWKxakmu+isUZY4w0ZLdb3rTm/j5z38+JfdUcVhk+D1u\nLqot5qLaYm5+21n0DEZ4fl+yf8X/95vMZkeb60OUF0xPcS9FmTc88g/wRuPUvueSdfD2r447baIl\nu++55x7e+973TsnSVBwWOflZXt62dglvs5sdHe0e5Bnbsf10S6fT7GhFKNt2bBdz0YoQ+UH1VyjK\nTDJeye4tW7bg8Xj44Ac/OCX3U3FQ0lhWkMWfb1zOn29cjjGGpuN9ThTUL15p5YfPH8QlsK6igIvr\nitlcF+LcSm12pCwCJvANfzqYSMnue++9l1//+tc89thjU2YOVoe0MmGGo3Febe12OuP98XA3sbgh\n4HVxfnXSX6HNjpSFwlxySI9Vsvt3v/sdn/zkJ/nDH/5ASUnJmK9Xh7Qybfg8lgicX13ETVes5GQ4\nwov7u5yTxW12s6PCoJdNdiLexXUhlhdpsyNFmQynKtl94403MjQ0xBVXXAFYTunvfOc7k76nnhyU\nKaOtN8wzezucznhv9IYBqCwKOlnbF9UWa7MjZd4wl04Ok2VaTg4iciXwTcAN3G2M+eqI8SrgHqAE\n6AI+ZIxptcduB662p37ZGPMT+/r3gI2AAE3A9caYPhG5Hvg6cMR+zZ3GmLsnsk5ldinNC/Cucyp4\n1zkVGGPY297vREH9+tWj/NeLhxCxmh0lxOL86iL1VyjKHGRccRARN/BvwBVAK7BNRB42xuxKmfbP\nwH3GmB+IyGXAbcCHReRq4FxgA+AHnhCRR4wxvcBN9m9E5BvAjUBCdH5ijLlxaraozAYiQl1pDnWl\nOfzFpmqisTivHenhmWZLLO55ej//8Yd9+DwuNlYVOmLRoM2OFGVOMJGTwwVAizFmH4CI3A9cA6SK\nwxrgk/bjx4EHU64/aYyJAlEReQ24EvhpijAIkAXMf/uWMiYet4tzKws5t7KQT1xuNTt6cX+XEzKb\n2uxoU62VW3FxXYjq4qAm4ynKLDARcSgHDqc8bwUuHDHnVeDdWKandwG5IlJsX/+CiNwBBIFLSREV\nEfk+cJV97VMp7/ceEXkzlrnpJmNM6v0Tr70BuAGgsrJyAttQ5hJBn4dLzirlkrNKAehINDuyTxa/\n2/kGAOUFWWy2Q2a12ZGizBxTFa10M3Cn7S94EstfEDPGbBWR84FngXbgOSCWeJEx5iO22epfgfcC\n3wd+BfyXMWZIRD4K/AC4bOQNjTF3AXeB5ZCeon0os0Qox887z17GO+1mRwc7k82OHt15nJ++lGx2\nlMjavqBamx0pynQxkf+zjgDLU55XkHQWA2CMOYp1ckBEcoD3GGO67bEtwBZ77MdYp4HU18ZsU9Vn\ngO8bYzpThu8GvnY6G1LmPyJCdSib6lA2H3qT1exo59EeRyzue/4gdz+9H69bOKey0MmvOLsiH482\nO1KUKWEi4rANqBeRGixReB/wgdQJIhICuowxceAWrMilhDO7wBjTKSLrgfXAVtvPUGuMabEfvxPY\nY79mqTHmmP3W7wR2T3aTyvzG7RLWVxSwvqKA/3NJHeFIjJcOJJsd/b//aeIb/91Ert/DhSuKubiu\nmIvrQ9SWaLMjZWExWsnuz3/+8zz00EO4XC5KS0u59957WbZs2aTvNaE8BxG5CvgXrFDWe4wxW0Tk\nS8BLxpiHReRarAglg2VW+rhtFgoAr9hv0wv8rTFmu4i4gKeAPKxQ1leBjxljekXkNixRiGKFxX7M\nGLPnVOvTPIfFzYn+YZ7bl2x2dLBzAICyPL8TBbW5LkRZnjY7Uk6PuZbnMFrJ7t7eXvLy8gD41re+\nxa5du0ZNgpuWPAdjzG+B3464dmvK458DGXVijTFhrIilkdfjwOYx7nUL1ulDUSZEYbaPq9Yt5aqU\nZkdP2/kVj+9p44FXLCtofWmOIxYXrigiV5sdKfOEiZbs7u/v19pKqejJQRmLeNyw61ivk4y37UCX\n0+xow/ICRyw2LC/QZkdKBqnftm9/8Xb2dJ3SiHHarCpaxWcv+OyE5m7btm3Mkt3/+I//yH333Ud+\nfj6PP/74qDWWtLaSoqTgcgkN5fk0lOfz0bfUEo7EeOXQCSe/4s7fN/Otx5oJ+txcWFNkiUV9iLPK\ntNmRMrc4VcnuLVu2sGXLFm677TbuvPNO/umf/mnS99OTg7Ko6RmI8Jzd7OiZlg72dfQDVmjt5rpi\nx1+xTJsdLUrmgs9hrJLdxcXFTsnuBIcOHeKqq65ix44dGe+jJwdFOQ3yg16ubFjClQ1Ws6MjKc2O\nnmnp4KHtdrOjkmxHKN60opj8LPVXKDPDhg0b2L59+5glu5ubm6mvrwfgoYceYtWqVVNyXxUHRUmh\nvCCL6zYu5zq72dHrx086/St+/nIr9z1nNTtaX1HAxXUhNtUVc15VIX6PFg9Upo9Tlez+h3/4B15/\n/XVcLhdVVVVTUq4b1KykKBNmOBpn++FuJ2R2e0qzowtqip3OeKuXaLOjhcJcMCtNFWpWUpRpwudx\ncUFNERfUFPFJu9nRC/uSzY6+8lsrkqUo28em2qS/QpsdKfMRFQdFOUNyA17+dE0Zf7qmDIDjvWEn\nZPaZlg5+/ZqV6F9VnNLsaEUxhdrsSJkHqDgoyhRRlhfg3edW8O5zE82O+ni62QqZfXj7UX78gtXs\nqGFZviMWG6sLtdmRMidRcVCUacBqdpRLXWku12+uIRqL82prj3Oy+N7T+/jOH/bafbmTzY7WLtNm\nR8rcQMVBUWYAj9vFeVWFnFdVyP+9vJ7+oSgvHuhy+ld87Xev8zVeJz/Ly6baYkcsqrTZkTJLqDgo\nyiyQ7fdw6VmlXGo3O2o/OcSzey1fxdPNHTyyI9nsKNG/YlNtMaEcbXakzAwqDooyByjJ9XPNhnKu\n2VCOMYYDiWZHzR08suMYP3nJaoa4emmeEzJ7QU0RQZ/+L7yYGK1kd4I77riDm2++mfb2dkKh0KTv\npf+yFGWOISLUhLKpCWXzYbvZ0Y4jyWZHP3j2IN99ymp2dG6i2VF9iPXl2uxoofPCCy9w6623OiW7\nExw+fJitW7dOactkFQdFmeO4XcLZyws4e3kBH7+0jsHhGC8dTOZXfON/mrjDbnb0ppT8itqSbPVX\nLBDGK9l900038bWvfY1rrrlmyu6p4qAo84wsn5s/qS/hT+qtssxd/cM8t7fT7mHRzn/vOg7AkryA\nXWW2mM21IUq12dGkeOMrX2Fo99SW7PavXsWSz31u3Hlf//rXue6660Yt2f3QQw9RXl7O2WefPaVr\nU3FQlHlOUbaPq9cv5er1VrOjQ50DPLPXioL6/Z7j/OKVVgBWlqU2Oyomx6//+88nRivZPTAwwFe+\n8hW2bt065ffT2kqKsoBJNDtKmKBe3N/FUDSOJ7XZUb3V7Mir/ooM5kJtpVOV7P7hD3/I5ZdfTjBo\nlWhpbW1l2bJlvPjiiyxZsiTtfU63tpKKg6IsIsKRGK8cPOGIxWtHejAGsn1uLlyRzK9YWZaj/grm\nhjgkGKtkdyrV1dW89NJLo0YraeE9RVHGJOB1s6kuxKY668PDanaUqAfVye/3tAFWaO3mRDJefYil\n+drsaDY5Vcnu6UJPDoqiOLSeGODZlk7nZNHZPwwkmx1dXBfiTbXF5AUWR7OjuXRymCx6clAU5Yyp\nKAxy3flBrjt/OfG41ewoUQ/qZy8lmx2dvbzACZk9p7JAmx0tQFQcFEUZFZdLWL00j9VL8/jrP1nB\ncDTOHw+dcMTi20/s5V9/30KW180FNUWOWKxakqvNjhYAKg6KokwIn8fFhSuKuXBFMZ9861n02s2O\nEmKx5be7ASjO9rGpLuSU+ago1GZH8xEVB0VRzoi8gJcr1pRxhd3s6I0eq9lRQix+9epRAKpTmx3V\nFlMQ1GZH8wEVB0VRpoQl+QHec14F7znPanbU0tbnOLYf2n6UH9nNjtaVJ5sdnVelzY7mKioOiqJM\nOSJCfVku9WW5fGRzDZFYnNdau3m6uZNnWjr47pP7+Pcn9uL3uDi/usgRizXL8rTZ0RxBxUFRlGnH\n63ZxXlUR51UV8Xd/ajc72p8sHnj77/ZwO1AQTG92VFmkzY5SGa1k9xe/+EW++93vUlJi1dr6yle+\nwlVXXTXpe6k4KIoy42T7PVy6qpRLV1nNjtpOhq3igXZnvN82Ws2OKgqznCioTbXFFC/yZkdjley+\n6aabuPnmm6f0XioOiqLMOqW5gbRmR/s7+h3H9m8aj3H/NqvZ0ZqleVxcb4nFBdVFZPkWh7/iVCW7\npwvNkFYUZU4TjcXZcbTXaaH68sETDMfi+Nwuzq1KJuOtm4ZmR6lZxU/9tImOw31T+v6h5Tn8yXUr\nJzR327Zto5bs/uIXv8i9995LXl4eGzdu5I477qCwsDDj9ZohrSjKgsLjdrFheQEbUpodbTuQzK/4\n561N/PPWJnIDHi5aUeycLFaEFlazo9FKdgN87GMf4/Of/zwiwuc//3k+9alPcc8990z6fioOiqLM\nK7J8bt68soQ3r7QcsJ19Qzy3z/JXPNXcwVa72dHS/IDj2N5UV0xp7uSaHU30G/5UM1bJ7g0bNvDc\nc89RVlbmzP2bv/kb3vGOd0zJfVUcFEWZ1xTn+HnH+mW8Y/0yjDEc6hpwoqD+Z/dxfv6y1ezorLJc\npzPeBTXzp9nRhg0b2L59+5glu48dO8bSpVajp1/+8pc0NDRMyX3nx38dRVGUCSAiVBVnU1WczQcv\nrMpodvSjFw5yzzP78biEcyoLnJPF2XO82dGpSnZ/5jOfYfv27YgI1dXV/Md//MeU3FMd0oqiLBrC\nkRgvpzQ7akxpdvSmFcn+FfWlVrMjLdk9DiJyJfBNwA3cbYz56ojxKuAeoAToAj5kjGm1x24Hrran\nftkY8xP7+veAjYAATcD1xpg+EfED9wHnAZ3Ae40xByayTkVRlFMR8LrZbEc3AXQPDFv5FbZYPGY3\nOyrN9XNxXYgPrnITicbxeubuqWK6GFccRMQN/BtwBdAKbBORh40xu1Km/TNwnzHmByJyGXAb8GER\nuRo4F9gA+IEnROQRY0wvcJP9GxH5BnAj8FXgr4ATxpg6EXkfcDvw3inar6IoikNB0Mfb1y3l7ess\nm/3hrgGe3dvB0y2d/KGpnbcvL2b3G734PW5yAh5y/B5y/G7croUvFhM5OVwAtBhj9gGIyP3ANUCq\nOKwBPmk/fhx4MOX6k8aYKBAVkdeAK4GfpgiDAFlAwr51DfBF+/HPgTtFRMx02L+OvAIvfhcCeeDP\nS/mdbz/OTx/zBGABhcYpipLO8qIg7y2q5L3nVxKPG3bs2sWSvAD9wzFO9A/T2TeEIGT53JZQBDwE\nfW5cc/xz4Uw+PiciDuXA4ZTnrcCFI+a8Crwby/T0LiBXRIrt618QkTuAIHApKaIiIt8HrrKvfWrk\n/YwxURHpAYqBjtQbisgNwA0AlZWVE9jGKPS1wYGnINwLQ70k9WkMXN5RBMR+nCYupxAZ7+TC6RRF\nmRlcLiE3O4hruI/q4mIMMDAcoy8cpW8oSvvJMG0nwSVCtj9xqvAQ8LrmVH6FMYbOzk4CgdP77Jmq\naKWbsb7hXw88CRwBYsaYrSJyPvAs0A48B8RSFv0R22z1r1imo+9P9IbGmLuAu8BySJ/Rqs+60voB\niMdh+GRSKNJ+96Q870kf69+XfD7UO/493b6JnVISvx3hSREgz+KuL6MoM0VFRQWtra20t7dnjLmM\nYSgaZygSoyMaJxKzPobcLvB73Pg9LvxeN545UGU2EAhQUVFxWq+ZiDgcAZanPK+wrzkYY45inRwQ\nkRzgPcaYbntsC7DFHvsxlvM59bUx21T1GSxxSNyvVUQ8QD6WY3p6cbnsD+r8M38PR2B6RhGZnuTz\n1MdDvdDRlnw+fHL8+7j9YwjIWCIzyinHow1XFGU8vF4vNTU1E5p7rGeQZ1o67cztdtpPDgFQE8pm\nc12x1exoRYj8oHc6lzxlTEQctgH1IlKD9cH9PuADqRNEJAR0GWPiwC1YkUsJZ3aBMaZTRNYD64Gt\ntp+h1hjTYj9+J7DHfruHgb/AOmVcC/x+WvwN08GUCEwMhk5mCsh4InPyjeSc4QnUf/EExheQ8cxk\n7vnxj1xRZoKl+Vlce14F19rNjprb+ni62YqC+uUrR/jP561mR+tTmh2dO4ebHU0oz0FErgL+BSuU\n9R5jzBYR+RLwkjHmYRG5FitCyWCZlT5ujBkSkQDwiv02vcDfGmO2i4gLeArIwwplfRX4mDGm137N\nD4FzsMJi35dwho+F5jmMIB4b3QQ2ETNZ4nekf/z7eLImdko5lZnMrXmYysInEovz6uFuJ2T2j4e6\nicYNfo+LC2pSmh0tzcM1g2aoU+U5aBKcMjqxaNKPMp7IjHXKiQyMfx9v8BQCMgFfjAqMMg/pG4ry\n4v5OpzPe68ctc3Jh0Mum2lCy2VFxcFrXoeKgzA6xSNJEdrpmssTv6OD49/Fmj3OCmYAvxjU3j/bK\n4qCtN8yzdjLe080dvNEbBmB5UWqzoxBF2VPrK1RxUOYv0WFLYMY7pTjXRznlRMPj38eXM46fZRxf\njD9XBUaZEowx7Es0O2ru4Lm9nZwcigKwdlmeIxbnT0GzIxUHZXETHR5fQMbzxcSGxr+PL3eccORx\nfDG+XCuoQVFSiMbiNB7pcfpXvHzwBJGYwed2cV5VIR+4sJI/O3vZGb23NvtRFjceH3hCkB068/eI\nDk3slJIqMv3t0LU3ORYbHucmYp1ARj2dTNAXowKz4PC4XZxTWcg5lYXceFk9A8NRth044ZwsjvdO\n4GR8JvedlndVlIWGxw85JdbPmRIJT9yZn7je1wYdzcmxeGScm8jY4jJRM5k/V8vEzGGCPg9vWVnC\nW+xmR9Nl/VFxUJSZwhuwfnJKz+z1xlj+k4xTylgnGFtk+t6AjteT1+LRU99HXPYJZrys/VOIjC9H\nBWaGmK5SHSoOijJfEAFvlvWTWzb+/NEwBiKDE3fmJ373HoXw7uQ1Ezv1fcRtCcyESsOMMceXrQIz\ni6g4KMpiQgR8Qesnd8mZvYcxVg7L6eS8hHuhtxXaUuaY+DhrdZ9eOPJoc7xBFZgzRMVBUZTTQ8T6\nVu/LBpae2XsYA8P9p59Y2X04aUobOjm+wLg845vAxvPFeLMWpcCoOCiKMvOIgD/H+sk7szBMS2D6\nTi/nJdwL3QfThWjcUv2e8QVkPDPZPOwFo+KgKMr8RBKhv7lYbWDOgHjcEpixnPljnWC69qc/n2gv\nmInmvIwmMjPcC0bFQVGUxYvLZX8g51nNAc6EifSCGU1kJtMLJlVAVl8D6//8DBc/NioOiqIok2Eq\nS/Wfbv2xjjboOz51e0lBxUFRFGW2cbkhq8D6mSNonr2iKIqSgYqDoiiKkoGKg6IoipKBioOiKIqS\ngYqDoiiKkoGKg6IoipKBioOiKIqSgYqDoiiKkoGKg6IoipKBioOiKIqSgYqDoiiKkoGKg6IoipKB\nioOiKIqSgYqDoiiKkoGKg6IoipLBou7n0NjeyN2Nd1NfWE99YT0rC1dSmVuJ2+We7aUpiqLMKota\nHHqGe9jfu58nWp8gbuIA+N1+VuSvYGXhyjTRCGWFZnm1iqIoM4cYM05j7HnAxo0bzUsvvXTGrw9H\nw+zr2UfziWaaTzTTdKKJ5u5mOgY7nDlFgSLqC5JiUV9YT21BLVmerKnYgqIoyowjIi8bYzaONrao\nTw4JAp4Aa4rXsKZ4Tdr1rnCXIxjN3c00dTXxi+ZfMBgdBEAQKvMqqS+oTztpVORUqGlKUZR5jYrD\nKSgKFHHh0gu5cOmFzrVYPMaRviPW6SIhGieaeOzQYxisU1iWJ4va/Nq0U0Z9YT1FgaLZ2oqiKMpp\noWalKWIwOsi+7n00nWhKE46ucJczJ5QVyjhl1BbU4nf7Z3HliqIsVtSsNANkebJYG1rL2tDatOsd\ngx1JsbD9Gfe/fj9DsSEA3OIe1TRVnlOOSzTSWFGU2WFC4iAiVwLfBNzA3caYr44YrwLuAUqALuBD\nxphWe+x24Gp76peNMT+xr/8I2AhEgBeBjxpjIiJyCfAQsN9+zQPGmC+d8Q5nmVBWiFBWiE3LNjnX\nYvEYh04eShONXZ272HpwqzMn6AlSV1iXJhorC1eS78+fjW0oirLIGNesJCJuoAm4AmgFtgHvN8bs\nSpnzM+DXxpgfiMhlwEeMMR8WkauBvwfeDviBJ4DLjTG9InIV8Ij9Fj8GnjTG/LstDjcbY94x0U3M\nBbPSVDAQGaCluyXDn9Ez1OPMKQ2WWkJRkBSMmvwafG7fLK5cUZT5yGTNShcALcaYffab3Q9cA+xK\nmbMG+KT9+HHgwZTrTxpjokBURF4DrgR+aoz5bcoCXwQqJr6lhUnQG2R9yXrWl6x3rhljaB9sT4bY\n2qLxn8f+k0g8AoBHPFTnV1unjKKVTsjt0uyliMhsbUdRlHnMRMShHDic8rwVuHDEnFeBd2OZnt4F\n5IpIsX39CyJyBxAELiVdVBARL/Bh4O9SLl8kIq8CR7FOETtHLkpEbgBuAKisrJzANuYnIkJpsJTS\nYCmbyzc71yPxCId6D6WJxmsdr/HIgUecOTneHMuHMcKfkevLnY2tKIoyj5gqh/TNwJ0icj3wJHAE\niBljtorI+cCzQDvwHBAb8dpvY50unrKfvwJUGWP6bNPTg0D9yBsaY+4C7gLLrDRF+5g3eF1eagtq\nqS2o5cqaK53rfcN9jmkqIRqP7H+Enzb91JmzNHtphmhU51fjdXlnYyuKosxBJiIOR4DlKc8r7GsO\nxpijWCcHRCQHeI8xptse2xTbA4IAAB7LSURBVAJsscd+jOW/wH7+BSwn9kdT3qs35fFvReTbIhIy\nxiTTlZUxyfHlsKF0AxtKNzjXjDEcHzieEWb77JFniZooAB6XhxX5KzJEoyxYpqYpRVmETEQctgH1\nIlKDJQrvAz6QOkFEQkCXMSYO3IIVuZRwZhcYYzpFZD2wHthqj/018DYsB3U85b2WAMeNMUZELsCq\nHNs5uW0ubkSEJdlLWJK9hDdXvNm5HolF2N+7P8009fLxl/nNvt84c/J8eY5gpCb1ZXuzZ2MriqLM\nEOOKgzEmKiI3Ao9ihbLeY4zZKSJfAl4yxjwMXALcJiIGy6z0cfvlXuAp+5tnL1aIa9Qe+w5wEHjO\nHk+ErF4LfExEosAg8D6zEDL15iBet5eVhStZWbiSq51oY+gZ6qGluyVNNH6171f0R/qdOeU55Wmn\njJWFK6nMq8Tj0tQZRVkIaIa0MiGMMRztP5penPBEMwd6DxAzlhvJ5/KxosCuaJtimgplhdQ0pShz\nkFOFsqo4KJNiODbsVLRNTeprG2xz5hT4C5LRUrZo1BbUEvQGZ3HliqJo+Qxl2vC5fawqWsWqolVp\n17vD3U4SX0IwHmh+IK2ibUVuRYZoLM9drhVtFWUOsKjFYfDVV2n/1zsJrGsga906Ag0NeEtLZ3tZ\nC4KCQAHnLzmf85ec71yLmzhHTh6hqbsp7aTx+OHHnWZLAXcgzTSVcIIXZxXP1lYUZVGyqMUhdrKP\naHs7nXd9F2KW3dxTVmaJRcM6+3cD7nytZzQVuMTF8rzlLM9bzuWVlzvXw9Ewe3v2pvkznmp9igdb\nHnTmFAWKktFS9iljRcEKbbakKNOE+hyA+OAg4d27CTc2Mti4g3BjI8MHDzrj3spKshoaCKxbR9a6\nBgJr1uAKqr18uukc7KS5uzlNNPZ27yUcCwOW2FTmVibbudr1pipyK7SiraJMAHVInwGx3l7CO3ZY\nYrFjB4M7dhA9dswadLnw19YmxaJhHf6zVuLyafG76SYWj9Ha15pRBv3wycNpzZbqCurS/Bn1hfUU\nBgpnefWKMrdQcZgiou3tDO7YQbhxB4M7Ggk37iB24gQA4vXiP+usNJOUv7YWcatzdSYYiAywt3uv\nc9JIiMeJoRPOnJKskvTufAX1rChYoc2WlEWLisM0YYwhcuQo4R2NDDY2Et6xk/COHcT7rWQxCQYJ\nrFmd9F+sW4d3+XKN+Z8hjDF0hjtp6mpKi5za272X4fgwYDVbqsqrSvNn1BfWsyxnmZqmlAWPisMM\nYuJxhg8cSPNfhHfvxgxbH0au/Hyy1q5NmqTWrcNbVjbLq15cROPRjGZLTSeaONKXLBmW7c2mrqAu\nQzS02ZKykFBxmGVMJMJQc3Oa/2KoqSkZIVVSkua/CDSsxVOo9vGZpj/Sn95syRaN3mGnFiRlwbKk\nA9wWjRX5K/C6taKtMv9QcZiDxMNhO0Iq6b8Y3r/fGfcuX06gYa1jkgqsWYs7R4vdzTTGGNoG2tLM\nUk0nmtjXs49o3K5om2i2VJisM1VfUM+S7CVqQlTmNCoO84TYyZOEd+60/Be2aESP2hFSIvhqV6T5\nL/yrVmmE1CwRiUc42HPQEowUJ/ix/mPOnFxvbvopo7CeuoI6bbakzBlUHOYx0c7OZEhtYyODO3YQ\n67QrmHu9BFauJNDQ4Pgv/LW1iGdR5zbOKieHT1qmqa500eiL9DlzlmUvyzBNVeVXabMlZcZRcVhA\nGGOIHjtm+y8aHT9GvM/68JGsLAKrVzv+i6x1DXirqtS8MYsYY3ij/w3HNOVUtO054DRb8rq8yWZL\nKaJRGizVv50ybag4LHBMPM7wwYP2CcMySYV378aE7UzivDyyGtYSWNvgmKQ8S9QePttEYhGrou2I\nAoXHB447c/J8eWn9vxOioRVtlalAxWERYqJRhlpa0vwXQ03NELW+qbpDIbskiF10cN06jZCaI/QM\n9TitXFNFYyA64MwpzynPEI3KXG22pJweKg4KAPGhIYb27EnzXwzv2wf2vwFveXkypHZtA4GGtbhz\ncmZ51QpYFW2P9h3NEI0DvQecirY+l4/agtr0AoVFKykOFOspURkVFQdlTGJ9fYR37kr6LxobiRyx\nk8FE8NXUpPkv/KtX4/JruYm5wlBsiH3dtmkqxQnePtjuzCn0F6ZFTCWaLWlFW0XFQTktol1dGSG1\nsfYOa9Djwb+y3gqpbVhrhdTW1SFejbSZS5wIn8g4ZbR0t6Q1W1qeuzzDNFWRU6HNlhYRKg7KpDDG\nED1+POns3tHI4I6dxHutzGHx+wmsXp2W5e2rrkJcWptoLhE3cVpPtlrhtd1JX8ahk4fSmi3VFtRm\niEZRoGiWV69MByoOypRjjCFy8CCDO3Y6/ovwrl2YQeubqSsnJ5l/0bCOrIa1eJYtU9v3HGQwOsi+\n7n1OQl/ipNEV7nLmFAeK0yvaFtZTm19LwBOYxZUrk0XFQZkRTDTK0N59ySq1jTsINzVBJAKAu7g4\nrSRI1rp1eIq1/edcpWOwwzldJERjb/dehmJDQHqzJcefUbCS8txyrWg7T1BxUGaN+PCwFSFl98EI\n72hkqGWvEyHlWbY0TSwCa9fiztXyEnOVWDzG4ZOHk6cM2wneerI1rdlSooptauRUQaBgllevjETF\nQZlTxPv7Ce/alZblHTl82Bn3VVenV6ldsxpXQM0Xc5mByAAt3S0ZTvDuoW5nTmlWaYZpakX+Cnxu\nrQ82W6g4KHOe6IkTdrOkRsePEW1rswbdbvz19WklzQMrV2qE1BzHGEPHYEcykS/FNBWJ26ZGcVOd\nV50hGsuy1T81E6g4KPOSyPG2NP/F4I4dxHt6ABCfD//qVWkmKV9NjUZIzQOi8SiHeg8l60zZuRmp\nzZZyvDnpzZZs0cjz5c3iyhceKg7KgsAYQ+Tw4WRL1sZGBnftwgxYZSVc2dkE1q5N+i8a1uEt12+g\n84W+4b70Zkv2SePk8ElnzpLsJY4/IyEaNXk12mzpDFFxUBYsJhZjeN++NP/F0J49mESEVGFhekjt\nugY8JSWzvGplohhjOD5w3Cl9njhlpDVbcnmoya9JE42VhSspC5bpF4NxUHFQFhVmeJjw601pJc2H\nWlogbiV6eZYsSROLQEMD7jw1V8wnIrEIB3oPpIlG04km3uh/w5mT68vNEIy6gjpyfFovLIGKwxgc\nbe7m+Yf2UlAWpKA06PzOL8nC7VXb9UIiPjBAePfutJIgkYOHnHFvVWV6SO3q1biCWhZ7vtE73EvL\niXTTVPOJ5oxmS6l1puoL66nKq1qUFW1VHMagdU8XL/56P93HBxg8GUkOCOQWBVJEI4v8UutxbnEA\nl0uPqguBWE+Pk38xuMPyY0TfsL95ulz46+rS/BeBlfWItmWddxhjONZ/LHnKsEVjf89+YiYGWM2W\nagtqM/wZJVklC9o0peIwAYYGo/S0DdB93P5pG6SnbYATxweIhGPOPJdHyA9lUVAWtAXDelxQFiSY\n51vQ/5AWA5G2tmRIrV2lNtZtxeqL14t/1ao0k5RvxQrErYXq5iPDsWH29+x3BCNRb6ptoM2Zk+/P\nd5L4EqJRV1C3YJotqThMAmMMgycjtmAM2AIyaD8eJBaNO3O9fjf5CbGwzVT5pVkUlAYJZGs0xXzE\nGEPkyBErMsr2X4R37iTe3w+AKxgksGZNMmlv3Tq8FRX6JWEe0zPUkxQM25/RcqIlrdlSRU7FqM2W\n5ltFWxWHaSIeN/SdCNNji0VCQLrbBjnZMUjqf9pAjjfDRJUQD69vfv2DWuyYeJzh/fvTu+zt3oMZ\nHgbAXVBAoKHBKWkeaFiHt6x0lletTIa4iXOk70iGaepg70Gnoq3f7WdF/ooMf0YoKzTLqx8bFYdZ\nIBaN09sxaJupBuluH6DHNln19wynzc0p9FuCUZZipioNkhsK4HarY3w+YIaHCTc3J/0XjXaEVMwy\nSXpKS9NKgmQ1rMVdoLWG5jvhaNjqAz5CNDoGO5w5RYGiDF/GXGm2pOIwxxgOR+lpG8wwU3UfH2Bo\nIOrME5eQF0pxjJdmkW8/zinwI+oYn9PEBwcJ796T5r8YPnDAGfdWVlp9vBN5GGvW4MrOnr0FK1NG\nV7jLqWibEI29PXvTmi1V5lVm+DMqcitmtKLtpMVBRK4Evgm4gbuNMV8dMV4F3AOUAF3Ah4wxrfbY\n7cDV9tQvG2N+Yl//EbARiAAvAh81xkTEMtZ+E7gKGACuN8a8cqr1zTdxOBXhvkjSRGU7xrvbrFNH\nNJL0b3i8LsefkZ8WiptFIMerNu85Sqy31+6yl+zjHT12zBp0ufDXrrAio+woKf9ZZ+HSCKkFQSwe\no7WvNV00ups51HsoraJtbX4tK4vSRaMwUDgta5qUOIiIG2gCrgBagW3A+40xu1Lm/Az4tTHmByJy\nGfARY8yHReRq4O+BtwN+4AngcmNMr4hcBTxiv8WPgSeNMf9uX/8EljhcCHzTGHPhqda4kMRhLEzc\n0N8zlCEY3W2D9LYPEo8n/47+oMc2U2XZJ46kf8MXWHyx3HOdaEdHekht4w5iXXajHa+XwFlnWWLR\nYJmk/HW1GiG1gBiIDIxqmkptthTKClFfMKLZUkEtfvfk+rlPVhwuAr5ojHmb/fwWAGPMbSlzdgJX\nGmMO29/8e4wxeSLyaSBgjPmyPe97wKPGmJ+OuMdNQMgY848i8h/AE8aY/7LHXgcuMcYcG2uNi0Ec\nTkUsFudkZ5ju41YEVdIxPkBf11Da3GC+L8NEVVAWJD+kiX9zBWMM0aNH00qChHfuJN5nJXJJVhaB\nNWsssbD9GN7KSj0tLjDSKtrawrGvZ5/TbMktbirzKnn/qvfz/lXvP6N7nEocJvI1shw4nPK8Fesb\nfSqvAu/GMge9C8gVkWL7+hdE5A4gCFwK7Ep9oYh4gQ8Df3eK+5UDx0a87gbgBoDKysoJbGPh4na7\nnBPCSCLDMXrbB9MiqXqOD7D/tY60xD8RyC0OpJupbOd4TpEm/s0kIoK3vBxveTl5V74NsCOkDhxM\n81+cuP9+zA9+AIArP5+stWtTnN4NeMq0ttB8JpQVIpQVYtOyTc61WDzGoZOH0kQj4J6eXidTZWO4\nGbhTRK4HngSOADFjzFYROR94FmgHngNiI177bSyT0lOnc0NjzF3AXWCdHCa3/IWL1+emuDyH4vLM\nejJDAxHLRJXI4bDNVMf2HctM/CuxxSLh27BDcjXxb2YQlwv/ihr8K2rIf+c7ATCRCEMtLWklzTvv\nvtuJkHKXhNJLgjQ04CmcHtu1MjO4XW5q8muoya/hbdVvm9Z7TUQcjgDLU55X2NccjDFHsU4OiEgO\n8B5jTLc9tgXYYo/9GMt/gf38C1hO7I+ezv2UqcEf9FJW7aWsOr3onDGGgd7hjEiq7rZBDu7sJB5N\narHX73Yc4ckThyUe/qAm/k0n4vUSWL2awOrVcN11AMTDYcK7d6dlefc98YTTltVbUWH7LyyxCKxd\niztHI6SUTCYiDtuAehGpwfqQfh/wgdQJIhICuowxceAWrMilhDO7wBjTKSLrgfXAVnvsr4G3YTmo\n4ylv9zBwo4jcj2W+6jmVv0GZekSE7Hw/2fl+ltWnf9OMxw19XWFbMJKO8eMHeml5uS0t8S8r15ti\npkqeOvJLsvBo4t+04AoECJ5zDsFzznGuxfr60kuCvPoaJx/5nTUogm/FijT/hX/VKlz+yTk6lfnP\nRENZrwL+BSuU9R5jzBYR+RLwkjHmYRG5FrgNMFhmpY8bY4ZEJAAkwlB7gb81xmy33zMKHAQSnTwe\nMMZ8yXZo3wlciRXK+hFjzCm9zYvdIT1XiEXi9HSkmKlSTFYDoyT+jVZmRBP/ZoZoV5cTSpswScU6\n7MQtj4fAypVpJUH8tbWIRyPdFhqaBKfMOqmJf45z/LhV3DA18c/lEvJKskaYqSzHeHa+Jv5NF8YY\nom+8kVYSJLxjJ/GT1nc3CQQsE1aK/8JXVaVtWec5Kg7KnMUYQ7g/YpmoRhQ37Gkbkfjnc1mO8bJU\nx7h16ghka+LfVGPicYYPHkw3Se3ahQmHAXDl5lr1o1Kc3p4lS/TvMI9QcVDmJSZu6OseyjBRdR8f\n4GRHOCPxb7T+G5r4N7WYaJShvXuTVWobGwk3NUHUOv25Q6H0kNp16/AUFc3yqpWxUHFQFhyxWJyT\nHeG0SKpEP46+E+mJf9n5vpTChvbJoyxIXigLt0fNIpMlPjTE0J49TknzwR2NDO/dl4yQWrYsrehg\nYO0a3Lm5s7xqBVQclEVGZDjmnDR62geSlXHbBgj3jZL4N4pjXBP/Jkesr5/wrp1pJUEira3OuK+m\nJhlSu67BassamJ5kLmVsVBwUxSbcH8lwjCeEJDKUTPxze6zChvklyU5/CQHJylX/xpkQPXHCOlk0\nWs7ucGMj0fZ2a9DjwV9fb4fU2kUH6+oQr+bKTCcqDooyDonEv0Q13FQB6WkfJB5LSfwLuNOq4Dot\nY8uC+LPUv3E6RI4fT/NfDO7cSbynBwDx+60IqURJ83Xr8FVXa4TUFKLioCiTIB43nOwMWz6NtDax\nA/R2hmFk4t/I/uKlmvg3UYwxRA4dSvNfhHfuwgxafRBcOTkE1q5N6+PtWbZMT3JniIqDokwT0UiM\n3vakY7zHLm7YfXyAgd6UxD+xE/9Kgxk+jrziAC5N/BsTE4vZEVJJ/0X49dchYvmP3EVFmSG1obnb\nmnMuoeKgKLPA8GA06dMY0cBpeDAl8c8t5IWykjWqUgQku0ALG45GfHiYoddfd5L2wjsaGdq7D+JW\nXoxn6dK0kiCBtWtx5+WN866LDxUHRZlDGGOsjn8jMsUTJdVjIxP/StNDcBPFDQM56qxNJd7fT3j3\n7rQue5FDh5xxX3V1mv8isHo1rqzZ7+M8m6g4KMo8wUn8O57ZX7y3M4xJTfzL9qSZqfJTfBxev/o3\nAGLd3QymZnjv2EH0+HFr0O3GX1eXHlK7cuWiipBScVCUBYCT+JeSKZ5I/stI/CvwZ3T7KyjN0sQ/\nIHK8jfDOHUmTVGMjsUSElM+Hf/Uqp6R51roGfDU1C7Ytq4qDoixwIkMxO+Evtb+49Tzcn5L45xKn\n419qj/H8sixyCwOLsrChMYZIa2t6SO2uXZiBAQBcwSCBESVBvOXlC8IXpOKgKIuYcH8krdNfasvY\naGrin9eVTPob4RhfbIl/JhZjeN8+yyRl+y+Gdu/GJCKkCgrSWrIGGhrwlpbO8qpPHxUHRVEyMMYw\n0DOcJhYJX8fIxD9fwJ2W7Jc4deSXLp7EPzM8TLip2fZfWCapoZaWZIRUWVma/yKroQF3fv4sr/rU\nqDgoinJaxGNxTnaFk4KRIiAnu0Yk/uX50vuL22aq/JIsPN6FaatPEB8YILxnT5pJavjgQWfcW1WZ\nJhaBNWtwBYOzuOJ0VBwURZkyopEYPe2D9CQiqVKc44MjEv9yCwPJU0ZZ0jGeW7RwE/9iPT2Ed+60\no6Ms0Yi+8YY16HLhr61Nr1J71krE55uVtao4KIoyIwwNRtPLjDghuQMMh5P+DZdbyC/JyigzUlAW\nJJi/8BL/ou3tKS1ZLZNU7MQJAMTrxb9qVVIsGtZabVlnIEJKxUFRlFnFGMPgycioZUZ62gaJRVMS\n//zuEWaqZEhuIHth5CAYY4gcOZrmvwjv3Em8vx8ACQYJrFmdVhLEu3z5lIumioOiKHMWEzecPBEe\nYaayHp/sGCT1IyqQ7U03UyU6/5XM/8Q/E48zvH9/Wknz8O7dmGHLVOfOz7cio1L6eHvLyiZ1TxUH\nRVHmJbFonN6OwbQQ3ETmeH93euJfTqHfadaUaqbKDQVwz1P/holEGGpuTvNfDDU3Q8wy0XlKSij6\nq7+k+Prrz+j9TyUOiyMGTVGUeYnb46JwSTaFS7IzxobDUXraBzP6b7S80sZQf7KwobiEvLSOf8kc\njpwC/5xO/BOvl8CaNQTWrIH3XgdAfHCQ8O49TklzT/H0VKBVcVAUZV7iC3goWZ5LyfLMftThvkh6\nJNXxQXraBzjSdILocNK/4fa6kgl/qVnjZVZhw7noGHdlZRE89xyC554zrfdRcVAUZcERyPGyJCef\nJSvSk9CMMfR3D2c4xruO9nPg1Q7iKYUNfVmeZCRVanHD0iC+RZD4t/B3qCiKYiMi5BT6ySn0U3FW\nYdqYk/h3fDCtuOGxlh6ath1PS/wL5vlGLTOSX5KF2zs//RsjUXFQFEUBXG4X+SVB8kuCVDUUp41F\nh63Ev+SJw3q8/7UOBk+mFDYUyClK928kyozkFgdwzWH/xkhUHBRFUcbB43NTXJ5DcXlOxtjQQMQp\nnd6dUtxwz75jRFIT/zxCfigrs/9GWZBg3txL/FNxUBRFmQT+oJeyai9l1eltSJ3EvxQTVeLEcWhn\nV1rin9fvTmvWlCogs5X4p+KgKIoyDYgIwTwfwTwfy+oL0sbicUNfVzjZY9wWkLYDvex9uS098S/H\nmx6Ca4tHfmkWXt/0Jf6pOCiKoswwLpeQF7I687EmfSwWidPbOeiE4CYS/w7v6mLPc2+kzc0p9HP2\n5cvZ8KeVU75GFQdFUZQ5hNs7TuJf22Bapngwb3oquqo4KIqizBN8AQ8llbmUVGYm/k01CyMgV1EU\nRZlSVBwURVGUDFQcFEVRlAxUHBRFUZQMJiQOInKliLwuIi0i8g+jjFeJyGMi8pqIPCEiFSljt4vI\nDvvnvSnXb7Tfz4hIKOX6JSLSIyLb7Z9bJ7tJRVEU5fQYN1pJRNzAvwFXAK3ANhF52BizK2XaPwP3\nGWN+ICKXAbcBHxaRq4FzgQ2AH3hCRB4xxvQCzwC/Bp4Y5bZPGWPeMYl9KYqiKJNgIieHC4AWY8w+\nY8wwcD9wzYg5a4Df248fTxlfAzxpjIkaY/qB14ArAYwxfzTGHJjk+hVFUZRpYCLiUA4cTnneal9L\n5VXg3fbjdwG5IlJsX79SRIK26ehSYPkE7nmRiLwqIo+IyNrRJojIDSLykoi81N7ePoG3VBRFUSbK\nVCXB3QzcKSLXA08CR4CYMWariJwPPAu0A88BsTHfxeIVoMoY0yciVwEPAvUjJxlj7gLuAhCRdhE5\neIZrDwEdZ/ja+YrueXGge14cTGbPVWMNTEQcjpD+bb/CvuZgjDmKfXIQkRzgPcaYbntsC7DFHvsx\n0HSqm9n+iMTj34rIt0UkZIwZc/PGmJIJ7GNUROSlsRpsL1R0z4sD3fPiYLr2PBGz0jagXkRqRMQH\nvA94eMTiQiKSeK9bgHvs627bvISIrAfWA1tPdTMRWSJ2YXMRucBeY+fEt6QoiqJMlnHFwRgTBW4E\nHgV2Az81xuwUkS+JyDvtaZcAr4tIE1CGfVIAvMBTIrILywT0Ifv9EJH/KyKtWCeR10Tkbvs11wI7\nRORV4FvA+4xJLWCrKIqiTDey2D93ReQG23+xaNA9Lw50z4uD6drzohcHRVEUJRMtn6EoiqJkoOKg\nKIqiZLBoxEFE7hGRNhHZMca4iMi37HpPr4nIuTO9xqlkAvv9oL3PRhF5VkTOnuk1TjXj7Tll3vki\nEhWRa2dqbdPFRPZs1yvbLiI7ReQPM7m+6WAC/7bzReRXdiLtThH5yEyvcaoRkeUi8riI7LL39Hej\nzJnSz7BFIw7AvdilO8bg7VjJdvXADcC/z8CappN7OfV+9wNvMcasA76MnVA4z7mXU+85USvsdsYJ\nqZ5H3Msp9iwiBcC3gXcaY9YCfz5D65pO7uXUf+ePA7uMMWdjRVLeYYfhz2eiwKeMMWuANwEfF5ER\n3aen9jNs0YiDMeZJoOsUU67BKh5ojDHPAwUisnRmVjf1jLdfY8yzxpgT9tPnsUKK5zUT+BsDfAL4\nBdA2/Suafiaw5w8ADxhjDtnz5/2+J7Bng1XCR4Ace250JtY2XRhjjhljXrEfn8RKKxhZxmhKP8MW\njThMgInUkFqo/BXwyGwvYroRkXKs2l/z/VR4OqwECsUqpf+yiPzv2V7QDHAnsBo4CjQCf2eMic/u\nkqYOEakGzgFeGDE0pZ9hU1VbSZmniMilWOJw8WyvZQb4F+Czxpi4nYS/GPAA5wGXA1nAcyLyvDHm\nlGVs5jlvA7YDlwG1wH+LyFOppXnmK3Z5ol8Afz/d+1FxSDJuDamFhl3S5G7g7caYxVCiZCNwvy0M\nIeAqEYkaYx6c3WVNK61Ap10yv19EngTOZpwaZ/OcjwBftSsrtIjIfmAV8OLsLmtyiIgXSxh+ZIx5\nYJQpU/oZpmalJA8D/9v2+L8J6DHGHJvtRU0XIlIJPAB8eIF/i3QwxtQYY6qNMdXAz4H/s8CFAeAh\n4GIR8YhIELgQy169kDmEdVJCRMqAs4B9s7qiSWL7T74H7DbGfGOMaVP6GbZoTg4i8l9YkQshu6bT\nF7BqP2GM+Q7wW+AqoAUYwPr2MW+ZwH5vBYqBb9vfpKPzvZrlBPa84Bhvz8aY3SLyO6xGW3HgbmPM\nKUN95zoT+Dt/GbhXRBoBwTIlzvcy3puBDwONIrLdvvY5oBKm5zNMy2coiqIoGahZSVEURclAxUFR\nFEXJQMVBURRFyUDFQVEURclAxUFRFEXJQMVBURRFyUDFQVEURcng/wdFVvSBg24ibQAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C64C734M9H5u",
        "colab_type": "text"
      },
      "source": [
        "# New try 10 epoch per train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEjyQoZB9Lrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "np.random.seed(43) # reproducible\n",
        "params.isModification = True\n",
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses = executeSelectionWithGeneticAlgorithm(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWfu4E129Ll3",
        "colab_type": "code",
        "outputId": "b955e4b3-849d-4ba8-93ad-48158afff3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plotEvolutionProgress(allFitnesses, takeBestN = 2)\n",
        "allFitnesses.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD4CAYAAAAQP7oXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWWkuGmZmVto/7ywH+mcIXGIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNk4q44pJ5tl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "fe0377ac-27a2-4386-da85-1827f994cf31"
      },
      "source": [
        "lastGenIndividuals, bestIdx, lastGenFitness, allFitnesses "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0],\n",
              "        [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1],\n",
              "        [1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1],\n",
              "        [1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0],\n",
              "        [1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1],\n",
              "        [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1],\n",
              "        [1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1],\n",
              "        [0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              "        [1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]],\n",
              "       dtype=int32),\n",
              " 9,\n",
              " array([0.9934, 0.9903, 0.9871, 0.9911, 0.9905, 0.9898, 0.9919, 0.9903,\n",
              "        0.9912, 0.995 ]),\n",
              " array([[0.989 , 0.9895, 0.9914, 0.9914, 0.9915, 0.9917, 0.993 , 0.993 ,\n",
              "         0.993 , 0.9932],\n",
              "        [0.989 , 0.9892, 0.9895, 0.9917, 0.9917, 0.9919, 0.9928, 0.993 ,\n",
              "         0.993 , 0.993 ],\n",
              "        [0.989 , 0.9892, 0.9911, 0.9914, 0.9917, 0.9919, 0.9919, 0.9928,\n",
              "         0.993 , 0.9943],\n",
              "        [0.9914, 0.9914, 0.9917, 0.9918, 0.9919, 0.9919, 0.9928, 0.993 ,\n",
              "         0.9937, 0.9943],\n",
              "        [0.9914, 0.9915, 0.9915, 0.9917, 0.9919, 0.9921, 0.993 , 0.9932,\n",
              "         0.9937, 0.9939],\n",
              "        [0.9902, 0.9914, 0.9917, 0.9918, 0.9923, 0.9928, 0.9928, 0.993 ,\n",
              "         0.9931, 0.9935],\n",
              "        [0.9893, 0.9902, 0.9915, 0.9915, 0.9926, 0.9929, 0.9932, 0.9933,\n",
              "         0.9935, 0.9939],\n",
              "        [0.9906, 0.9919, 0.9922, 0.9922, 0.9923, 0.9928, 0.993 , 0.9932,\n",
              "         0.9939, 0.9939],\n",
              "        [0.9884, 0.9919, 0.9923, 0.9927, 0.9927, 0.9929, 0.9929, 0.9931,\n",
              "         0.9931, 0.9933],\n",
              "        [0.9871, 0.9898, 0.9903, 0.9903, 0.9905, 0.9911, 0.9912, 0.9919,\n",
              "         0.9934, 0.995 ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IM7qy-HkurB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9T9FF95lC6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, box_size, 10, 0)\n",
        "model = compile_model(model)\n",
        "visualize_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuXJhy_ieyQ0",
        "colab_type": "text"
      },
      "source": [
        "# Manually"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaIZak9OZnqx",
        "colab_type": "code",
        "outputId": "1703400d-603d-4371-b083-ebfdaeae9c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "x_train, y_train, x_test, y_test, box_size = load_mnist(doubled=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 9s, sys: 19.8 s, total: 1min 29s\n",
            "Wall time: 1min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwTVIW1He7kO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STAGES = np.array([\"s1\",\"s2\",\"s3\"]) # S\n",
        "NUM_NODES = np.array([3,4,5])       # K\n",
        "FILTERS = np.array([32, 48, 64])\n",
        "sampleIndividual = [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSY8vpXfM8B",
        "colab_type": "code",
        "outputId": "21ba34ef-54a2-4c71-fe2d-221ae5ac9a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = CNN_build(STAGES, NUM_NODES, FILTERS, sampleIndividual, 56, 10, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting network building..\n",
            "\n",
            "Build layer s1 : 3 nodes, 32 filters.\n",
            "Stage indices: [1, 1, 0]\n",
            "Stage indexes: [array([0]), array([1, 2])]\n",
            "Building vs1_0\n",
            "Builded vs1_0\n",
            "Building vs1_1\n",
            "Builded vs1_1\n",
            "Building vs1_2\n",
            "Builded node vs1_2\n",
            "Building vs1_3\n",
            "Builded node vs1_3\n",
            "from_him:  [2.0, 0.0, 0.0]\n",
            "to_him:  [0.0, 1.0, 1.0]\n",
            "stage_nodes:  [<tf.Tensor 'vs1_1/Relu:0' shape=(?, 56, 56, 32) dtype=float32>, <tf.Tensor 'vs1_2/Relu:0' shape=(?, 56, 56, 32) dtype=float32>, <tf.Tensor 'vs1_3/Relu:0' shape=(?, 56, 56, 32) dtype=float32>]\n",
            "Building vs1_4\n",
            "Connect to last node node 1   Tensor(\"vs1_2/Relu:0\", shape=(?, 56, 56, 32), dtype=float32)\n",
            "Connect to last node node 2   Tensor(\"vs1_3/Relu:0\", shape=(?, 56, 56, 32), dtype=float32)\n",
            "Builded vs14\n",
            "\n",
            "Build layer s2 : 4 nodes, 48 filters.\n",
            "Stage indices: [0, 0, 0, 0, 1, 1]\n",
            "Stage indexes: [array([0]), array([1, 2]), array([3, 4, 5])]\n",
            "Building vs2_0\n",
            "Builded vs2_0\n",
            "Building vs2_1\n",
            "Builded vs2_1\n",
            "Building vs2_2\n",
            "Builded node vs2_2\n",
            "Building vs2_3\n",
            "Builded node vs2_3\n",
            "Building vs2_4\n",
            "Builded node vs2_4\n",
            "from_him:  [0.0, 1.0, 1.0, 0.0]\n",
            "to_him:  [0.0, 0.0, 0.0, 2.0]\n",
            "stage_nodes:  [<tf.Tensor 'vs2_1/Relu:0' shape=(?, 28, 28, 48) dtype=float32>, <tf.Tensor 'vs2_2/Relu:0' shape=(?, 28, 28, 48) dtype=float32>, <tf.Tensor 'vs2_3/Relu:0' shape=(?, 28, 28, 48) dtype=float32>, <tf.Tensor 'vs2_4/Relu:0' shape=(?, 28, 28, 48) dtype=float32>]\n",
            "Building vs2_5\n",
            "Connect to last node node 3   Tensor(\"vs2_4/Relu:0\", shape=(?, 28, 28, 48), dtype=float32)\n",
            "Builded vs25\n",
            "\n",
            "Build layer s3 : 5 nodes, 64 filters.\n",
            "Stage indices: [1, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n",
            "Stage indexes: [array([0]), array([1, 2]), array([3, 4, 5]), array([6, 7, 8, 9])]\n",
            "Building vs3_0\n",
            "Builded vs3_0\n",
            "Building vs3_1\n",
            "Builded vs3_1\n",
            "Building vs3_2\n",
            "Builded node vs3_2\n",
            "Building vs3_3\n",
            "Builded node vs3_3\n",
            "Building vs3_4\n",
            "Builded node vs3_4\n",
            "Building vs3_5\n",
            "Builded node vs3_5\n",
            "from_him:  [3.0, 2.0, 1.0, 0.0, 0.0]\n",
            "to_him:  [0.0, 1.0, 2.0, 1.0, 2.0]\n",
            "stage_nodes:  [<tf.Tensor 'vs3_1/Relu:0' shape=(?, 14, 14, 64) dtype=float32>, <tf.Tensor 'vs3_2/Relu:0' shape=(?, 14, 14, 64) dtype=float32>, <tf.Tensor 'vs3_3/Relu:0' shape=(?, 14, 14, 64) dtype=float32>, <tf.Tensor 'vs3_4/Relu:0' shape=(?, 14, 14, 64) dtype=float32>, <tf.Tensor 'vs3_5/Relu:0' shape=(?, 14, 14, 64) dtype=float32>]\n",
            "Building vs3_6\n",
            "Connect to last node node 3   Tensor(\"vs3_4/Relu:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
            "Connect to last node node 4   Tensor(\"vs3_5/Relu:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
            "Builded vs36\n",
            "Created Network builded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAOeVitcfOyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_90wxfdfRXF",
        "colab_type": "code",
        "outputId": "c7e4595d-fd7e-4c79-9c0a-69035287737a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "visualize_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model summary: \n",
            "Model: \"individual\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 56, 56, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "vs1_0 (Conv2D)                  (None, 56, 56, 32)   320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "vs1_1 (Conv2D)                  (None, 56, 56, 32)   9248        vs1_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_2 (Conv2D)                  (None, 56, 56, 32)   9248        vs1_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_3 (Conv2D)                  (None, 56, 56, 32)   9248        vs1_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 32)   0           vs1_2[0][0]                      \n",
            "                                                                 vs1_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs1_4 (Conv2D)                  (None, 56, 56, 32)   9248        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 32)   0           vs1_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_0 (Conv2D)                  (None, 28, 28, 48)   13872       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "vs2_2 (Conv2D)                  (None, 28, 28, 48)   20784       vs2_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_3 (Conv2D)                  (None, 28, 28, 48)   20784       vs2_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 28, 28, 48)   0           vs2_2[0][0]                      \n",
            "                                                                 vs2_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_4 (Conv2D)                  (None, 28, 28, 48)   20784       add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs2_5 (Conv2D)                  (None, 28, 28, 48)   20784       vs2_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 48)   0           vs2_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_0 (Conv2D)                  (None, 14, 14, 64)   27712       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "vs3_1 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_2 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 14, 14, 64)   0           vs3_1[0][0]                      \n",
            "                                                                 vs3_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_3 (Conv2D)                  (None, 14, 14, 64)   36928       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 14, 14, 64)   0           vs3_2[0][0]                      \n",
            "                                                                 vs3_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_4 (Conv2D)                  (None, 14, 14, 64)   36928       vs3_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_5 (Conv2D)                  (None, 14, 14, 64)   36928       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 14, 14, 64)   0           vs3_4[0][0]                      \n",
            "                                                                 vs3_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "vs3_6 (Conv2D)                  (None, 14, 14, 64)   36928       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)     0           vs3_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 3136)         0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "next_to_last (Dense)            (None, 32)           100384      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "last (Dense)                    (None, 10)           330         next_to_last[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 484,314\n",
            "Trainable params: 484,314\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGteF_JxgBak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', cooldown=1)\n",
        "estop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmqrhD9fbnX",
        "colab_type": "code",
        "outputId": "16049449-de70-49f5-da7c-025ba4ac9c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "%%time\n",
        "history, result = train_model(model, x_train, y_train, x_test, y_test, 30, 512, 1, 0.2, [reducelr, estop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 96000 samples, validate on 24000 samples\n",
            "Epoch 1/30\n",
            "96000/96000 [==============================] - 122s 1ms/step - loss: 0.4295 - acc: 0.8654 - val_loss: 0.0661 - val_acc: 0.9813\n",
            "Epoch 2/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0544 - acc: 0.9844 - val_loss: 0.0441 - val_acc: 0.9879\n",
            "Epoch 3/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0348 - acc: 0.9899 - val_loss: 0.0375 - val_acc: 0.9895\n",
            "Epoch 4/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0277 - acc: 0.9919 - val_loss: 0.0288 - val_acc: 0.9913\n",
            "Epoch 5/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0232 - acc: 0.9931 - val_loss: 0.0321 - val_acc: 0.9907\n",
            "Epoch 6/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0212 - acc: 0.9935 - val_loss: 0.0260 - val_acc: 0.9921\n",
            "Epoch 7/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0296 - val_acc: 0.9912\n",
            "Epoch 8/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0257 - val_acc: 0.9923\n",
            "Epoch 9/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0272 - val_acc: 0.9920\n",
            "Epoch 10/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0217 - val_acc: 0.9936\n",
            "Epoch 11/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0102 - acc: 0.9967 - val_loss: 0.0234 - val_acc: 0.9937\n",
            "Epoch 12/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0311 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 13/30\n",
            "96000/96000 [==============================] - 117s 1ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0221 - val_acc: 0.9950\n",
            "Epoch 14/30\n",
            "96000/96000 [==============================] - 116s 1ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0275 - val_acc: 0.9940\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 15/30\n",
            "96000/96000 [==============================] - 116s 1ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0286 - val_acc: 0.9951\n",
            "Epoch 00015: early stopping\n",
            "20000/20000 [==============================] - 10s 518us/step\n",
            "CPU times: user 13min 43s, sys: 6min 6s, total: 19min 50s\n",
            "Wall time: 29min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMYjil9fjP13",
        "colab_type": "code",
        "outputId": "2e259362-e372-43fa-cc10-3c9b25a3ef02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03145271535242287, 0.99495]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq26Lc0ujT2Y",
        "colab_type": "code",
        "outputId": "dd631450-8098-4b7f-96b4-7beaed43d8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "epochs = history.epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.title('Loss/Val loss curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(epochs, loss, color='red', label='training')\n",
        "plt.plot(epochs, val_loss, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDJEkWmb9uAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K8N0nlVjZYp",
        "colab_type": "code",
        "outputId": "bd568d14-514d-411a-9ab3-997471262ffc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.title('Acc/Val acc curve')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(epochs, acc, color='red', label='training')\n",
        "plt.plot(epochs, val_acc, color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTk4QZmaWkxOEmZnl9P8DOifa7krursIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVp4A8xQU-fb",
        "colab_type": "text"
      },
      "source": [
        "# Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZObn4NLVDK0",
        "colab_type": "text"
      },
      "source": [
        "* Google Schoolar Searches: [link](https://scholar.google.com/scholar?hl=sr&as_sdt=0%2C5&q=genetic+cnn+handwritting&btnG=)\n",
        "\n",
        "* Fokus na rad: \n",
        " * .pdf: [link](https://arxiv.org/abs/1703.01513)\n",
        " * github: [link](https://arxiv.org/abs/1703.01513)\n",
        "* Dodatno rad:\n",
        " *  .pdf: [link](https://arxiv.org/pdf/1710.10741.pdf)\n",
        " * Clanak na netu: [link](https://blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164)\n",
        "* Ako sami implementiramo: [link](https://github.com/joeddav/devol/blob/master/devol/devol.py)\n"
      ]
    }
  ]
}